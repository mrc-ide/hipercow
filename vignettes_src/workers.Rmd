---
title: "Workers"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Workers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!-- This vignette really requires a real cluster behind it to work
     properly; we're going to submit a bunch of workers and tasks at
     them, and the example driver cannot support this without
     involving something better for the queue.  It's also nicer for
     users if they see code that remotely looks like what they are
     used to seeing -->

```{r setup, include = FALSE}
source("../vignettes/common.R")
vignette_root <- new_hipercow_root_path(TRUE)
set_vignette_root(vignette_root)
```

```{r, echo = FALSE, results = "asis"}
add_header()
```

This vignette describes a pair of relatively advanced techniques for using a *second* queue embedded on top of the usual HPC scheduler in order to scale work; either running many more tasks than is convenient to run with the HPC scheduler, or running tasks that need more resources than you can easily get on a single cluster node.

If you have thousands and thousands of tasks to submit at once you may not want to flood the cluster with them all at once. Each task submission tends to be relatively slow on every platform that we have used, and submitting thousands of tasks will take minutes (even if you could submit 10 tasks a second, a thousand tasks will take almost two minutes, and a million tasks would take 27 hours!). Some cluster schedulers also slow down as the queue size increases, becoming less efficient at distributing work. And if you take up the whole cluster someone may come and find you in order to complain.  At the same time, batching your tasks up into little bits and manually sending them off is a pain and work better done by a computer.  An alternative is to submit a (relatively small) set of "workers" to the cluster, and then submit tasks to them.  We call this the **"lightweight queue pattern"**.

The second use case is where you want to run some computation on the cluster that needs to run some of its calculations in parallel, as you might do following instructions in `vignette("parallel")`.  Suppose that your cluster only has nodes with 32 cores though, and you have some calculations that would benefit from more cores than this.  Or suppose that you want to farm out some smaller number number of sub-tasks each of which will consume an entire node.  You can use the approach described here to scale your tasks off a single node, and we call this the **"interprocess communication pattern"**.

Both of these patterns are enabled with our [`rrq`](https://mrc-ide.github.io/rrq) package, along with a [Redis](https://redis.io) server which is running on the cluster.

These are advanced topics, so be sure you're happy running tasks on the cluster before diving in here.  You should also be prepared to make some fairly minor changes to your code to suit some limitations and constraints of this approach.

# Getting started

To get started, you will need the `rrq` package, if you do not have it already (this will be installed automatically by `hipercow`, you can skip this step if you want)

```r
install.packages(
  "rrq",
  repos = c("https://mrc-ide.r-universe.dev", "https://cloud.r-project.org"))
```

You'll want a very recent version; here we are using version `r as.character(packageVersion("rrq"))`

```{r}
library(hipercow)
hipercow_init(driver = "dide-windows")
```

# The lightweight queue pattern

Briefly, with this approach we will submit `m` workers to the cluster, and then we will submit `n` tasks to these workers.  This approach allows you to decouple the number of tasks that you have to submit from the potential resource that you will consume on the cluster.  In addition the queue that you submit to (that your workers sit on) is much faster than the cluster scheduler, so this can actually be faster than submitting (short) tasks directly to the cluster.

The intended use case for this system is:

* Many small tasks, each of which takes only a few seconds or minutes.
* When you have many tasks and want to limit your total resource use
* (More advanced) When you want to change your resource use over time, scaling up usage over quiet periods such as holidays, and back down once everyone is back at work.

The downside is an extra level of bookkeeping to keep track of and a little more distance between you and your work that can make digging into what has gone wrong a bit frustrating.

Most interaction with `rrq` is done via a "controller"; this is an object that you can use to submit tasks and query on their status:

```{r}
r <- hipercow_rrq_controller()
```

We'll use this controller to submit tasks (rather than functions in hipercow), but many of the ideas will feel very similar to you from `hipercow` itself.  The controller object is just a handle that is passed to most functions in the rrq package:

```{r}
r
```

The other thing you'll need are some workers.  Let's submit a single worker to the cluster, and wait for it to become available:

```{r}
resources <- hipercow_resources(queue = "Testing")
info <- hipercow_rrq_workers_submit(1, resources = resources)
info
```

Because we are experimenting here, we are using the `Testing` queue, which should be used only for finding out if your cluster scripts are working - it has a h hard limit on how long a task (or here, a worker) can run for, which will lead to it being unceremoniously terminated quite quickly!

A group of workers are submitted as task bundles and can be inspected using their bundle name like any other task:

```{r}
hipercow_bundle_status(info$bundle_name)
```

You can use this to see how your workers are getting on, and if they have stopped.

This worker will remain running for 10 minutes after the last piece of work it runs.

## Basic usage

We'll load the `rrq` package to make the calls a little clearer to read:

```{r}
library(rrq)
```

Submitting a task works much the same as `hipercow`, except that rather than `task_create_expr` you will use `rrq_task_create_expr` and pass the the controller as an argument:

```{r}
id <- rrq_task_create_expr(runif(10))
```

as with `hipercow`, this `id` is a hex string:

```{r}
id
```

There's nothing here to distinguish this from a task identifier in `hipercow` itself (both just use strings), so be careful with your workflows.

Once you have you have your task, interacting with it will feel familiar as you can query its status, wait on it and fetch the result:

```{r}
rrq_task_status(id)
rrq_task_wait(id)
rrq_task_result(id)
```

The big difference here from `hipercow` is how fast this process should be; the roundtrip of a task here will be a (hopefully small) fraction of a second:

```{r}
system.time({
  id <- rrq_task_create_expr(runif(10))
  rrq_task_wait(id)
  rrq_task_result(id)
})
```

## Scaling up

Let's submit 1,000 trivial tasks, using `rrq_task_create_bulk_expr`, taking the square root of the first thousand positive integers.

```{r, include = FALSE}
t0 <- Sys.time()
```
```{r}
ids <- rrq_task_create_bulk_expr(sqrt(x), data.frame(x = 1:1000))
```

There's no equivalent of a task bundle in `rrq`; this just returns a vector of task 1000 task identifiers.  You can pass this vector in to `rrq_task_wait()` though, and then fetch the results using `rrq_task_results()` (note the pluralisation; `rrq_task_results()` always returns a list, while `rrq_task_result()` fetches a single task result).

```{r}
ok <- rrq_task_wait(ids)
result <- rrq_task_results(ids)
```

```{r, include = FALSE}
t1 <- Sys.time()
elapsed <- as.numeric(t1 - t0, "secs")
```

This process has taken `r round(elapsed, 2)` seconds, which is likely much faster than submitting this many tasks directly.

# Interprocess commuication pattern

You can submit a task to the cluster that accesses a pool of workers.  This is quite difficult to demonstrate in a clear way, but bear with us.

The general pattern we try to achieve here is this:

1. Submit a normal `hipercow` task to the cluster
2. This task distributes work over a set of workers; this might happen several times
3. Return some summary of this work from your main task

A practical example of this approach might be to submit a `hipercow` task that runs an orderly report and within that you run an MCMC where you send each chain to a different worker (which may each use multiple cores).  This gives you three levels of parallelism and the ability to span past a single node fairly easily.  Though you may need to use a pen and paper to keep track of what you're doing.

For this example, we'll use the "dide-windows" driver and submit work to a series of four workers running on Windows nodes on the DIDE cluster.

```{r, include = FALSE}
code <- c(
  "example <- function(n) {",
  "  ids <- rrq::rrq_task_create_bulk_call(sqrt, seq_len(n))",
  "  ok <- rrq::rrq_task_wait(ids)",
  "  stopifnot(ok)",
  "  result <- rrq::rrq_task_results(ids)",
  "  rrq::rrq_task_delete(ids)",
  "  sum(unlist(result))",
  "}")
writeLines(code, file.path(vignette_root, "code.R"))
```

We'll submit a `hipercow` task that runs this small piece of code:

```{r, echo = FALSE, results = "asis"}
r_output(readLines("code.R"))
```

Hopefully this is fairly self-explanatory, if a bit pointless.  Note that we delete the rrq tasks after completing them, which prevents rrq tasks accumulating.

This code needs to be available in the `hipercow` environment run by the task:

```{r}
hipercow_environment_create("default", sources = "code.R")
```

It would be nice if we had some more workers too; let's add a couple more:

```{r}
info <- hipercow_rrq_workers_submit(2, resources = resources)
```

now submit a task that will call this function:

```{r}
id <- task_create_expr(
  example(16),
  parallel = hipercow_parallel(use_rrq = TRUE),
  resources = resources)
id
```

Here, `id` is a *hipercow* task identifier.  This sends an additional task to the queue, so now we have five things running on the cluster (four workers and one task).  The task runs, picks up the controller, then uses it do distribute a (trivial) calculation over the four workers.

```{r}
task_wait(id)
task_result(id)
```

You can see from the worker logs here the tasks being split between the workers:

```{r}
rrq_worker_log_tail(n = 32)
```

This example is trivial, but you could submit 10 workers each using a 32 core node, and then use a single core task to farm out a series of large simulations across your bank of computers.  Or create a 500 single core workers (so ~25% of the cluster) and smash through a huge number of simulations with minimal overhead.

# Tricks and tips

This section will expand as we document patterns that have been useful.

## Controlling the worker environment

The workers will use the `rrq` environment if it exists, failing that the `default` environment.  So if you need different packages and sources loaded on the workers on your normal tasks, you can do this by creating a different environment

```{r}
hipercow_environment_create("rrq", packages = "cowsay")
```

You can submit your workers with any resources and parallel control you want (see `vignettes("parallel")` for details); pass these as `resources` and `parallel` to `hipercow_rrq_workers_submit()`.

# General considerations

## Stopping redundant workers

By default, workers will live for 10 minutes after finishing their last task.  This means that most of the time that you use workers you can largely forget about cleanup.  If you want be polite and give up these resources early (this would be important if you wanted to launch new workers, or if you were using a large fraction of the cluster), you can tell them to stop after completion of the last task:

```{r}
hipercow_rrq_stop_workers_once_idle()
```

## Permanence

You should not treat data in a submitted task as permanent; it is subject for deletion at any point!  So your aim should be to pull the data out of rrq as soon as you can.  Practically we won't delete data from the database for at least a few days after creation, but we make no guarantees.  We'll describe cleanup here later.

We reserve the right to delete things from the Redis database without warning, though we will try and be polite about doing this.

## Object storage

Redis is an *in memory* datastore, which means that all the inputs and outputs from your tasks are stored in memory on the head node.  This means that you do need to be careful about what you store as part of your tasks.  We will refuse to save any object larger than 100KB once serialised (approximately the size of a file created by `saveRDS()` without using compression).

We encourage you to make use of rrq's task deletion using `rrq::rrq_task_delete()` to delete tasks once you are done with them.  You can pass a long vector efficiently into this function.

If you need to save large outputs you will need to write them to a file (e.g., with `saveRDS()` rather than returning them from the function or expression set as the target of the rrq task.  If you are submitting a very large number of tasks that take a short and deterministic time to run this can put a lot of load on the file server, so be sure you are using a project share and not a personal share when using the DIDE cluster (see `vignette("dide-cluster")`).
