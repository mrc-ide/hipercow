[{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/articles/INLA.html","id":"latest-available-version-of-inla-for-your-r-version","dir":"Articles","previous_headings":"Local installations","what":"Latest available version of INLA for your R version","title":"Using INLA on Windows","text":"works. Right now, within R 4.4, get version 24.05.10, whereas R 4.3, get 24.05.01-1. exact version get recent version find R 4.4 R 4.3, folders even older R. latest version R, likely able get latest version INLA, INLA team make new releases latest R version. Therefore, really need latest INLA, must latest version R.","code":"install.packages(\"INLA\",    repos = c(getOption(\"repos\"),            INLA = \"https://inla.r-inla-download.org/R/stable\"),        dep = TRUE, type = \"binary\")"},{"path":"https://mrc-ide.github.io/hipercow/articles/INLA.html","id":"specific-version-of-inla-where-available-","dir":"Articles","previous_headings":"Local installations","what":"Specific version of INLA, where available.","title":"Using INLA on Windows","text":"install.packages allow us choose version, remotes::install_version works type=\"source\", may recall mentioning twice, succeed reasons. want specific version INLA, limited binaries INLA team made R version. look R 4.4 R 4.3 example, find desired version. R 4.3, INLA_23.09.09.zip looks nice. Download zip, use R CMD INSTALL INLA_23.09.09.zip - R, try:-","code":"tmpdir <- tempdir() version <- \"23.09.09\" file <- sprintf(\"INLA_%s.zip\", version) url <- sprintf(\"https://inla.r-inla-download.org/R/stable/bin/windows/contrib/4.3/%s\", file) tmpfile <- path.file(tmpdir, file) curl::curl_download(url, tmpfile) install.packages(tmpfile) unlink(tmpfile)"},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/articles/INLA.html","id":"latest-version-of-inla-for-latest-r-version-","dir":"Articles","previous_headings":"Hipercow provisioning","what":"Latest version of INLA for latest R version.","title":"Using INLA on Windows","text":"current latest R version 4.4. using version, can either use script pkgdepends method. pkgdepends, hipercow root can write pkgdepends.txt :- script method, instead write provision.R paste code install package, local install:- hipercow_provision() work usual way. See vignette(\"packages\") details.","code":"repo::https://inla.r-inla-download.org/R/stable INLA install.packages(\"INLA\",    repos = c(getOption(\"repos\"),            INLA = \"https://inla.r-inla-download.org/R/stable\"),        dep = TRUE, type = \"binary\")"},{"path":"https://mrc-ide.github.io/hipercow/articles/INLA.html","id":"latest-version-of-inla-for-older-r-version","dir":"Articles","previous_headings":"Hipercow provisioning","what":"Latest version of INLA for older R version","title":"Using INLA on Windows","text":", script method work , prefer pkgdepends, specific version want install, must recent version R version. R 4.3, pkgdepends.txt say:- latest version see .","code":"repo::https://inla.r-inla-download.org/R/stable INLA@24.05.01-01"},{"path":"https://mrc-ide.github.io/hipercow/articles/INLA.html","id":"specific-version-of-inla-where-available--1","dir":"Articles","previous_headings":"Hipercow provisioning","what":"Specific version of INLA, where available.","title":"Using INLA on Windows","text":"See instructions local installation, put code provision.R use script method hipercow_provision().","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/administration.html","id":"rebuilding-the-bootstrap-library","dir":"Articles","previous_headings":"","what":"Rebuilding the bootstrap library","title":"Administration","text":"Ensure packages built r-universe; might take little (rebuilds hour). Check builds page see updated. Install copy hipercow usual (’ll need hipercow.dide conan2 installed use don’t already). Set working directory anywhere network share (home drives fine ). Trigger building bootstrap : update versions cluster one minor version older recent. side effect changing Windows configuration wherever run command recent supported R version.","code":"install.packages(   c(\"hipercow\", \"hipercow.dide\"),   repos = c(\"https://mrc-ide.r-universe.dev\", \"https://cloud.r-project.org\")) hipercow.dide:::bootstrap_update_all()"},{"path":"https://mrc-ide.github.io/hipercow/articles/administration.html","id":"testing-a-copy-of-hipercow-on-the-cluster","dir":"Articles","previous_headings":"","what":"Testing a copy of hipercow on the cluster","title":"Administration","text":"want test copy hipercow cluster, need install specific version somewhere picked . simplest way install everything new bootstrap environment. Create new development bootstrap library running (, network location): Now can use new version, setting option hipercow.development = TRUE: assumed development version installed locally , likely case.","code":"hipercow::hipercow_init(\".\") hipercow::hipercow_configure(\"dide-windows\", r_version = \"4.3.0\") hipercow.dide:::bootstrap_update(development = \"mrc-4827\") library(hipercow) hipercow_init(\".\", \"dide-windows\", r_version = \"4.3.0\") # needs to match above options(hipercow.development = TRUE) id <- task_create_expr(sessionInfo()) task_status(id) task_log_show(id) task_status(id) task_result(id)"},{"path":"https://mrc-ide.github.io/hipercow/articles/administration.html","id":"recreating-the-vignettes","dir":"Articles","previous_headings":"","what":"Recreating the vignettes","title":"Administration","text":"need run network share set environment variable:- Windows, mapped drive, .Renviron indicating work. ’ll make lots directories . vignette can built running (ideally fresh session working directory package root) generates new dide-cluster.Rmd file within vignettes/ contains runnable code can safely run CI. packages.Rmd vignette requires rfiglet installed via remotes::install_github() set metadata automatic installation find correct source. vignette build fail early satisfied can fix . may want run options(hipercow.development = TRUE) build using development versions (see ). remaining vignettes use example driver can run independent actual cluster. command line, make vignettes run vignettes, seems work versions make.","code":"HIPERCOW_VIGNETTE_ROOT=/path/to/share HIPERCOW_VIGNETTE_ROOT=Q:/hipercow_vignettes hipercow.dide:::dide_check_credentials() knitr::knit(\"vignettes_src/dide-cluster.Rmd\", \"vignettes/dide-cluster.Rmd\") knitr::knit(\"vignettes_src/packages.Rmd\", \"vignettes/packages.Rmd\") knitr::knit(\"vignettes_src/workers.Rmd\", \"vignettes/workers.Rmd\") knitr::knit(\"vignettes_src/stan.Rmd\", \"vignettes/stan.Rmd\")"},{"path":"https://mrc-ide.github.io/hipercow/articles/administration.html","id":"rtools-java-support-and-r-versions-windows","dir":"Articles","previous_headings":"","what":"Rtools, Java support and R versions (Windows)","title":"Administration","text":"batch files specific version R support :- Set path Rscript.exe R version Set necessary environmental variables matching version RTools, RTOOLS43_HOME BINPREF. Set environment variable JAVA_HOME rJava package looks . batch files live \\\\projects.dide.ic.ac.uk\\software\\hpc\\R, called things like setr64_4_3_2.bat, looks like . get copied C:\\Windows cluster node, using HPC Cluster Manager. simply select nodes, right click, “Run Command”, look history previous copy commands, copy batch files %SystemRoot% - hence always path every node. also need edit permissions allow everyone read file, running cluster node:- also needs (manually) headnode, runs BuildQueue.","code":"@echo off IF EXIST I:\\rtools (set RTOOLS_DRIVE=I) else (set RTOOLS_DRIVE=T) FOR /f %%V in (%RTOOLS_DRIVE%:\\Java\\latest.txt) DO set JAVA_HOME=%RTOOLS_DRIVE%:\\Java\\%%V set RTOOLS43_HOME=%RTOOLS_DRIVE%:\\Rtools\\Rtools43 set BINPREF=%RTOOLS_DRIVE%:/Rtools/Rtools43/x86_64-w64-mingw32.static.posix/bin/ set path=%RTOOLS_DRIVE%:\\Rtools\\Rtools43\\usr\\bin;%RTOOLS_DRIVE%:\\Rtools\\Rtools43\\x86_64-w64-mingw32.static.posix\\bin;C:\\Program Files\\R\\R-4.3.2\\bin\\x64;%path%  echo Using RTOOLS43_HOME = %RTOOLS43_HOME% echo Using JAVA_HOME = %JAVA_HOME% cacls %SYSTEMROOT%\\setr64_*.bat /e /p everyone:r"},{"path":"https://mrc-ide.github.io/hipercow/articles/administration.html","id":"adding-r-versions","dir":"Articles","previous_headings":"Rtools, Java support and R versions (Windows)","what":"Adding R Versions","title":"Administration","text":"Download new R version \\\\projects\\software\\hpc\\R. Copy recent install_r_....bat file, name matching new R version. Edit ; usually just changing R_VERSION near top enough. Copy recent setr64_...bat file, name matching new R version. Usually just path enough, major versions, ’ll need consult documentation see need new RTools version . Run new install batch file cluster nodes. fi--didex1 edit C:\\xampp\\htdocs\\mrcdata\\hpc\\api\\v1\\cluster_software\\cluster_software.json add new version, perhaps remove retired ones.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/administration.html","id":"updating-rtools","dir":"Articles","previous_headings":"Rtools, Java support and R versions (Windows)","what":"Updating RTools","title":"Administration","text":"varies time, especially different major R versions. essentially:- local computer, install latest RTools sensible folder :\\rtools, : bootstrap share, \\wpia-hn rest done separate setr64_...bat files; review versions need new RTools.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/administration.html","id":"updating-java-support","dir":"Articles","previous_headings":"Rtools, Java support and R versions (Windows)","what":"Updating Java support","title":"Administration","text":"unlikely needed urgent sense, want new different version: Download JDK LTS zip file choice azul.com, favourite place OpenJDK builds. Unzip :\\Java, rename folder makes tidier version number, 21.0.2 Update :\\Java\\latest.txt contain new version string. JAVA_HOME point root Java JDK, rJava xlsx work happily.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/administration.html","id":"stan","dir":"Articles","previous_headings":"Rtools, Java support and R versions (Windows)","what":"stan","title":"Administration","text":"See vignette(\"stan\") general comments stan. update installation CmdStan :/ (generally available), run: Users run home directories installation 1GB influential environment variables set driver level prevent stan breaking Rtools installation (CMDSTAN CMDSTANR_USE_RTOOLS). details see: https://github.com/stan-dev/cmdstanr/issues/979 https://github.com/stan-dev/cmdstanr/pull/978 https://github.com/stan-dev/cmdstanr/pull/980","code":"hipercow::hipercow_init(driver = \"dide-windows\") hipercow.dide:::cmdstan_install()"},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"options","dir":"Articles","previous_headings":"","what":"Options","title":"Details","text":"influential options control hipercow behaviour, may want set wish depart defaults set. can set option within session using options() function, example want particular option persist sessions edit .Rprofile file, easily done using usethis::edit_r_profile().","code":"options(hipercow.progress = FALSE)"},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-auto_install_missing_packages","dir":"Articles","previous_headings":"Options > Influential options","what":"hipercow.auto_install_missing_packages","title":"Details","text":"Logical, controlling hipercow install missing packages needs machine. default TRUE, generally cause hipercow.dide conan2 installed first time try use hipercow.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-progress","dir":"Articles","previous_headings":"Options > Influential options","what":"hipercow.progress","title":"Details","text":"Logical, controlling display progress bar contexts (e.g., task_wait()). affects default behaviour hipercow function accepting progress argument, option becoming default value absence explicit argument. , can always disable individual progress bars option lets disable default. default value option TRUE (.e., display progress bars default).","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-timeout","dir":"Articles","previous_headings":"Options > Influential options","what":"hipercow.timeout","title":"Details","text":"Numeric, controlling default timeout task_wait(), task_log_watch() , hipercow_bundle_wait() hipercow_hello(). set, default Inf (.e., wait forever).","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-validate_globals","dir":"Articles","previous_headings":"Options > Influential options","what":"hipercow.validate_globals","title":"Details","text":"Logical, controlling validate value “global” variables task starts. TRUE, save task (e.g., task_create_expr()) created environment hipercow_environment_create() specified values globals argument, hash values find current session task starts cluster validate values find local session. default FALSE (.e., validation done).","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-max_size_local","dir":"Articles","previous_headings":"Options > Influential options","what":"hipercow.max_size_local","title":"Details","text":"number, maximum size object (bytes) save creating task (e.g., task_create_expr()). save task need save local variables reference call; often small ’s problem. However, pass 5GB shapefile end filling disk copies file, task spend lot time reading writing . ’s usually better arrange large objects found scripts via environment. default value 1e6 (1,000,000 bytes, 1 MB). Set Inf disable check.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-default_envvars","dir":"Articles","previous_headings":"Options > Influential options","what":"hipercow.default_envvars","title":"Details","text":"hipercow_envvars object, environment variables added every task created. Hipercow sets environment variables default improve user experience. variables can overridden per-task passing envvars parameter creating tasks, globally defining option. Environment variables task computed collecting (increasing order preference): hipercow default environment variables (defined hipercow:::DEFAULT_ENVVARS); currently R_GC_MEM_GROW=3 driver-specific variables (defined default_envvars argument hipercow_driver); see vignette(\"dide-cluster\") defaults specific DIDE cluster user-set option hipercow.default_envvars argument envvars task creation function Environment variables set later override earlier.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-development","dir":"Articles","previous_headings":"Options > Influential options","what":"hipercow.development","title":"Details","text":"Use development library (exists) bootstrapping. may ask set temporarily diagnosing bug . Don’t set generally library often exist, date!","code":""},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-timeout-1","dir":"Articles","previous_headings":"Options > DIDE options","what":"hipercow.timeout","title":"Details","text":"number, representing seconds, timing performing web requests. default 10s chosen poorly may need increase decrease .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"rrq-options","dir":"Articles","previous_headings":"Options","what":"rrq options","title":"Details","text":"options relevant using hipercow rrq integration.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"hipercow-rrq_offload_threshold_size","dir":"Articles","previous_headings":"Options > rrq options","what":"hipercow.rrq_offload_threshold_size","title":"Details","text":"Objects passed rrq tasks usually stored Redis. However since stored memory, larger objects offloaded disk instead. option controls threshold used decide whether offload objects. Objects larger configured value (bytes) offloaded disk. default value 100000, .e., 100kB. option used queue first created. Changing afterwards effect.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"options-from-other-packages","dir":"Articles","previous_headings":"Options","what":"Options from other packages","title":"Details","text":"make heavy use cli package, see documentation options. Particular options might care : cli.progress_show_after: Delay seconds showing progress bar; might reduce make bars appear quickly. cli.progress_clear: Retain progress bar screen completion.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"setting-options","dir":"Articles","previous_headings":"Options","what":"Setting options","title":"Details","text":"can set options either within session using options() function future sessions editing .Rprofile. Changing option options() looks like: might put top cluster script affect future tasks submit within session run . ’ll probably run line next time, effect . won’t affect project. always want value, can add .Rprofile. easiest way using usethis package running: adding call options() anywhere file. comfortable using (exiting) vi command line may prefer using vi ~/.Rprofile. changing .Rprofile need restart R changes take effect. can set multiple options want running (example):","code":"options(hipercow.max_size_local = 1e7) usethis::edit_r_profile() options(   hipercow.progress = FALSE,   hipercow.max_size_local = 1e-7)"},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"r-versions","dir":"Articles","previous_headings":"","what":"R versions","title":"Details","text":"default, try track “suitable” copy R based current version. try use exactly version available, otherwise oldest cluster version newer , failing recent cluster version. can control R version used configuring; example use 4.3.0 exactly can use: every minor version installed, available versions may differ dide-windows dide-linux. version close enough need. Try use versions one “minor” version old (middle version number). can see current version CRAN’s landing page. 4.3.x versions 4.2.x 4.3.x series likely work well , 4.1.x earlier work well binary versions packages longer available packages start depending features present newer versions, may available.","code":"hipercow_configure(\"dide-windows\", r_version = \"4.3.0\")"},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"long-running-tasks","dir":"Articles","previous_headings":"Workflow considerations","what":"Long running tasks","title":"Details","text":"R session use send tasks cluster important; directory send tasks. can stop R session, reboot computer shut laptop tasks keep running (keep waiting cluster pick ). come back working directory later can ask task’s status, fetch results etc easily.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/details.html","id":"disk-space","dir":"Articles","previous_headings":"Workflow considerations","what":"Disk space","title":"Details","text":"run disk space, terrible things happen, error messages get may misleading. Worse, may run space, space gets freed ’s obvious original problem . underlying reason store information state tasks network share; run space writing final result task, task remain running indefinitely fail write succeeded.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"pre-requisites-","dir":"Articles","previous_headings":"","what":"Pre-requisites:-","title":"The DIDE Cluster","text":"short, need: know DIDE username password added DIDE cluster user connected DIDE network, (probably using ZScaler) working directory network share cluster can see explained detail . satisfied, can initialise hipercow using hipercow_init() use dide_check() verify everything works, hipercow_hello() submit test task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"authentication-with-dide","dir":"Articles","previous_headings":"","what":"Authentication with DIDE","title":"The DIDE Cluster","text":"First run dide_authenticate() function talk entering credentials checking work. need per machine, time change password. typical interaction looks like: hit problems, try going https://mrcdata.dide.ic.ac.uk/hpc trying combinations remember . done update password manager (perhaps BitWarden?) can find easily next time. possible access cluster, even username correct. Try logging onto portal; reports don’t access please request access messaging Wes. don’t know username password, read .","code":"> dide_authenticate() I need to unlock the system keychain in order to load and save your credentials.  This might differ from your DIDE password, and will be the password you use to log in to this particular machine Keyring password: 🔑  OK  ── Please enter your DIDE credentials ────────────────────────── We need to know your DIDE username and password in order to log you into the cluster. This will be shared across all projects on this machine, with the username and password stored securely in your system keychain. You will have to run this command again on other computers  Your DIDE password may differ from your Imperial password, and in some cases your username may also differ. If in doubt, perhaps try logging in at https://mrcdata.dide.ic.ac.uk/hpc and use the combination that works for you there.  DIDE username (default: rfitzjoh) > Password: 🔑  OK  I am going to try and log in with your password now, if this fails we can always try again, as failure is just the first step towards great success. Excellent news! Everything seems to work!"},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"about-our-usernames-and-passwords","dir":"Articles","previous_headings":"Authentication with DIDE","what":"About our usernames and passwords","title":"The DIDE Cluster","text":"historical reasons DIDE exists domain (DIDE) separate Imperial’s domain (IC). means may different DIDE username Imperial username (though usually ) may different password (though people set ). overall situation summarised infographic:  need change DIDE password can DIDE domain machine pressing Ctrl-Alt-Delete following prompts. already expired, can’t login, need contact Chris Paul. store credentials using keyring package. saves username password securely system keyring, unlocked login least Windows macOS. need rerun dide_authenticate() whenever change DIDE password. Linux users may install additional system packages (Ubuntu/Debian etc libsecret-1-dev, libssl-dev, libsodium-dev) enter keychain password time use hipercow.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"networks","dir":"Articles","previous_headings":"","what":"Networks","title":"The DIDE Cluster","text":"Ensure connected DIDE network using ZScaler; see instructions ICT, desktop PC virtual machine within building plugged Ethernet (less common now). Note connected WiFi building enough - need ZScaler.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"filesystems-and-paths","dir":"Articles","previous_headings":"","what":"Filesystems and paths","title":"The DIDE Cluster","text":"anything work hipercow DIDE cluster, working directory must network share. sure network share, run Interpreting depends platform (machine typing commands ): Windows: drive like C: D: local. recognise drive letter one like Q: mapped default home M: mapped project share. macOS: path likely /Volumes (one corresponds USB stick course!) Linux: path start one mount points configured /etc/fstab network path.","code":"getwd()"},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"cluster-based-storage-and-home-directories","dir":"Articles","previous_headings":"Filesystems and paths","what":"Cluster-based storage and home directories","title":"The DIDE Cluster","text":"strongly recommend use cluster-based storage serious work. servers hosting shares start wpia-hn, use rather home directory (servers called qdrive, wpia-san04), temp drive departmental project shares (servers starting wpia-didef4 projects). advantages cluster-based shares larger (run disk space slowly) faster others. launch many tasks use home share can get unexpected failures disk can’t keep amount data read written. Don’t use home directory (generally Q: Windows) anything intensive casual experimentation. seen many people jobs fail mysteriously network home directory launched parallel, generally fixed using cluster share. don’t know access cluster-based share, talk PI one exists . PI, talk Chris (/Wes) getting one set .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"mapping-network-drives-on-your-computer","dir":"Articles","previous_headings":"Filesystems and paths","what":"Mapping network drives on your computer","title":"The DIDE Cluster","text":"operating systems, need connected DIDE departmental domain. Options :- outside department, using ZScaler see ICT documentation details. inside department wifi, also need ZScaler connected. inside department wired network. fastest stable network, giving best experience available . , instructions setting depend sort computer typing commands moment (cluster type). ’re going use example mapping home directory ; said earlier, isn’t recommended proper cluster running, everyone home share, can use example.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"windows","dir":"Articles","previous_headings":"Filesystems and paths > Mapping network drives on your computer","what":"Windows","title":"The DIDE Cluster","text":"using Windows machine DIDE domain, home drive (Q:) temp drive (T:) likely already mapped . fully-qualified network name current working directory, although Windows can load files fully-qualified network name, results always might hope. need map another drive, ’re DIDE domain, :- DIDE domain, fire ZScaler (IC credentials) Open PC, Computer tab, find Map network drive. drops reveal another Map network drive button. Choose drive letter - arbitrary, conventions Q: home drive, T: temp drive. Please avoid using : use Hipercow internally, anything D: likely clash system. Set fully-qualified network share; example \\\\qdrive.dide.ic.ac.uk\\homes\\bob Tick “Connect using different credentials”, “Reconnect sign-”. Click Finish, credentials window, choose “choices”, “Use different account”. Specify username including domain - DIDE\\bob example, DIDE password. Choose “Remember ” ’re happy , “OK” drive get mapped.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"macos","dir":"Articles","previous_headings":"Filesystems and paths > Mapping network drives on your computer","what":"macOS","title":"The DIDE Cluster","text":"Finder, go Go -> Connect Server... press Command-K. address field write name share want connect . DIDE username bob, ’ll write: work Bob’s home share. get message saying “attempt connect server”qdrive.dide.ic.ac.uk” press Connect continue. , credentials page, ’ll select Registered User (guest), username, example DIDE\\bob ’ll provide DIDE password. may like tick “Remember password” ’re happy . directory mounted /Volumes/bob - , last folder fully-qualified domain name provide becomes name local mountpoint within /Volumes). may better way , connection re-established automatically anyone better way let us know.","code":"smb://qdrive.dide.ic.ac.uk/homes/bob"},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"linux","dir":"Articles","previous_headings":"Filesystems and paths > Mapping network drives on your computer","what":"Linux","title":"The DIDE Cluster","text":"current understanding best way. Full instructions Ubuntu community wiki. First, install cifs-utils /etc/fstab file, add : <dide-username> DIDE username without DIDE\\ bit. <local-username> local username (.e., echo $USER). <local-userid> local numeric user id (.e. id -u $USER) <local-groupid> local numeric group id (.e. id -g $USER) <home-mount-point> want DIDE home directory mounted please back file editing. example Rich - local Linux user rich, DIDE username rfitzjoh, uid gid looked :- file .smbcredentials contains set chmod 600 modicum security, aware password stored plaintext. set clearly insecure. believe omit credentials line can system prompt password interactively, ’m sure works automatic mounting. Finally, run mount drives luck work don’t get new computer. laptop regularly connected internal network, might want add option noauto explicitly mount drive required ","code":"sudo apt-get install cifs-utils //qdrive.dide.ic.ac.uk/homes/<dide-username> <home-mount-point> cifs uid=<local-userid>,gid=<local-groupid>,credentials=/home/<local-username>/.smbcredentials,domain=DIDE,sec=ntlmssp,iocharset=utf8 0  0 //qdrive.dide.ic.ac.uk/homes/rfitzjoh /home/rich/net/home cifs uid=1000,gid=1000,credentials=/home/rich/.smbcredentials,domain=DIDE,sec=ntlmssp,iocharset=utf8 0  0 username=<dide-username> password=<dide-password> sudo mount -a //qdrive.dide.ic.ac.uk/homes/rfitzjoh /home/rich/net/home cifs uid=1000,gid=1000,credentials=/home/rich/.smbcredentials,domain=DIDE,sec=ntlmssp,iocharset=utf8,noauto 0  0 sudo mount ~/net/home"},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"initialisation","dir":"Articles","previous_headings":"","what":"Initialisation","title":"The DIDE Cluster","text":"use, sufficient write , example want run jobs Windows nodes. Instead, additionally, configure dide-linux indicate ’d like run jobs Linux nodes. Configuring drivers fine project may want launch platforms. configure , ’ll specific want use provisioning task creation, whereas ’s one driver, used default. see workflow prefer, whether root, keeping things separate. examples vignettes assume one driver configured, won’t see driver argument explicitly set. One thing: using single driver, can combine init configure , example, hipercow_init(\"dide-windows\"). default, aim automatically detect shares, believe works Windows, macOS Linux. running network share configuration errors work share , please let us know.","code":"library(hipercow) hipercow_init() #> ✔ Initialised hipercow at '.' (/home/rfitzjoh/net/home/cluster/hipercow-vignette/hv-20250423-7d83f6872b6bb) #> ℹ Next, call 'hipercow_configure()' hipercow_configure(driver = \"dide-windows\") #> ✔ Configured hipercow to use 'dide-windows'"},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"does-it-work","dir":"Articles","previous_headings":"","what":"Does it work?","title":"The DIDE Cluster","text":"steps can checked automatically: Try test task: See overall configuration (often ask ):","code":"library(hipercow) hipercow_init(driver = \"dide-windows\") #> ℹ hipercow already initialised at '.' (/home/rfitzjoh/net/home/cluster/hipercow-vignette/hv-20250423-7d83f6872b6bb) #> ℹ Configuration for 'dide-windows' unchanged dide_check() #> ✔ Found DIDE credentials for 'rfitzjoh' #> ✔ DIDE credentials are correct #> ✔ Connection to private network working #> ✔ Path looks like it is on a network share #> ℹ Using '/home/rfitzjoh/net/home/cluster/hipercow-vignette/hv-20250423-7d83f6872b6bb' #> ✔ 'hipercow' and 'hipercow.dide' versions agree (1.1.3) hipercow_hello() #> ✔ Found DIDE credentials for 'rfitzjoh' #> ✔ DIDE credentials are correct #> ✔ Connection to private network working #> ✔ Path looks like it is on a network share #> ℹ Using '/home/rfitzjoh/net/home/cluster/hipercow-vignette/hv-20250423-7d83f6872b6bb' #> ✔ 'hipercow' and 'hipercow.dide' versions agree (1.1.3) #> ✔ Submitted task 'f9e8fa83205e66ef9cd8bd7f3ff1e549' using 'dide-windows' #>  #> ── hipercow 1.0.55 running at 'V:/cluster/hipercow-vignette/hv-20250423-7d83f687 #> ℹ library paths: #> • #> V:/cluster/hipercow-vignette/hv-20250423-7d83f6872b6bb/hipercow/lib/windows/4.4.2 #> • I:/bootstrap-windows/4.4.2 #> • C:/Program Files/R/R-4.4.2/library #> ℹ id: f9e8fa83205e66ef9cd8bd7f3ff1e549 #> ℹ starting at: 2025-04-23 10:57:58.901961 #> ℹ Task type: expression #> • Expression: { [...] #> • Locals: moo #> • Environment: default #>   R_GC_MEM_GROW: 3 #>   CMDSTAN: I:/cmdstan/cmdstan-2.35.0 #>   CMDSTANR_USE_RTOOLS: TRUE #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #>  ----- #> Moooooo! #>  ------ #>     \\   ^__^ #>      \\  (oo)\\ ________ #>         (__)\\         )\\ /\\ #>              ||------w| #>              ||      || #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✔ status: success #> ℹ finishing at: 2025-04-23 10:57:58.901961 (elapsed: 0.5092 secs) #> ✔ Successfully ran test task 'f9e8fa83205e66ef9cd8bd7f3ff1e549' hipercow_configuration() #>  #> ── hipercow root at /home/rfitzjoh/net/home/cluster/hipercow-vignette/hv-20250423-7d83f6872b6bb ───────── #> ✔ Working directory '.' within root #> ℹ R version 4.4.2 on Linux (rfitzjoh@wpia-dide300) #>  #> ── Packages ── #>  #> ℹ This is hipercow 1.1.3 #> ℹ Installed: hipercow.dide (1.1.3), conan2 (1.9.101), logwatch (0.1.1), rrq (0.7.22) #>  #> ── Environments ── #>  #> ── default #> • packages: (none) #> • sources: (none) #> • globals: (none) #>  #> ── empty #> • packages: (none) #> • sources: (none) #> • globals: (none) #>  #> ── Drivers ── #>  #> ✔ 1 driver configured ('dide-windows') #>  #> ── dide-windows #> • cluster: wpia-hn #> • shares: 1 configured: #> → (local) /home/rfitzjoh/net/home => \\\\qdrive.dide.ic.ac.uk\\homes\\rfitzjoh => V: (remote) #> • r_version: 4.4.2 #> • path_lib: hipercow/lib/windows/4.4.2 #> • platform: windows #> • username: rfitzjoh"},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"the-dide-cluster","dir":"Articles","previous_headings":"","what":"The DIDE Cluster","title":"The DIDE Cluster","text":"one MS-HPC (think Azure) cluster called wpia-hn hosted South Kensington, built mainly recent 32-core, 512Gb nodes, older still capable nodes. running Windows, MS-HPC can also attach Linux nodes, now begun supporting. Please let us now get .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"default-environment-variables","dir":"Articles","previous_headings":"The DIDE Cluster","what":"Default environment variables","title":"The DIDE Cluster","text":"","code":"#>                  name                     value #> 1             CMDSTAN I:/cmdstan/cmdstan-2.35.0 #> 2 CMDSTANR_USE_RTOOLS                      TRUE"},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"the-nodes","dir":"Articles","previous_headings":"The DIDE Cluster","what":"The Nodes","title":"The DIDE Cluster","text":"hipercow root just made, can look cluster like hipercow_cluster_info(). gives us information can use hipercow_resources request particular resources. See vignette(\"parallel\") information. Nodes: present around 70 nodes, numbered wpia-xxx - gaps nodes experimental, serving purposes cluster moment. Cores: present, largest node cluster 32 cores - fact nodes . change grow cluster, now, nodes similar. 32-core nodes favourite compromise moment power usage, computational speed, density, physical space limited. Memory: nodes 512Gb RAM; nodes 059-070 slightly smaller 384Gb. change; larger nodes may arrive, may try beef older nodes ensure enough RAM per job. Queues: Windows nodes, unfortunate legacy AllNodes queue used; Linux LinuxNodes. additional node currently reserved Training development, come hipercow workshop, likely submit small jobs one. driver (Windows Linux) default queue set, jobs run appropriate nodes without anything. may add different queues subset nodes different capabilities, case may appear. R versions: can see R versions supported cluster nodes, including recent, couple older versions. generally try support current previous versions R. ’s good idea keep --date. redis URL something need anything moment.","code":"hipercow_cluster_info() #> $resources #> $resources$name #> [1] \"wpia-hn\" #>  #> $resources$node_os #> [1] \"windows\" #>  #> $resources$max_cores #> [1] 32 #>  #> $resources$max_ram #> [1] 512 #>  #> $resources$queues #> [1] \"AllNodes\" \"Testing\"  #>  #> $resources$default_queue #> [1] \"AllNodes\" #>  #> $resources$build_queue #> [1] \"BuildQueue\" #>  #> $resources$testing_queue #> [1] \"Testing\" #>  #> $resources$redis_url #> [1] \"wpia-hn.hpc.dide.ic.ac.uk\" #>  #> $resources$nodes #>  [1] \"wpia-001\" \"wpia-002\" \"wpia-003\" \"wpia-004\" \"wpia-005\" \"wpia-006\" #>  [7] \"wpia-007\" \"wpia-008\" \"wpia-009\" \"wpia-010\" \"wpia-011\" \"wpia-012\" #> [13] \"wpia-013\" \"wpia-014\" \"wpia-015\" \"wpia-016\" \"wpia-017\" \"wpia-018\" #> [19] \"wpia-019\" \"wpia-020\" \"wpia-021\" \"wpia-022\" \"wpia-023\" \"wpia-024\" #> [25] \"wpia-025\" \"wpia-026\" \"wpia-027\" \"wpia-028\" \"wpia-029\" \"wpia-030\" #> [31] \"wpia-031\" \"wpia-032\" \"wpia-033\" \"wpia-034\" \"wpia-035\" \"wpia-036\" #> [37] \"wpia-037\" \"wpia-038\" \"wpia-039\" \"wpia-040\" \"wpia-043\" \"wpia-044\" #> [43] \"wpia-045\" \"wpia-046\" \"wpia-047\" \"wpia-048\" \"wpia-051\" \"wpia-052\" #> [49] \"wpia-053\" \"wpia-054\" \"wpia-055\" \"wpia-056\" \"wpia-057\" \"wpia-058\" #> [55] \"wpia-059\" \"wpia-060\" \"wpia-061\" \"wpia-062\" \"wpia-063\" \"wpia-064\" #> [61] \"wpia-065\" \"wpia-066\" \"wpia-067\" \"wpia-068\" \"wpia-069\" \"wpia-070\" #> [67] \"wpia-071\" \"wpia-072\" \"wpia-073\" \"wpia-074\" \"wpia-075\" \"wpia-076\" #> [73] \"wpia-077\" \"wpia-078\" \"wpia-079\" \"wpia-080\" \"wpia-081\" \"wpia-082\" #>  #>  #> $r_versions #> [1] '4.2.3' '4.3.0' '4.3.2' '4.3.3' '4.4.0' '4.4.1' '4.4.2' '4.4.3' #>  #> $redis_url #> [1] \"wpia-hn.hpc.dide.ic.ac.uk\""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"cluster-storage","dir":"Articles","previous_headings":"The DIDE Cluster","what":"Cluster Storage","title":"The DIDE Cluster","text":"headnode, wpia-hn.hpc.dide.ic.ac.uk storage connected cluster nodes via fast InfiniBand network. cluster nodes talk share, use infiniband without anything special. storage can also mapped (mounted) can see files desktop laptop, just standard network speed. ’ll need access share drive - talk PI - follow instructions earlier vignette map . important thing definitely use storage possible cluster tasks significant amount file reading writing, ’s highly recommended use work using cluster. Also, refer data cluster storage within task, one area ’ll something different targeting Windows cluster nodes, compared Linux cluster nodes. ’ve already talked mapping, mounting, referring DIDE shares local computer. need talk referring within cluster job, might running Windows, Linux.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"cluster-storage-on-windows-compute-nodes","dir":"Articles","previous_headings":"The DIDE Cluster > Cluster Storage","what":"Cluster Storage on Windows Compute nodes","title":"The DIDE Cluster","text":"can refer DIDE network shares using fully-qualified network paths, file home directory want read R Windows node, can write:- write local Windows computer. work small tasks, ’ve said, use large volumes /O. Instead share cluster-storage. Furthermore, referring cluster-storage within cluster job, refer wpia-hn wpia-hn-app ensure use fast Infiniband network connection get data. example, data refer Windows local computer //wpia-hn.hpc.dide.ic.ac.uk/flu-project/data.dat, access data cluster job, write //wpia-hn-app/flu-project/data.dat.","code":"x <- readLines(\"//qdrive.dide.ic.ac.uk/homes/wes/hello.txt\")"},{"path":"https://mrc-ide.github.io/hipercow/articles/dide-cluster.html","id":"cluster-storage-on-linux-compute-nodes","dir":"Articles","previous_headings":"The DIDE Cluster > Cluster Storage","what":"Cluster Storage on Linux Compute nodes","title":"The DIDE Cluster","text":"access network paths directly; need explicitly mounted, hard reliably within cluster job. therefore mounted main cluster shares cluster nodes advance, read/write access machine. need refer network shares right way. Specifically:- refer file home directory (example, //qdrive.dide.ic.ac.uk/homes/wes/hello.txt) within cluster job Linux node, write /didehomes/wes/hello.txt - noting yet : recommend using home directories significant data tasks. refer data cluster share (example, //wpia-hn.hpc.dide.ic.ac.uk/flu-project/data.dat) Linux cluster job, write /wpia-hn/flu-project/data.dat. already wired use fast network connection. find data expecting, get touch Wes; data moved around partly prepare Linux, partly departmental relocation, data appearing dormant yet migrated.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/environments.html","id":"basics","dir":"Articles","previous_headings":"","what":"Basics","title":"Environments","text":"two main things make “environment”: set packages like attached (loaded via library()) set source files like loaded session (via source()) can anything want within source file (including loading packages!) flexible. ’s going default environment: can see attached packages (packages loaded via library whose functions available) couple extra loaded packages, examplehipercow dependencies cli (packages R loaded functions available without ::). objects field shows objects loaded session; empty session nothing .","code":"id <- task_create_expr(list(session = sessionInfo(), objects = ls())) #> ✔ Submitted task '6522711e8e0f59b31975df1178c2e800' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> $session #> R version 4.5.0 (2025-04-11) #> Platform: x86_64-pc-linux-gnu #> Running under: Ubuntu 24.04.2 LTS #>  #> Matrix products: default #> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  #> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 #>  #> locale: #>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        #>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    #>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           #> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    #>  #> time zone: UTC #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> loaded via a namespace (and not attached): #> [1] compiler_4.5.0 cli_3.6.5      withr_3.0.2    hipercow_1.1.5 rlang_1.1.6    #>  #> $objects #> character(0)"},{"path":"https://mrc-ide.github.io/hipercow/articles/environments.html","id":"loading-packages","dir":"Articles","previous_headings":"Basics","what":"Loading packages","title":"Environments","text":"code might want use functions package. example, might want use say function cowsay package task fails error message indicates problem: say() function found. run cowsay::say might inconvenient just prefer . need arrange library(cowsay) run trying run expression. , update default environment: time task succeeds: Looking logs, can see glorious output task: can also see logs say: task starts , runs code, loaded default attached cowsay. can see default environment using hipercow_environment_show() prints information. can list many packages want, loaded order.","code":"id <- task_create_expr(say(\"Moooo\", by = \"cow\")) #> ✔ Submitted task '84e68280c55ebb806a853de38ac515ee' using 'example' task_wait(id) #> [1] FALSE task_result(id) #> <simpleError in say(\"Moooo\", by = \"cow\"): could not find function \"say\"> hipercow_environment_create(packages = \"cowsay\") #> ✔ Created environment 'default' id <- task_create_expr(say(\"Moooooo\", by = \"cow\")) #> ✔ Submitted task '3ce306e52326523f371c02040ac86498' using 'example' task_wait(id) #> [1] FALSE task_log_show(id) #>  #> ── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-2f9b482552ec'  #> ℹ library paths: #> • /home/runner/work/_temp/Library #> • /opt/R/4.5.0/lib/R/site-library #> • /opt/R/4.5.0/lib/R/library #> ℹ id: 3ce306e52326523f371c02040ac86498 #> ℹ starting at: 2025-05-13 06:44:28.836511 #> ℹ Task type: expression #> • Expression: say(\"Moooooo\", by = \"cow\") #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ℹ Loading environment 'default'... #> • packages: cowsay #> • sources: (none) #> • globals: (none) #> ✖ status: failure #> ✖ Error: there is no package called ‘cowsay’ #> ℹ finishing at: 2025-05-13 06:44:28.836511 (elapsed: 0.307 secs) ℹ Loading environment 'default'... • packages: cowsay • sources: (none) • globals: (none) hipercow_environment_show(\"default\") #>  #> ── hipercow environment 'default' ────────────────────────────────────────────── #> • packages: cowsay #> • sources: (none) #> • globals: (none)"},{"path":"https://mrc-ide.github.io/hipercow/articles/environments.html","id":"loading-your-own-functions","dir":"Articles","previous_headings":"Basics","what":"Loading your own functions","title":"Environments","text":"Now, suppose want change length moo cow produces. might write function. Ignoring cluster minute, wanted use code ordinarily use source load : need thing cluster, default found: error , consequence different - code present. update environment call add moo.R: (note replaces previous definition default). Now, can run task: can list many source files want. brave, use dir() : load .R files within directory R/ hipercow root. careful start recursively loading files though; happen included source() commands within R files , followed, result cycle.","code":"moo <- function(n) {   sprintf(\"M%s!\", strrep(\"o\", n)) } source(\"moo.R\") moo(5) #> [1] \"Mooooo!\" id <- task_create_expr(say(moo(5), by = \"cow\")) #> ✔ Submitted task 'a97aa1e118d79622616cae6c6e57f120' using 'example' task_wait(id) #> [1] FALSE task_result(id) #> <packageNotFoundError in library(p, character.only = TRUE): there is no package called ‘cowsay’> hipercow_environment_create(packages = \"cowsay\", sources = \"moo.R\") #> ✔ Updated environment 'default' id <- task_create_expr(say(moo(5), by = \"cow\")) #> ✔ Submitted task '65bffdad1d63b64caef0f1ab355b3078' using 'example' task_wait(id) #> [1] FALSE task_log_show(id) #>  #> ── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-2f9b482552ec'  #> ℹ library paths: #> • /home/runner/work/_temp/Library #> • /opt/R/4.5.0/lib/R/site-library #> • /opt/R/4.5.0/lib/R/library #> ℹ id: 65bffdad1d63b64caef0f1ab355b3078 #> ℹ starting at: 2025-05-13 06:44:31.367247 #> ℹ Task type: expression #> • Expression: say(moo(5), by = \"cow\") #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ℹ Loading environment 'default'... #> • packages: cowsay #> • sources: moo.R #> • globals: (none) #> ✖ status: failure #> ✖ Error: there is no package called ‘cowsay’ #> ℹ finishing at: 2025-05-13 06:44:31.367247 (elapsed: 0.3051 secs) hipercow_environment_create(   sources = dir(glob2rx(\"R/\", pattern = \"*.R\", full.names = TRUE)))"},{"path":"https://mrc-ide.github.io/hipercow/articles/environments.html","id":"defining-globals","dir":"Articles","previous_headings":"","what":"Defining globals","title":"Environments","text":"advanced use environments load large objects ready task runs. Suppose large object need work , example large loaded geojson file fit model run, want run function . obvious thing write: myfn analysis function my_big_data large object another_argument argument ’re passing call , hipercow save inputs disk, quite big. even worse part bulk call, multiple copies may saved. problem can bad prevent default: , get object session? Suppose read_big_data() function used read object first place. might write source file data.R (name important): add sources, also add my_big_data globals. tells hipercow object my_big_data globally available sees expression create try save : can now create task run : use approach, aware things: default, guarantee object see creating task object loaded sources. can enable setting option hipercow.validate_globals (see vignette(\"details\")) generally load (via source()) data local session know working cluster Don’t update definitions files source tasks running get confused loaded","code":"myfn(my_big_data, another_argument) task_create_expr(length(my_big_data)) #> Error in `task_create_expr()`: #> ! Object too large to save with task: 'my_big_data' #> ✖ Objects saved with a hipercow task can only be 1 MB #> ℹ You can increase the limit by increasing the value of the option #>   'hipercow.max_size_local', even using 'Inf' to disable this check entirely #>   (see the `vignette(hipercow::details)` vignette) #> ℹ Better again, create large objects from your 'sources' argument to your #>   environment, and then advertise this using the 'globals' argument (see the #>   `vignette(hipercow::environments)` vignette) my_big_data <- read_big_data(\"bigfile.shp\") hipercow_environment_create(sources = \"data.R\", globals = \"my_big_data\") #> ✔ Updated environment 'default' id <- task_create_expr(length(my_big_data)) #> ✔ Submitted task 'd436201fcba21c066854ea5a3ad6990c' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] 1000000"},{"path":"https://mrc-ide.github.io/hipercow/articles/environments.html","id":"other-points","dir":"Articles","previous_headings":"","what":"Other points","title":"Environments","text":"Don’t rely environment submitted tasks load , change environment. , don’t write: second call hipercow_environment_create overwrites default environment, first task started yet, load second environment first! can many named environments want, might write :","code":"hipercow_environment_create(packages = \"pkg.a\") task_create_expr(use_pkg_a()) hipercow_environment_create(packages = \"pkg.b\") task_create_expr(use_pkg_b()) hipercow_environment_create(packages = \"pkg.a\", name = \"env_a\") task_create_expr(use_pkg_a(), environment = \"env_a\") hipercow_environment_create(packages = \"pkg.b\", name = \"env_a\") task_create_expr(use_pkg_b(), environment = \"env_b\")"},{"path":"https://mrc-ide.github.io/hipercow/articles/environments.html","id":"relationship-with-provisioning","dir":"Articles","previous_headings":"","what":"Relationship with provisioning","title":"Environments","text":"provision, install packages. defines set packages available, none loaded default. able load package installed via library(), access functions using namespace operator ::, default normal minimal set packages loaded. specify packages within provision script load , ’s fine - packages exist library may used. use packages environment provision, task fail start package found. provision set packages, provisions dependencies. people add tidyverse pkgdepends.txt, use (say) ggplot2 environment dependency tidyverse. fine.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"clusters-and-platforms","dir":"Articles","previous_headings":"","what":"Clusters and Platforms","title":"hipercow","text":"documentation, cluster, mean really head-node. support one moment: DIDE cluster. future, might also support PBS cluster ICT run, might create pure Linux cluster SLURM headnode instance. yet. platform, mean operating system. can use hipercow computer, whether runs Windows, Linux MacOS. differences operating systems, mostly refer DIDE network paths appear computer (ie, drive letters mountpoints), hipercow tries handle without fuss. recently, jobs run Windows cluster nodes. However, unusually (perhaps interestingly), DIDE cluster runs Microsoft HPC, can Linux-based Windows-based nodes attached , using basic launch tools either. interesting, since can allow Linux jobs run, launch mechanism extremely similar might already familiar hipercow. throughout documentation, refer one cluster, (DIDE cluster), supporting two target platforms - compute nodes running Windows Linux. Please feedback experiences especially Linux nodes, new ’d like know workflows work well .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"installing-prerequisites","dir":"Articles","previous_headings":"","what":"Installing prerequisites","title":"hipercow","text":"Install required packages “r-universe”. sure run fresh session. installed can load package use package prefixing calls hipercow::, prefer. Follow cluster-specific instructions vignettes(\"<cluster>\"); depend cluster intend use - present just DIDE cluster. DIDE Cluster: vignette(\"dide-cluster\")","code":"install.packages(   \"hipercow\",   repos = c(\"https://mrc-ide.r-universe.dev\", \"https://cloud.r-project.org\")) library(hipercow)"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"filesystems-and-paths","dir":"Articles","previous_headings":"","what":"Filesystems and paths","title":"hipercow","text":"need concept “root”; point filesystem can think everything relative . feel familiar used git orderly, root (root fine place put cluster work). Typically paths within root directory, paths , absolute paths general, effectively cease exist. project works way ’s easy move around, exactly need order run cluster. using RStudio, strongly recommend using RStudio project.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"initialising","dir":"Articles","previous_headings":"","what":"Initialising","title":"hipercow","text":"Run write things new path hipercow/ within working directory. initialisation typically want configure “driver”, controls tasks sent clusters. two options : dide-windows dide-linux target nodes running either operating system DIDE cluster. example: however, vignette use special “example” driver simulates cluster (don’t use anything , really won’t help): can run initialisation configuration one step running, example: Whether want target Windows Linux, setting driver dide-windows dide-linux respectively, hipercow commands follow . initialisation configuration can see computed configuration running hipercow_configuration(): , can see versions important packages, information working, information intend interact cluster. See vignette(\"dide-cluster\") example output might expect see, includes information mapping paths onto cluster, version R use, information. issues hipercow always want see output hipercow_configuration().","code":"hipercow_init() #> ✔ Initialised hipercow at '.' (/home/runner/work/_temp/hv-20250513-305179608ad8) #> ℹ Next, call 'hipercow_configure()' hipercow_configure(driver = \"dide-windows\") hipercow_configure(driver = \"example\") #> ✔ Configured hipercow to use 'example' hipercow_init(driver = \"dide-linux\") hipercow_configuration() #>  #> ── hipercow root at /home/runner/work/_temp/hv-20250513-305179608ad8 ─────────── #> ✔ Working directory '.' within root #> ℹ R version 4.5.0 on Linux (runner@fv-az1112-967) #>  #> ── Packages ── #>  #> ℹ This is hipercow 1.1.5 #> ℹ Installed: conan2 (1.9.102), logwatch (0.1.1), rrq (0.7.23) #> ✖ hipercow.dide is not installed #>  #> ── Environments ── #>  #> ── default #> • packages: (none) #> • sources: (none) #> • globals: (none) #>  #> ── empty #> • packages: (none) #> • sources: (none) #> • globals: (none) #>  #> ── Drivers ── #>  #> ✔ 1 driver configured ('example') #>  #> ── example #> (unconfigurable)"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"running-your-first-task","dir":"Articles","previous_headings":"","what":"Running your first task","title":"hipercow","text":"first time use tools (ever, , new machine) recommend sending tiny task make sure everything working expected: creates new task run expression sessionInfo() cluster. task_create_expr() function works -called “non standard evaluation” expression evaluated R session, sent run another machine. id returned just ugly hex string: Many functions accept id argument. can get status task, finished now really take long: task completed can inspect result: using “example” driver , result ’d get running sessionInfo() directly, just steps. See vignette(\"dide-cluster\") examples running DIDE cluster.","code":"id <- task_create_expr(sessionInfo()) #> ✔ Submitted task '6cab25285f8adcc8783ed74db73349ce' using 'example' id #> [1] \"6cab25285f8adcc8783ed74db73349ce\" task_status(id) #> [1] \"success\" task_result(id) #> R version 4.5.0 (2025-04-11) #> Platform: x86_64-pc-linux-gnu #> Running under: Ubuntu 24.04.2 LTS #>  #> Matrix products: default #> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  #> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 #>  #> locale: #>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        #>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    #>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           #> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    #>  #> time zone: UTC #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> loaded via a namespace (and not attached): #> [1] compiler_4.5.0 cli_3.6.5      withr_3.0.2    hipercow_1.1.5 rlang_1.1.6"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"using-functions-you-have-written","dir":"Articles","previous_headings":"","what":"Using functions you have written","title":"hipercow","text":"’s unlikely code want run cluster one functions built R ; likely written simulation similar want run instead. order , need tell cluster find code. two broad places code want run likely found script files packages; start former , deal packages much detail vignette(\"packages\"). Suppose file simulation.R containing simulation: can’t run cluster immediately, cluster know new function: (See vignette(\"troubleshooting\") failures.) need tell hipercow source() file simulation.R running task. use hipercow_environment_create() create “environment” (confused R’s environments) run things: Now can run simulation: can multiple environments task can set run different environment environment can source number source files, load number packages become mechanism environments parallel workers (via parallel, future rrq) set environments Read environments vignette(\"environments\")","code":"random_walk <- function(x, n_steps) {   ret <- numeric(n_steps)   for (i in seq_len(n_steps)) {     x <- rnorm(1, x)     ret[[i]] <- x   }   ret } id <- task_create_expr(random_walk(0, 10)) #> ✔ Submitted task 'e3c549aa662076f138d997b349141983' using 'example' task_wait(id) #> [1] FALSE task_status(id) #> [1] \"failure\" task_result(id) #> <simpleError in random_walk(0, 10): could not find function \"random_walk\"> hipercow_environment_create(sources = \"simulation.R\") #> ✔ Created environment 'default' id <- task_create_expr(random_walk(0, 10)) #> ✔ Submitted task '09213fb7bd59b73b4f59eb6dde4dfb9b' using 'example' task_wait(id) #> [1] TRUE task_result(id) #>  [1]  0.1255874 -0.6147476 -0.8554281 -1.1544391 -0.1096971  1.4239720 #>  [7]  1.9851303  0.5507115  1.2954113  0.7485067"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"getting-information-about-tasks","dir":"Articles","previous_headings":"","what":"Getting information about tasks","title":"hipercow","text":"created (submitted) tasks, queued cluster eventually run. hope surface enough information make easy see things going gone wrong.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"fetching-information-with-task_info","dir":"Articles","previous_headings":"Getting information about tasks","what":"Fetching information with task_info()","title":"hipercow","text":"primary function fetching information task task_info(): prints core information task; identifier (09213fb7bd59b73b4f59eb6dde4dfb9b) status (success), along information sort task , expression , variables used, environment executed time key events happened task (created, started finished). display meant friendly; need compute information, can access times reading $times element task_info() return value: Likewise, information task within $data. work underling data might just unclass object see structure: note exact structure subject (infrequent) change.","code":"task_info(id) #>  #> ── task 09213fb7bd59b73b4f59eb6dde4dfb9b (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: random_walk(0, 10) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:39.467212 (moments ago) #> ℹ Started at 2025-05-13 06:44:39.510449 (moments ago; waited 44ms) #> ℹ Finished at 2025-05-13 06:44:39.511523 (moments ago; ran for 2ms) task_info(id)$times #>                   created                   started                  finished  #> \"2025-05-13 06:44:39 UTC\" \"2025-05-13 06:44:39 UTC\" \"2025-05-13 06:44:39 UTC\" unclass(task_info(id)) #> $id #> [1] \"09213fb7bd59b73b4f59eb6dde4dfb9b\" #>  #> $status #> [1] \"success\" #>  #> $data #> $data$type #> [1] \"expression\" #>  #> $data$id #> [1] \"09213fb7bd59b73b4f59eb6dde4dfb9b\" #>  #> $data$time #> [1] \"2025-05-13 06:44:39 UTC\" #>  #> $data$path #> [1] \".\" #>  #> $data$environment #> [1] \"default\" #>  #> $data$envvars #>            name value secret #> 1 R_GC_MEM_GROW     3  FALSE #>  #> $data$parallel #> NULL #>  #> $data$expr #> random_walk(0, 10) #>  #> $data$variables #> NULL #>  #>  #> $driver #> [1] \"example\" #>  #> $times #>                   created                   started                  finished  #> \"2025-05-13 06:44:39 UTC\" \"2025-05-13 06:44:39 UTC\" \"2025-05-13 06:44:39 UTC\"  #>  #> $retry_chain #> NULL"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"fetching-logs-with-task_log_show","dir":"Articles","previous_headings":"Getting information about tasks","what":"Fetching logs with task_log_show","title":"hipercow","text":"Every task produce logs, can important part understanding went wrong. can view log task_log_show() prints contents logs screen; can access values directly task_log_value(id). format logs generally tasks; header saying running, information task printed (identifier, time, details task ), logs come calls message() print() within queued function (within “task logs” section; empty task prints nothing). Finally, summary printed final status, final time (elapsed time), warnings produced flushed (see vignette(\"troubleshooting\") warnings). second log , “outer” log, generally less interesting default. logs come cluster scheduler show startup process leads () code hipercow runs. differ driver driver. addition, log may available forever; DIDE cluster retains couple weeks: logs returned task_log_show(id, outer = FALSE) logs generated statement containing Rscript -e.","code":"task_log_show(id) #> ✖ No logs for task '09213fb7bd59b73b4f59eb6dde4dfb9b' (yet?) task_log_show(id, outer = TRUE) #> ✖ No logs for task '09213fb7bd59b73b4f59eb6dde4dfb9b' (yet?)"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"watching-logs-with-task_log_watch","dir":"Articles","previous_headings":"Getting information about tasks","what":"Watching logs with task_log_watch","title":"hipercow","text":"task still running, can stream logs computer using task_log_watch(); print new logs line--line arrive (delay 1s default). can useful debugging something give illusion ’re running locally. Using Ctrl-C (ESC RStudio) escape stop log streaming underlying task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"running-many-tasks-at-once","dir":"Articles","previous_headings":"","what":"Running many tasks at once","title":"hipercow","text":"Running one task cluster nice, takes load laptop, ’s generally ’re going process. likely, many, similar, tasks want set running . might : Fitting model series countries Exploring uncertainty parameter Running series stochastic processes cases, want submit group related tasks, sharing common function, differing data passed function. call “bulk interface”, simplest usually effective way getting started parallel computing. sort problem referred “embarrassingly parallel”; pejorative, just means work decomposes bunch independent chunks start . already familiar things can run way: anything can run R’s lapply parallelised. two similar bulk creation functions, differ based way data structured: task_create_bulk_call used list, element represents key input computation (similar lapply()) task_create_bulk_expr used data.frame, row represents inputs computation (little similar dplyr’s rowwise support)","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"bulk-call-or-parallel-map","dir":"Articles","previous_headings":"Running many tasks at once","what":"Bulk call, or “parallel map”","title":"hipercow","text":"bulk call interface one might feel familiar ; modelled ideas functions like lapply (, use purrr, map() function). idea simple, list data apply function element within . ’ll start reminder lapply works, adapt run parallel cluster. Imagine want run simple simulation different parameter. example simulate n samples normal distribution compute observed mean variance: can run locally like : Suppose vector means run : can apply mysim elements mu writing: note : mu argument iterated provided sd argument passed every call mysim get back list return, length mu, element result applying mysim element. Nothing said anything order calculations carried ; one might assume applied myfun first element mu , second, just conjecture. last point seems bit silly, useful condition think considering can parallelised; can run “loop” backwards get answer (ignoring things like specific draws random number generating functions) problem well suited parallelised. function mysim file called simulation-bulk.R, ’ll add environment ’s available cluster (alongside random_walk ): can submit tasks cluster using task_create_bulk_call: creates task bundle groups together related tasks. whole set functions working bundles behave similarly task query functions. task_status() retrieves status single task, can get status bundle running returns vector tasks included bundle. can also “reduce” status “worst” status tasks: Similarly, can wait whole bundle complete get results list flow (create, wait, result) equivalent lapply produces data shape return, tasks carried parallel! task submitted cluster picked first available node. might submit 100 tasks cluster quiet, seconds later running time. might want vary mu sd, case might convenient keep track inputs data.frame: can use task_create_bundle_call , : iterates data row-wise way. Note different lapply iterate columns (practice find almost never people want). names columns must match names function arguments columns must used. passed additional arguments , example changing n:","code":"mysim <- function(mu, sd = 1, n = 1000) {   r <- rnorm(n, mu, sd)   c(mean(r), var(r)) } source(\"simulation-bulk.R\") mysim(0, 1) #> [1] 0.004339615 1.000001295 mu <- c(0, 1, 2, 3, 4) lapply(mu, mysim, sd = 1) #> [[1]] #> [1] -0.01626336  0.93585134 #>  #> [[2]] #> [1] 1.0384556 0.9996111 #>  #> [[3]] #> [1] 1.9584970 0.9689123 #>  #> [[4]] #> [1] 3.057711 1.006066 #>  #> [[5]] #> [1] 4.0052268 0.9658853 hipercow_environment_create(sources = c(\"simulation.R\", \"simulation-bulk.R\")) #> ✔ Updated environment 'default' bundle <- task_create_bulk_call(mysim, mu, args = list(sd = 1)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'rearmost_chrysalis' with 5 tasks bundle #> → <hipercow_bundle 'rearmost_chrysalis' with 5 tasks> hipercow_bundle_status(bundle) #> [1] \"success\" \"success\" \"success\" \"success\" \"success\" hipercow_bundle_status(bundle, reduce = TRUE) #> [1] \"success\" hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_result(bundle) #> [[1]] #> [1] -0.02248414  0.97774126 #>  #> [[2]] #> [1] 1.033726 1.064940 #>  #> [[3]] #> [1] 1.970805 1.000775 #>  #> [[4]] #> [1] 3.002703 1.013349 #>  #> [[5]] #> [1] 3.997295 0.989268 pars <- data.frame(mu = mu, sd = sqrt(mu + 1)) b <- task_create_bulk_call(mysim, pars) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'carneous_hoki' with 5 tasks hipercow_bundle_wait(b) #> [1] TRUE hipercow_bundle_result(b) #> [[1]] #> [1] -0.03819042  1.02408766 #>  #> [[2]] #> [1] 1.008840 2.101506 #>  #> [[3]] #> [1] 2.069847 3.023502 #>  #> [[4]] #> [1] 2.923402 3.845022 #>  #> [[5]] #> [1] 3.864101 4.942739 b <- task_create_bulk_call(mysim, pars, args = list(n = 40)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'albinic_bird' with 5 tasks"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"bulk-expression","dir":"Articles","previous_headings":"Running many tasks at once","what":"Bulk expression","title":"hipercow","text":"also support bulk expression interface, can clearer . work row-wise pars evaluate expression first argument data found data.frame. allow use different column names convenient:","code":"b <- task_create_bulk_expr(mysim(mu, sd, n = 40), pars) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'trainsick_husky' with 5 tasks pars <- data.frame(mean = mu, stddev = sqrt(mu + 1)) b <- task_create_bulk_expr(mysim(mean, stddev, n = 40), pars) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'dentine_gorilla' with 5 tasks"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"more-on-bundles","dir":"Articles","previous_headings":"Running many tasks at once","what":"More on bundles","title":"hipercow","text":"can things bundles can tasks: equivalent task_log_watch task_log_show can’t easily multiple tasks time satisfactory way. hipercow_bundle_delete delete bundles, leave tasks alone. hipercow_purge delete tasks, causing actual deletion data. functions naturally slightly different semantics single-task function; example, hipercow_bundle_result() returns list results hipewcow_bundle_wait option fail_early control shold return FALSE soon task fails.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"picking-bundles-back-up-again-later","dir":"Articles","previous_headings":"Running many tasks at once","what":"Picking bundles back up again later","title":"hipercow","text":"can use hipercow_bundle_list() function list known bundles: bundle name (automatically generated default) time created. launched bundle reason lost session (e.g., Windows update rebooted computer) can use get ids back. ’re sure launched, can use task_info: can make process bit friendly setting name bundle creating using bundle_name argument:","code":"hipercow_bundle_list() #>                 name                time #> 1    dentine_gorilla 2025-05-13 06:44:42 #> 2    trainsick_husky 2025-05-13 06:44:42 #> 3       albinic_bird 2025-05-13 06:44:42 #> 4      carneous_hoki 2025-05-13 06:44:41 #> 5 rearmost_chrysalis 2025-05-13 06:44:41 name <- hipercow_bundle_list()$name[[1]] bundle <- hipercow_bundle_load(name) task_info(bundle$ids[[1]]) #>  #> ── task ceb8248f26f931a4410364abc7edcac7 (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: mysim(mean, stddev, n = 40) #>   • Locals: mean and stddev #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:42.936948 (moments ago) #> ℹ Started at 2025-05-13 06:44:43.000202 (moments ago; waited 64ms) #> ℹ Finished at 2025-05-13 06:44:43.001414 (moments ago; ran for 2ms) pars <- data.frame(mean = mu, stddev = sqrt(mu + 1)) b <- task_create_bulk_expr(mysim(mean, stddev, n = 40), pars,                            bundle_name = \"final_runs_v2\") #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'final_runs_v2' with 5 tasks"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"making-bundles-from-tasks","dir":"Articles","previous_headings":"Running many tasks at once","what":"Making bundles from tasks","title":"hipercow","text":"can also make bundle group tasks; may convenient need launch number tasks individually reason want consider together group. can use bundle :","code":"id1 <- task_create_expr(mysim(1, 2)) #> ✔ Submitted task '4706fa8f2865272df52572f035887d90' using 'example' id2 <- task_create_expr(mysim(2, 2)) #> ✔ Submitted task 'c8426c7c9a8184552f7154c4d1d8468c' using 'example' b <- hipercow_bundle_create(c(id1, id2), \"my_new_bundle\") #> ✔ Created bundle 'my_new_bundle' with 2 tasks b #> → <hipercow_bundle 'my_new_bundle' with 2 tasks> hipercow_bundle_status(b) #> [1] \"success\" \"success\" hipercow_bundle_wait(b) #> [1] TRUE"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"parallel-tasks","dir":"Articles","previous_headings":"","what":"Parallel tasks","title":"hipercow","text":"far, tasks submitted run using single core cluster, special requests made. simple example using two cores; ’ll use hipercow_resources() specify want two cores cluster, hipercow_parallel() say want set two processes cores, using parallel package. (also support future). parallel tasks sleep 5 seconds. use task_info() report long took two runs execute; ran one--one, ’d expect around 10 seconds, seeing much shorter time , pair processes running time. details specifying resources launching different kinds parallel tasks, see vignette(\"parallel\").","code":"resources <- hipercow_resources(cores = 2) id <- task_create_expr(   parallel::clusterApply(NULL, 1:2, function(x) Sys.sleep(5)),   parallel = hipercow_parallel(\"parallel\"),   resources = resources) #> ✔ Submitted task '8354f64f8498b6ceea025cf02d7ac0fe' using 'example' task_wait(id) #> [1] TRUE task_info(id) #>  #> ── task 8354f64f8498b6ceea025cf02d7ac0fe (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: parallel::clusterApply(NULL, 1:2, function(x) Sys.sleep(5)) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:43.5703 (moments ago) #> ℹ Started at 2025-05-13 06:44:43.634053 (moments ago; waited 64ms) #> ℹ Finished at 2025-05-13 06:44:49.022108 (moments ago; ran for 5.4s)"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"understanding-where-variables-come-from","dir":"Articles","previous_headings":"","what":"Understanding where variables come from","title":"hipercow","text":"Suppose simulation started 0, point computed locally (say x, imaginatively) can use value start simulation running: x value come environment expression passed task_create_expr() found (specifically, use rlang “tidy evaluation” framework might familiar dplyr friends). pass expression references value exist locally, get (hopefully) informative error message task created:","code":"x <- 100 id <- task_create_expr(random_walk(x, 10)) #> ✔ Submitted task '0df1eb1a4404f3cc9fb8fc250976932f' using 'example' task_wait(id) #> [1] TRUE task_result(id) #>  [1] 100.7364 101.6134 104.0365 102.2984 101.5219 103.4611 102.2067 101.9490 #>  [9] 103.0665 105.0759 id <- task_create_expr(random_walk(starting_point, 10)) #> Error in `rlang::env_get_list()`: #> ! Can't find `starting_point` in environment."},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"cancelling-tasks","dir":"Articles","previous_headings":"","what":"Cancelling tasks","title":"hipercow","text":"can cancel task submitted completed, using task_cancel(): example, ’s task sleep 10 seconds, submit cluster: decided silly idea, can try cancel : can cancel task submitted (waiting picked cluster) running (though drivers support ; need add example driver still, improve example!). can cancel many tasks passing vector identifiers time. Tasks finished (successfully ) cancelled.","code":"id <- task_create_expr(Sys.sleep(10)) #> ✔ Submitted task 'd452dc28adea4b6400dc20f88137dd07' using 'example' task_cancel(id) #> ✖ Did not manage to cancel 'd452dc28adea4b6400dc20f88137dd07' which had status 'running' #> [1] FALSE task_status(id) #> [1] \"running\" task_info(id) #>  #> ── task d452dc28adea4b6400dc20f88137dd07 (running) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: Sys.sleep(10) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:49.994068 (moments ago) #> ℹ Started at 2025-05-13 06:44:50.057781 (moments ago; waited 64ms) #> ! Not finished yet (running for 55ms)"},{"path":"https://mrc-ide.github.io/hipercow/articles/hipercow.html","id":"retrying-tasks","dir":"Articles","previous_headings":"","what":"Retrying tasks","title":"hipercow","text":"lots reasons might want retry task. example: failed think might work next time updated package used, want try new version don’t like output stochastic function want generate new output cancelled task want try now can retry tasks task_retry(), easier submitting new task content, also preserves link retried tasks. random walk give slightly different results time use , demonstrate idea : ran random walk got 0.7064141, clearly expecting. Let’s try : Running task_retry() creates new task, new id 8999f7... compared d8f87b.... task finished, get different result: Much better! get hint retried task task_info() can see full chain retries : task retried affects interact previous ids; default follow recent element chain: can get original result back passing argument follow = FALSE: tasks completed (success, failure cancelled) can retried, adds new task end chain; branching. Retrying id1 create chain id1 -> id2 -> id3, following select id3 three tasks chain. currently change property retried task, may change future.","code":"id1 <- task_create_expr(random_walk(0, 10)) #> ✔ Submitted task 'd8f87b0fc46d0e8bd0f9d6494d02b47e' using 'example' task_wait(id1) #> [1] TRUE task_result(id1) #>  [1] -0.2010879  0.0110095  1.2169456  2.8090950  2.3301872  2.6869810 #>  [7]  0.6375382 -0.4393589 -1.3147251  0.7064141 id2 <- task_retry(id1) #> ✔ Submitted task '8999f7a829c44ee1ab19a2eccd1f86e3' using 'example' task_wait(id2) #> [1] TRUE task_result(id2) #>  [1] 1.999850 3.305946 3.635446 1.777244 2.375780 1.503801 2.030081 4.746287 #>  [9] 4.621399 3.748197 task_info(id2) #>  #> ── task 8999f7a829c44ee1ab19a2eccd1f86e3 (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: random_walk(0, 10) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:50.185555 (less than a minute ago) #> ℹ Started at 2025-05-13 06:45:00.370325 (moments ago; waited 10.2s) #> ℹ Finished at 2025-05-13 06:45:00.371687 (moments ago; ran for 2ms) #> ℹ Last of a chain of a task retried 1 time task_info(id2)$retry_chain #> [1] \"d8f87b0fc46d0e8bd0f9d6494d02b47e\" \"8999f7a829c44ee1ab19a2eccd1f86e3\" task_result(id1) #>  [1] 1.999850 3.305946 3.635446 1.777244 2.375780 1.503801 2.030081 4.746287 #>  [9] 4.621399 3.748197 task_result(id2) #>  [1] 1.999850 3.305946 3.635446 1.777244 2.375780 1.503801 2.030081 4.746287 #>  [9] 4.621399 3.748197 task_result(id1, follow = FALSE) #>  [1] -0.2010879  0.0110095  1.2169456  2.8090950  2.3301872  2.6869810 #>  [7]  0.6375382 -0.4393589 -1.3147251  0.7064141 task_result(id2) #>  [1] 1.999850 3.305946 3.635446 1.777244 2.375780 1.503801 2.030081 4.746287 #>  [9] 4.621399 3.748197"},{"path":"https://mrc-ide.github.io/hipercow/articles/migration.html","id":"differences","dir":"Articles","previous_headings":"","what":"Differences","title":"Migration from didehpc","text":"differences note hipercow didehpc; confused difference mentioned please let us know. user interface quite different, free functions replacing big queue_didehpc object. Previously created object (often obj) queue_didehpc interacted running method (say obj$task_result()); instead hipercow use free function (example task_result). See translation methods new function(s). object corresponding task. Previously object handles methods. task t fetched result t$result(). queue, moved free functions (example task_result()). longer check packages installed. might modify behaviour, previous behaviour allowing queue object created packages installed stopped. Instead, provide tools (notably, hipercow_provision_check()) check state packages expect . ’s nothing stop submitting tasks cluster environment run due missing packages, hope flexible. never load packages current environment, don’t even need installed. didehpc loaded queue, loaded packages context current session. longer happens, packages need installed . Smaller differences include: task_wait return result task, boolean indicating task successful","code":""},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/articles/migration.html","id":"queue_didehpc","dir":"Articles","previous_headings":"Differences > Mapping of didehpc methods to hipercow functions","what":"queue_didehpc","title":"Migration from didehpc","text":"cluster_load: TODO (mrc-4892) config: hipercow_configuration() context: analogue dide_id: analogue (might add task_info() though) dide_log: task_log_show() argument outer = TRUE enqueue: task_create_expr() enqueue_: task_create_explicit() enqueue_bulk: task_create_bulk_expr() initialize_context: analogue install_packages: hipercow_provision() arguments method = \"pkgdepends\", refs = ... lapply: task_create_bulk_call() login: dide_check() (don’t actually log way though) mapply: task_create_bulk_call() provision_context: hipercow_provision() reconcile: task_info() (one id time, reconciles side effect) rrq_controller: stop_workers: TODO (mrc-4869) submit: task_submit() submit_workers: TODO (mrc-4869) task_bundle_get: hipercow_bundle_load() task_bundle_info: analogue, bundles longer need share anything common. task_bundle_list: hipercow_bundle_list() task_delete: TODO (mrc-4842) task_get: analogue (see ) task_list: implemented. Practically quite slow real-world usage terribly useful, might just skip . Let us know bothers . task_result: task_result() (single task) task_status: task_status() task_times: task_info() unsubmit: task_cancel()","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/migration.html","id":"task","dir":"Articles","previous_headings":"Differences","what":"task","title":"Migration from didehpc","text":"Running task_get, creating task $enqueue() returned task object. methods correspond free functions hipercow: context_id: analogue expr: task_info() log: task_log_show() task_log_value(), also task_log_watch() result: task_result() status: task_status() times: task_info() wait: task_wait()","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/migration.html","id":"bundle","dir":"Articles","previous_headings":"Differences","what":"bundle","title":"Migration from didehpc","text":"Running $task_bundle_get() creating bulk submission $enqueue_bulk() $lapply() created task bundle object. methods correspond free functions hipercow: times: yet implemented (hipercow_bundle_info) results: hipercow_bundle_result() wait: hipercow_bundle_wait() status: hipercow_bundle_status() expr: yet implemented, may go hipercow_bundle_info function_name: implemented","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/migration.html","id":"configuration","dir":"Articles","previous_headings":"","what":"Configuration","title":"Migration from didehpc","text":"Previously might used didehpc_config change lots bits didehpc’s behaviour. ’ve removed now! list arguments didehpc_config() credentials: first time use hipercow use dide_authenticate arrange credentials securely save keychain. home: used information mount home drive, always . longer mount default unless working directory. temp: used information temp drive, mount default either. cluster: cluster use. ’s currently configurable support one (wpia-hn, “new cluster”). may reappear Windows-specific option hipercow_configure() later depending cluster setup goes. shares: still supported, shares option hipercow_configure() template: renamed queue hipercow_resources(), template essentially meant. pass hipercow_resources list functions creating tasks. cores: cores option hipercow_resources(). nodes: wasn’t really useful didehpc, since reserved nodes use one . now, implemented hipercow. wholenode: flexible now. Setting cores Inf request whole node, however many cores . Setting exclusive TRUE ensures task runs node time , even request smaller number cores node . parallel: call hipercow_parallel() argument \"future\" \"parallel” pass result parallel argument creating task, set local cluster within node. Parallel processing can additionally done requesting multiple cores hipercow_resources(), sets useful environment variables thread-capable packages use . workdir: longer specified; path working directory determined automatically. use_workers: workers yet supported, interface change use_rrq: rrq yet supported, interface change worker_timeout: workers yet supported, interface change worker_resource: workers yet supported, interface change conan_bootstrap: longer configurable, just work now. r_version: still supported, r_version option hipercow_configure() use_java: longer needed; recent Java LTS always available rJava packages use . java_home: longer needed; JAVA_HOME environment variable automatically set recent Java LTS release.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/migration.html","id":"missing-features","dir":"Articles","previous_headings":"","what":"Missing features","title":"Migration from didehpc","text":"Features planning implement, yet available. use yet migrate hipercow. Let us know Cluster channel blocking moving ’s helpful us prioritise. Use workers, rrq general Dependencies tasks (e.g., submit task another completed); ’ll implement nobody actually using knowledge.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/migration.html","id":"new-features","dir":"Articles","previous_headings":"","what":"New features","title":"Migration from didehpc","text":"Support provisioning environments renv Support escape hatch method provisioning scripts; use whatever want users rarely need enter password configuration now automatic Simple method retry failed (otherwise unsatisfactory) tasks Resources offer specifying maximum runtime, memory requirements, indicating tasks run, lowering priority, better parallel support. Easily stream logs running task","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/packages.html","id":"using-pkgdepends","dir":"Articles","previous_headings":"","what":"Using pkgdepends","title":"Packages and provisioning","text":"method least prescriptive workflow simplest. recommend good starting place. two places might get lists packages install: file pkgdepends.txt directory also contains hipercow/ directory Manually, within call hipercow_provision() ’ll consider turn .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/packages.html","id":"a-list-of-packages","dir":"Articles","previous_headings":"Using pkgdepends","what":"A list of packages","title":"Packages and provisioning","text":"Create file called pkgdepends.txt top hipercow root. file simple format, line name package, pkgdepends “package reference”, plus support comments, blank lines specifying additional repositories install . complex case might look like Blank lines ignored Lines starting # comments also ignored Entries separated newlines Lines like coda represent packages CRAN another CRAN-like repository Lines like mrc-ide/malariasimulation@v1.6.0 pkgdepends reference can quite complex control version installed Lines like repo::https://ncov-ic.r-universe.dev add additional CRAN-like repositories (recommended way installing packages odin orderly2) can install packages .tar.gz adding line like local::./mypkg_0.1.0.tar.gz path relative hipercow root folder. pkgdepends docs provide lots nice examples package references. Note repo::<url> line extension . new empty hipercow root, containing simple pkgdepends.txt file: pkgdepends.txt file contains simply: can provision environment running launches small task cluster uses pkgdepends install cowsay dependencies. recent installations attempted, use cached copies, make things fairly snappy. installed can run task uses package: methods provisioning can see done previously running hipercow_provision_list() hipercow_provision_check(). Running hipercow_provision_list() just lists installations library: hipercow_provision_check() function also compares previously performed installations hipercow_provision() arguments: can see library using hipercow_provision_compare(); compares two versions library. one version comparison empty library:","code":"# Also use the ncov-ic universe repo::https://ncov-ic.r-universe.dev  # Specific version of malaria simulation, via a tag mrc-ide/malariasimulation@v1.6.0  # Package from CRAN coda #> . #> ├── hipercow #> └── pkgdepends.txt cowsay hipercow_provision() #> ✔ Selected provisioning method 'pkgdepends' #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/rfitzjoh/lib/R/library/4.4.2 #> Installing into library: hipercow/lib #> Using method pkgdepends #> Running in path: /tmp/RtmpfKwuwL/hv-20250423-7e031370fe8a1 #> Library paths: #>   - /tmp/RtmpfKwuwL/hv-20250423-7e031370fe8a1/hipercow/lib #>   - /usr/lib64/R/library #>   - /usr/share/R/library #> id: 20250423100841 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • cowsay #>  #> ✔ Updated metadata database: 4.64 MB in 9 files. #>  #> ℹ Updating metadata database #> ✔ Updating metadata database ... done #>  #> + cowsay   1.2.0 [bld][dl] #> + crayon   1.5.3 [bld][dl] #> + rlang    1.1.6 [bld][cmp][dl] #> ℹ Getting 3 pkgs with unknown sizes #> ✔ Got crayon 1.5.3 (source) (40.40 kB) #> ✔ Got cowsay 1.2.0 (source) (665.51 kB) #> ✔ Got rlang 1.1.6 (source) (767.93 kB) #> ℹ Building crayon 1.5.3 #> ℹ Building rlang 1.1.6 #> ✔ Built crayon 1.5.3 (1.5s) #> ✔ Installed crayon 1.5.3  (19ms) #> ✔ Built rlang 1.1.6 (13.3s) #> ✔ Installed rlang 1.1.6  (37ms) #> ℹ Building cowsay 1.2.0 #> ✔ Built cowsay 1.2.0 (1s) #> ✔ Installed cowsay 1.2.0  (23ms) #> ✔ Summary:   3 new  in 15.8s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250423100841' #> Done! id <- task_create_expr(cowsay::say(\"HiperMoo\", \"cow\")) #> ✔ Submitted task '5567605b109f9860e02cf3a8b66c3670' using 'example' task_wait(id) #> [1] FALSE task_log_show(id) #>  #> ── hipercow 1.1.3 running at '/tmp/RtmpfKwuwL/hv-20250423-7e031370fe8a1' ─────── #> ℹ library paths: #> • /home/rfitzjoh/lib/R/library/4.4.2 #> • /usr/lib64/R/library #> • /usr/share/R/library #> ℹ id: 5567605b109f9860e02cf3a8b66c3670 #> ℹ starting at: 2025-04-23 11:09:03.580604 #> ℹ Task type: expression #> • Expression: cowsay::say(\"HiperMoo\", \"cow\") #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✖ status: failure #> ✖ Error: there is no package called ‘cowsay’ #> ℹ finishing at: 2025-04-23 11:09:03.580604 (elapsed: 0.2313 secs) hipercow_provision_list() #> ℹ 1 conan installation recorded #> • 1: 20250423100841 (moments ago) [0] hipercow_provision_check() #> ✔ Selected provisioning method 'pkgdepends' #> ℹ 1 conan installation recorded #> • 1: 20250423100841 (moments ago) [0] (*) #> ℹ The entry marked with '*' matches the provided installation hash hipercow_provision_compare() #> ── Comparing conan installations ───────────────────────────────────────────────────────────────────────────────────── #> • (empty installation) #> • 20250423100841 1st; current installation (moments ago) #>  #> ── 3 added packages ── #>  #> • cowsay (1.2.0) CRAN #> • crayon (1.5.3) CRAN #> • rlang (1.1.6) CRAN"},{"path":"https://mrc-ide.github.io/hipercow/articles/packages.html","id":"manually","dir":"Articles","previous_headings":"Using pkgdepends","what":"Manually","title":"Packages and provisioning","text":"Sometimes, regardless things installed, need install something manually. example, just want change version used package, pkgdepends fails resolve nice set dependencies complex interdependent set packages want install specific version top everything . , hipercow_provision method = \"pkgdepends\" refs character vector package references, following format pkgdepends.txt Now hipercow_provision_list() hipercow_provision_compare() show two steps history library can see changed:","code":"hipercow_provision(method = \"pkgdepends\", refs = \"cran::coda\") #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/rfitzjoh/lib/R/library/4.4.2 #> Installing into library: hipercow/lib #> Using method pkgdepends #> Running in path: /tmp/RtmpfKwuwL/hv-20250423-7e031370fe8a1 #> Library paths: #>   - /tmp/RtmpfKwuwL/hv-20250423-7e031370fe8a1/hipercow/lib #>   - /usr/lib64/R/library #>   - /usr/share/R/library #> id: 20250423100904 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • cran::coda #> ℹ Loading metadata database #> ✔ Loading metadata database ... done #>  #> + coda   0.19-4.1 [bld] #> ℹ No downloads are needed, 1 pkg is cached #> ✔ Got coda 0.19-4.1 (source) (74.30 kB) #> ℹ Building coda 0.19-4.1 #> ✔ Built coda 0.19-4.1 (2.5s) #> ✔ Installed coda 0.19-4.1  (20ms) #> ✔ Summary:   1 new   1 kept  in 2.5s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250423100904' #> Done! hipercow_provision_list() #> ℹ 2 conan installations recorded #> • 1: 20250423100841 (moments ago) [-1] #> • 2: 20250423100904 (moments ago) [0] hipercow_provision_compare() #> ── Comparing conan installations ───────────────────────────────────────────────────────────────────────────────────── #> • 20250423100841 1st; previous installation (moments ago) #> • 20250423100904 2nd; current installation (moments ago) #>  #> ── 3 unchanged packages ── #>  #> ℹ To show unchanged packages, print with 'show_unchanged = TRUE' #>  #> ── 1 added package ── #>  #> • coda (0.19.4.1) CRAN"},{"path":"https://mrc-ide.github.io/hipercow/articles/packages.html","id":"automatically-from-an-environment","dir":"Articles","previous_headings":"","what":"Automatically, from an environment","title":"Packages and provisioning","text":"pkgdepends approach duplicates information already present packages listed calls hipercow_environment(), implied files source()’d start task local metadata packages installed first place. try poke around script files find packages use, look installation, build set references hope recreate installation. new empty hipercow root, time containing source file src.R: file src.R contains code want run cluster: tell hipercow : Now, run hipercow_provision(), hipercow check src.R file seen use cowsay Now code works! installed cowsay initially running remotes::install_github() noticed installed package way. example, rfiglet package available CRAN must installed via remotes: ’ve adjusted src.R use rfiglet: now call hipercow_provision() can see installs rfiglet , automatically finding GitHub!","code":"#> . #> ├── hipercow #> └── src.R cowsay_fact <- function() {   cowsay::say(\"catfact\", \"cow\") } hipercow_environment_create(sources = \"src.R\") #> ✔ Created environment 'default' hipercow_provision() #> ✔ Selected provisioning method 'auto' #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/rfitzjoh/lib/R/library/4.4.2 #> Installing into library: hipercow/lib #> Using method auto #> Running in path: /tmp/RtmpfKwuwL/hv-20250423-7e0312b18dcf9 #> Library paths: #>   - /tmp/RtmpfKwuwL/hv-20250423-7e0312b18dcf9/hipercow/lib #>   - /usr/lib64/R/library #>   - /usr/share/R/library #> id: 20250423100910 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • cowsay #>  #> ✔ Updated metadata database: 4.64 MB in 9 files. #>  #> ℹ Updating metadata database #> ✔ Updating metadata database ... done #>  #> ! Failed to update system requirement mappings, will use cached mappings. #> + cowsay   1.2.0 [bld][dl] #> + crayon   1.5.3 [bld][dl] #> + rlang    1.1.6 [bld][cmp][dl] #> ℹ Getting 3 pkgs with unknown sizes #> ✔ Got crayon 1.5.3 (source) (40.40 kB) #> ✔ Got cowsay 1.2.0 (source) (665.51 kB) #> ✔ Got rlang 1.1.6 (source) (767.93 kB) #> ℹ Building crayon 1.5.3 #> ℹ Building rlang 1.1.6 #> ✔ Built crayon 1.5.3 (1.4s) #> ✔ Installed crayon 1.5.3  (18ms) #> ✔ Built rlang 1.1.6 (13.3s) #> ✔ Installed rlang 1.1.6  (42ms) #> ℹ Building cowsay 1.2.0 #> ✔ Built cowsay 1.2.0 (1.1s) #> ✔ Installed cowsay 1.2.0  (26ms) #> ✔ Summary:   3 new  in 15.8s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250423100910' #> Done! id <- task_create_expr(cowsay_fact()) #> ✔ Submitted task 'e7832a2b5f5dc60cdc39d712846a3660' using 'example' task_wait(id) #> [1] FALSE task_log_show(id) #>  #> ── hipercow 1.1.3 running at '/tmp/RtmpfKwuwL/hv-20250423-7e0312b18dcf9' ─────── #> ℹ library paths: #> • /home/rfitzjoh/lib/R/library/4.4.2 #> • /usr/lib64/R/library #> • /usr/share/R/library #> ℹ id: e7832a2b5f5dc60cdc39d712846a3660 #> ℹ starting at: 2025-04-23 11:09:32.798112 #> ℹ Task type: expression #> • Expression: cowsay_fact() #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ℹ Loading environment 'default'... #> • packages: (none) #> • sources: src.R #> • globals: (none) #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✖ status: failure #> ✖ Error: there is no package called ‘cowsay’ #> ℹ finishing at: 2025-04-23 11:09:32.798112 (elapsed: 0.2805 secs) remotes::install_github(\"richfitz/rfiglet\") cowsay_fact <- function() {   cowsay::say(\"catfact\", \"cow\") }  figlet_date <- function() {   print(rfiglet::figlet(as.character(Sys.Date()))) } hipercow_provision() #> ✔ Selected provisioning method 'auto' #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/rfitzjoh/lib/R/library/4.4.2 #> Installing into library: hipercow/lib #> Using method auto #> Running in path: /tmp/RtmpfKwuwL/hv-20250423-7e0312b18dcf9 #> Library paths: #>   - /tmp/RtmpfKwuwL/hv-20250423-7e0312b18dcf9/hipercow/lib #>   - /usr/lib64/R/library #>   - /usr/share/R/library #> id: 20250423100934 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • cowsay #> • richfitz/rfiglet@HEAD #> ℹ Loading metadata database #> ✔ Loading metadata database ... done #>  #> ! Using bundled GitHub PAT. Please add your own PAT using `gitcreds::gitcreds_set()`. #> + rfiglet   0.2.0 [bld][cmp] (GitHub: d713c1b) #> ℹ No downloads are needed, 1 pkg is cached #> ✔ Got rfiglet 0.2.0 (source) (144.05 kB) #> ℹ Packaging rfiglet 0.2.0 #> ✔ Packaged rfiglet 0.2.0 (426ms) #> ℹ Building rfiglet 0.2.0 #> ✔ Built rfiglet 0.2.0 (980ms) #> ✔ Installed rfiglet 0.2.0 (github::richfitz/rfiglet@d713c1b) (19ms) #> ✔ Summary:   1 new   3 kept  in 998ms #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250423100934' #> Done! id <- task_create_expr(figlet_date()) #> ✔ Submitted task '21ba10da48277e137bdccbb7a090e034' using 'example' task_wait(id) #> [1] TRUE task_log_show(id) #>  #> ── hipercow 1.1.3 running at '/tmp/RtmpfKwuwL/hv-20250423-7e0312b18dcf9' ─────── #> ℹ library paths: #> • /home/rfitzjoh/lib/R/library/4.4.2 #> • /usr/lib64/R/library #> • /usr/share/R/library #> ℹ id: 21ba10da48277e137bdccbb7a090e034 #> ℹ starting at: 2025-04-23 11:09:39.523727 #> ℹ Task type: expression #> • Expression: figlet_date() #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ℹ Loading environment 'default'... #> • packages: (none) #> • sources: src.R #> • globals: (none) #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #>  ____   ___ ____  ____         ___  _  _        ____  _____ #> |___ \\ / _ \\___ \\| ___|       / _ \\| || |      |___ \\|___ / #>   __) | | | |__) |___ \\ _____| | | | || |_ _____ __) | |_ \\ #>  / __/| |_| / __/ ___) |_____| |_| |__   _|_____/ __/ ___) | #> |_____|\\___/_____|____/       \\___/   |_|      |_____|____/ #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✔ status: success #> ℹ finishing at: 2025-04-23 11:09:39.523727 (elapsed: 0.2296 secs)"},{"path":"https://mrc-ide.github.io/hipercow/articles/packages.html","id":"using-a-script","dir":"Articles","previous_headings":"","what":"Using a script","title":"Packages and provisioning","text":"Sometimes just need lot control pkgdepends can provide want thing. support , create file provision.R root hipercow repository within write whatever want install packages. , another empty hipercow root, containing file provision.R: provision.R file contains simply: , ’s simple, just installs package (plus runs simple function ). Please considerate don’t write scripts take long run (e.g., longer 10-15 minutes) may killed cluster scheduler. Please also let us know script takes long.","code":"#> . #> ├── hipercow #> └── provision.R install.packages(\"cowsay\") cowsay::say(\"Moo\", \"cow\") hipercow_provision() #> ✔ Selected provisioning method 'script' #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/rfitzjoh/lib/R/library/4.4.2 #> Installing into library: hipercow/lib #> Using method script #> Running in path: /tmp/RtmpfKwuwL/hv-20250423-7e0314b181a2 #> Library paths: #>   - /tmp/RtmpfKwuwL/hv-20250423-7e0314b181a2/hipercow/lib #>   - /usr/lib64/R/library #>   - /usr/share/R/library #> id: 20250423100940 #> Logs from your installation script 'provision.R' follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> > install.packages(\"cowsay\") #> Installing package into ‘/tmp/RtmpfKwuwL/hv-20250423-7e0314b181a2/hipercow/lib’ #> (as ‘lib’ is unspecified) #> also installing the dependencies ‘crayon’, ‘rlang’ #>  #> trying URL 'https://cloud.r-project.org/src/contrib/crayon_1.5.3.tar.gz' #> Content type 'application/x-gzip' length 40396 bytes (39 KB) #> ================================================== #> downloaded 39 KB #>  #> trying URL 'https://cloud.r-project.org/src/contrib/rlang_1.1.6.tar.gz' #> Content type 'application/x-gzip' length 767928 bytes (749 KB) #> ================================================== #> downloaded 749 KB #>  #> trying URL 'https://cloud.r-project.org/src/contrib/cowsay_1.2.0.tar.gz' #> Content type 'application/x-gzip' length 665506 bytes (649 KB) #> ================================================== #> downloaded 649 KB #>  #> * installing *source* package ‘crayon’ ... #> ** package ‘crayon’ successfully unpacked and MD5 sums checked #> ** using staged installation #> ** R #> ** byte-compile and prepare package for lazy loading #> ** help #> *** installing help indices #>   converting help for package ‘crayon’ #>     finding HTML links ... done #>     chr                                     html   #>     col_align                               html   #>     col_nchar                               html   #>     col_strsplit                            html   #>     col_substr                              html   #>     col_substring                           html   #>     combine_styles                          html   #>     concat                                  html   #>     crayon                                  html   #>     drop_style                              html   #>     has_color                               html   #>     has_style                               html   #>     hyperlink                               html   #>     make_style                              html   #>     num_ansi_colors                         html   #>     num_colors                              html   #>     show_ansi_colors                        html   #>     start.crayon                            html   #>     strip_style                             html   #>     style                                   html   #>     styles                                  html   #> ** building package indices #> ** testing if installed package can be loaded from temporary location #> ** testing if installed package can be loaded from final location #> ** testing if installed package keeps a record of temporary installation path #> * DONE (crayon) #> * installing *source* package ‘rlang’ ... #> ** package ‘rlang’ successfully unpacked and MD5 sums checked #> ** using staged installation #> ** libs #> using C compiler: ‘gcc (GCC) 14.2.1 20250110 (Red Hat 14.2.1-7)’ #> gcc -I\"/usr/include/R\" -DNDEBUG -I./rlang/  -I/usr/local/include   -fvisibility=hidden -fpic  -O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-U_FORTIFY_SOURCE,-D_FORTIFY_SOURCE=3 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -mtls-dialect=gnu2 -fno-omit-frame-pointer -mno-omit-leaf-frame-pointer   -c capture.c -o capture.o #> gcc -I\"/usr/include/R\" -DNDEBUG -I./rlang/  -I/usr/local/include   -fvisibility=hidden -fpic  -O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-U_FORTIFY_SOURCE,-D_FORTIFY_SOURCE=3 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -mtls-dialect=gnu2 -fno-omit-frame-pointer -mno-omit-leaf-frame-pointer   -c internal.c -o internal.o #> gcc -I\"/usr/include/R\" -DNDEBUG -I./rlang/  -I/usr/local/include   -fvisibility=hidden -fpic  -O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-U_FORTIFY_SOURCE,-D_FORTIFY_SOURCE=3 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -mtls-dialect=gnu2 -fno-omit-frame-pointer -mno-omit-leaf-frame-pointer   -c rlang.c -o rlang.o #> gcc -I\"/usr/include/R\" -DNDEBUG -I./rlang/  -I/usr/local/include   -fvisibility=hidden -fpic  -O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-U_FORTIFY_SOURCE,-D_FORTIFY_SOURCE=3 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -mtls-dialect=gnu2 -fno-omit-frame-pointer -mno-omit-leaf-frame-pointer   -c version.c -o version.o #> gcc -shared -L/usr/lib64/R/lib -Wl,-z,relro -Wl,--as-needed -Wl,-z,pack-relative-relocs -Wl,-z,now -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -Wl,--build-id=sha1 -o rlang.so capture.o internal.o rlang.o version.o -L/usr/lib64/R/lib -lR #> installing to /tmp/RtmpfKwuwL/hv-20250423-7e0314b181a2/hipercow/lib/00LOCK-rlang/00new/rlang/libs #> ** R #> ** inst #> ** byte-compile and prepare package for lazy loading #> ** help #> *** installing help indices #>   converting help for package ‘rlang’ #>     finding HTML links ... done #>     UQ                                      html   #>     abort                                   html   #>     are_na                                  html   #>     arg_match                               html   #>     args_data_masking                       html   #>     args_dots_empty                         html   #>     args_dots_used                          html   #>     args_error_context                      html   #>     as_box                                  html   #>     as_closure                              html   #>     as_data_mask                            html   #>     as_environment                          html   #>     as_function                             html   #>     as_label                                html   #>     as_name                                 html   #>     as_string                               html   #>     as_utf8_character                       html   #>     bare-type-predicates                    html   #>     box                                     html   #>     bytes-class                             html   #>     call2                                   html   #>     call_args                               html   #>     call_fn                                 html   #>     call_inspect                            html   #>     call_match                              html   #>     call_modify                             html   #>     call_name                               html   #>     call_standardise                        html   #>     caller_arg                              html   #>     catch_cnd                               html   #>     check_dots_empty                        html   #>     check_dots_empty0                       html   #>     check_dots_unnamed                      html   #>     check_dots_used                         html   #>     check_exclusive                         html   #>     check_required                          html   #>     child_env                               html   #>     chr_unserialise_unicode                 html   #>     cnd                                     html   #>     cnd_inherits                            html   #>     cnd_message                             html   #>     cnd_muffle                              html   #>     cnd_signal                              html   #>     cnd_type                                html   #>     defusing-advanced                       html   #>     dev-notes-dots                          html   #>     done                                    html   #>     dot-data                                html   #>     dots_n                                  html   #>     dots_splice                             html   #>     dots_values                             html   #>     duplicate                               html   #>     dyn-dots                                html   #>     embrace-operator                        html   #>     empty_env                               html   #>     englue                                  html   #>     enquo                                   html   #>     entrace                                 html   #>     env                                     html   #>     env_bind                                html   #>     env_binding_are_active                  html   #>     env_binding_lock                        html   #>     env_browse                              html   #>     env_bury                                html   #>     env_cache                               html   #>     env_clone                               html   #>     env_depth                               html   #>     env_get                                 html   #>     env_has                                 html   #>     env_inherits                            html   #>     env_is_user_facing                      html   #>     env_lock                                html   #>     env_name                                html   #>     env_names                               html   #>     env_parent                              html   #>     env_poke                                html   #>     env_print                               html   #>     env_unbind                              html   #>     env_unlock                              html   #>     eval_bare                               html   #>     eval_tidy                               html   #>     exec                                    html   #>     expr                                    html   #>     expr_interp                             html   #>     expr_label                              html   #>     expr_print                              html   #>     exprs_auto_name                         html   #>     f_rhs                                   html   #>     f_text                                  html   #>     faq-options                             html   #>     ffi_standalone_types_check              html   #>     flatten                                 html   #>     fn_body                                 html   #>     fn_env                                  html   #>     fn_fmls                                 html   #>     format_error_bullets                    html   #>     format_error_call                       html   #>     friendly_type                           html   #>     get_env                                 html   #>     global_entrace                          html   #>     global_handle                           html   #>     global_prompt_install                   html   #>     glue-operators                          html   #>     has_length                              html   #>     has_name                                html   #>     hash                                    html   #>     inherits_any                            html   #>     inject                                  html   #>     injection-operator                      html   #>     interrupt                               html   #>     invoke                                  html   #>     is_call                                 html   #>     is_callable                             html   #>     is_condition                            html   #>     is_copyable                             html   #>     is_dictionaryish                        html   #>     is_empty                                html   #>     is_environment                          html   #>     is_expression                           html   #>     is_formula                              html   #>     is_function                             html   #>     is_installed                            html   #>     is_integerish                           html   #>     is_interactive                          html   #>     is_lang                                 html   #>     is_named                                html   #>     is_namespace                            html   #>     is_pairlist                             html   #>     is_reference                            html   #>     is_symbol                               html   #>     is_true                                 html   #>     is_weakref                              html   #>     lang                                    html   #>     last_error                              html   #>     last_warnings                           html   #>     list2                                   html   #>     local_bindings                          html   #>     local_error_call                        html   #>     local_options                           html   #>     local_use_cli                           html   #>     missing                                 html   #>     missing_arg                             html   #>     names2                                  html   #>     names_inform_repair                     html   #>     new-vector                              html   #>     new_call                                html   #>     new_formula                             html   #>     new_function                            html   #>     new_node                                html   #>     new_quosure                             html   #>     new_quosures                            html   #>     new_weakref                             html   #>     ns_env                                  html   #>     ns_registry_env                         html   #>     obj_address                             html   #>     on_load                                 html   #>     op-get-attr                             html   #>     op-na-default                           html   #>     op-null-default                         html   #>     pairlist2                               html   #>     parse_expr                              html   #>     prim_name                               html   #>     qq_show                                 html   #>     quo_expr                                html   #>     quo_label                               html   #>     quo_squash                              html   #>     quosure-tools                           html   #>     raw_deparse_str                         html   #>     rep_along                               html   #>     return_from                             html   #>     rlang-package                           html   #>     rlang_backtrace_on_error                html   #>     rlang_error                             html   #>     rlib_trace_spec                         html   #>     scalar-type-predicates                  html   #>     scoped_env                              html   #>     scoped_interactive                      html   #>     search_envs                             html   #>     seq2                                    html   #>     set_attrs                               html   #>     set_expr                                html   #>     set_names                               html   #>     splice-operator                         html   #>     splice                                  html   #>     stack-deprecated                        html   #>     stack                                   html   #>     string                                  html   #>     switch_type                             html   #>     sym                                     html   #>     topic-condition-customisation           html   #>     topic-condition-formatting              html   #>     topic-data-mask-ambiguity               html   #>     topic-data-mask-programming             html   #>     topic-data-mask                         html   #>     topic-defuse                            html   #>     topic-double-evaluation                 html   #>     topic-embrace-constants                 html   #>     topic-embrace-non-args                  html   #>     topic-error-call                        html   #>     topic-error-chaining                    html   #>     topic-inject-out-of-context             html   #>     topic-inject                            html   #>     topic-metaprogramming                   html   #>     topic-multiple-columns                  html   #>     topic-quosure                           html   #>     trace_back                              html   #>     try_fetch                               html   #>     type-predicates                         html   #>     type_of                                 html   #>     vec_poke_n                              html   #>     vector-coercion                         html   #>     vector-construction                     html   #>     with_env                                html   #>     with_handlers                           html   #>     wref_key                                html   #>     zap                                     html   #>     zap_srcref                              html   #> *** copying figures #> ** building package indices #> ** testing if installed package can be loaded from temporary location #> ** checking absolute paths in shared objects and dynamic libraries #> ** testing if installed package can be loaded from final location #> ** testing if installed package keeps a record of temporary installation path #> * DONE (rlang) #> * installing *source* package ‘cowsay’ ... #> ** package ‘cowsay’ successfully unpacked and MD5 sums checked #> ** using staged installation #> ** R #> ** inst #> ** byte-compile and prepare package for lazy loading #> ** help #> *** installing help indices #>   converting help for package ‘cowsay’ #>     finding HTML links ... done #>     animal_fetch                            html   #>     animals                                 html   #>     bubble_say                              html   #>     bubble_tail                             html   #>     cowsay-package                          html   #>     endless_horse                           html   #>     say                                     html   #>     say_think                               html   #> *** copying figures #> ** building package indices #> ** installing vignettes #> ** testing if installed package can be loaded from temporary location #> ** testing if installed package can be loaded from final location #> ** testing if installed package keeps a record of temporary installation path #> * DONE (cowsay) #>  #> The downloaded source packages are in #>  ‘/tmp/Rtmpbrz2AP/downloaded_packages’ #>  #> > cowsay::say(\"Moo\", \"cow\") #>  #>  _____  #> < Moo > #>  -----  #>       \\ #>        \\ #>  #>         ^__^  #>         (oo)\\ ________  #>         (__)\\         )\\ /\\  #>              ||------w| #>              ||      || #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250423100940' #> Done!"},{"path":"https://mrc-ide.github.io/hipercow/articles/packages.html","id":"using-renv","dir":"Articles","previous_headings":"","what":"Using renv","title":"Packages and provisioning","text":"using renv set packages, can use hipercow, detected automatically. renv project loaded lockfile created (renv::status() reports “issues found – project consistent state.”) able run see renv build new library based lockfile. New tasks launched use library. workflow differs slightly using renv normally take steps prevent renv updating library automatically tasks run result disaster multiple tasks trigger parallel.","code":"hipercow_provision()"},{"path":"https://mrc-ide.github.io/hipercow/articles/packages.html","id":"some-details-about-the-process","dir":"Articles","previous_headings":"","what":"Some details about the process","title":"Packages and provisioning","text":"general hope relatively little configuration specific calls needed , comes cost little magic. method argument hipercow_provision() given, use simple heuristic select method: file provision.R present, use script method; takes precedence ’s biggest, least clever hammer. might use last resort override method might using. file pkgdepends.txt present, use pkgdepends method; think method reasonable tradeoff predictability usability cover people’s needs. Otherwise ’ll try automatic installation; help people get started quickly. can always pass method explicitly arguments supported method (see ?hipercow_provision details). example, suppose normally things working pkgdepends hit trouble incompatible set versions, might write file fix_install.R run : interrupt installation runs, (currently) cancel running task. may change future. Please don’t submit another provisioning task finished (can use HPC portal check easily). used didehpc might expect referencing packages environment (.e., hipercow_environment_create()) automatically cause packages installed hipercow_provision(); however, method = \"auto\".","code":"hipercow_provision(method = \"script\", script = \"fix_install.R\")"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"task-level-parallelism","dir":"Articles","previous_headings":"","what":"Task-level parallelism","title":"Parallel Tasks","text":"Never underestimate performance gain might get simple running many tasks time. code written way makes easy run many instances , different parameters example, consider using task_create_bulk_expr() simply run tasks, without making coding changes. however, want use multiple cores time within task, task special requirements regarding compute nodes can run , read vignette. go, ’ll using example cluster; results ’ll get back real cluster differ, principles .","code":"hipercow_init(\".\", driver = \"example\") #> ✔ Initialised hipercow at '.' (/home/runner/work/_temp/hv-20250513-317295408e7) #> ✔ Configured hipercow to use 'example'"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"what-resources-does-the-cluster-have","dir":"Articles","previous_headings":"","what":"What resources does the cluster have?","title":"Parallel Tasks","text":"present, one Windows-based cluster, future plan others. aim use hipercow_resources() hipercow_parallel() across clusters support - yet clusters likely different resources queues. look information cluster currently configured use, call hipercow_cluster_info() - real example vignette(\"windows\"). purposes vignette, using virtual cluster called example single 4-core node, can run simple examples . create task uses one core, need request resources using hipercow_resources(), specify want cores used, using hipercow_parallel().","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"specifying-multi-core-resources","dir":"Articles","previous_headings":"","what":"Specifying multi-core resources","title":"Parallel Tasks","text":"cores exclusive arguments hipercow_resources() important ones . cores integer, soon node sufficient cores free, task launch node. Task submission fail node many cores. common way people increase resources allocated tasks practice. cores Inf, task run first node becomes completely free; node number cores. present nodes number cores. changes, useful throughput bulk number tasks benefit parallel execution, don’t particularly mind whether run 20-core machines, others 32-core machines. Setting exclusive TRUE, similar setting cores Inf, task get whole node ; difference number cores reported hipercow number cores request, may less number cores node . useful task co-exist node another tasks, perhaps anyone else’s tasks; example, single-core node uses memory node , task network API access fail multiple requests came IP address.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"running-parallel-tasks","dir":"Articles","previous_headings":"","what":"Running parallel tasks","title":"Parallel Tasks","text":"Requesting number cores hipercow_resoures cause number environment variables set task starts running. MC_CORES, OMP_NUM_THREADS, OMP_THREAD_LIMIT R_DATATABLE_NUM_THREADS, along HIPERCOW_CORES use internally, value number cores requested. packages (dust Stan) can use environment variables run parallel without anything . also ways can explicitly say many threads like use - see . However, ’re using packages look environment variables, requesting resources hipercow_resources() alone change behaviour performance code; affect resources cluster reserves allocates task, decides tasks run nodes. Hipercow provides ways making use cores reserved. hipercow_parallel() function present supports two methods running different code different cores reserved. One parallel package, future package. case, hipercow handles setup parallel cluster us, ’ll describe next.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"using-the-parallel-package","dir":"Articles","previous_headings":"Running parallel tasks","what":"Using the Parallel package","title":"Parallel Tasks","text":"example, reserve two cores cluster, call hipercow_parallel(\"parallel\") sets team workers (two case), use one allocated cores. parallel package built R provides simple, somewhat eccentric, approach multi-process parallelism. introductory vignette vignette(\"parallel\", package = \"parallel\"). general strategy using parallel write code run lapply(), use parallel::clusterApply() run parallel instead, changes needed. specifying parallel argument , hipercow start “cluster” within job , parallel::clusterApply command runs across two processes.","code":"resources <- hipercow_resources(cores = 2) id <- task_create_expr(   parallel::clusterApply(NULL, 1:2, function(x) Sys.sleep(5)),   parallel = hipercow_parallel(\"parallel\"),   resources = resources) #> ✔ Submitted task '74a7acec5b15960454ce6189544de365' using 'example' task_wait(id) #> [1] TRUE task_info(id) #>  #> ── task 74a7acec5b15960454ce6189544de365 (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #> • Expression: parallel::clusterApply(NULL, 1:2, function(x) Sys.sleep(5)) #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:45:08.562571 (moments ago) #> ℹ Started at 2025-05-13 06:45:08.8118 (moments ago; waited 250ms) #> ℹ Finished at 2025-05-13 06:45:14.392728 (moments ago; ran for 5.6s)"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"using-the-future-package","dir":"Articles","previous_headings":"Running parallel tasks","what":"Using the future package","title":"Parallel Tasks","text":"future package, similar use parallel, prefer way using furrr package, offers high-level interfaces match closely purrr package. testing though, furrr much higher overheads parallel. test , future usually takes close 8 seconds, whereas parallel takes just 5. perhaps test code early stage see whether difference matters , compared package prefer writing code . expect overhead reduce impact amount work parallel task increases (overhead 3s parallelised task takes 10 minutes, overhead negligible, especially find easier use). example, also need furrr package provisioned using hipercow_provision().","code":"resources <- hipercow_resources(cores = 2) id <- task_create_expr(   furrr::future_map(1:2, ~Sys.sleep(5)),   parallel = hipercow_parallel(\"future\"),   resources = resources) #> ✔ Submitted task 'f59df07a80af6af2fbd154573f7b8ec4' using 'example' task_wait(id) #> [1] TRUE task_info(id) #>  #> ── task f59df07a80af6af2fbd154573f7b8ec4 (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #> • Expression: furrr::future_map(1:2, ~ Sys.sleep(5)) #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:45:14.75306 (moments ago) #> ℹ Started at 2025-05-13 06:45:15.042385 (moments ago; waited 290ms) #> ℹ Finished at 2025-05-13 06:45:21.276278 (moments ago; ran for 6.2s)"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"specifying-more-work-than-there-are-cores","dir":"Articles","previous_headings":"Running parallel tasks","what":"Specifying more work than there are cores","title":"Parallel Tasks","text":"future_map clusterApply examples , provided vector work - case simply 1:2. examples, exactly matches number cores requested using hipercow_resources. amount work larger, example 1:4, methods, 2 processes run concurrently, requested, hipercow_parallel initialised cluster. extra processes queue allocated core free. example:- reserve 2 cores, map 3 processes onto cluster, take 2 seconds. takes 4 seconds , can’t run 3 processes time; one wait free core.","code":"resources <- hipercow_resources(cores = 2) id <- task_create_expr(   parallel::clusterApply(NULL, 1:3, function(x) Sys.sleep(2)),   parallel = hipercow_parallel(\"parallel\"),   resources = resources) #> ✔ Submitted task 'b7552c46e271e088931d9cb5127229fd' using 'example' task_wait(id) #> [1] TRUE task_info(id) #>  #> ── task b7552c46e271e088931d9cb5127229fd (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #> • Expression: parallel::clusterApply(NULL, 1:3, function(x) Sys.sleep(2)) #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:45:21.904811 (moments ago) #> ℹ Started at 2025-05-13 06:45:22.126021 (moments ago; waited 222ms) #> ℹ Finished at 2025-05-13 06:45:26.700665 (moments ago; ran for 4.6s)"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"how-many-cores-should-each-process-use","dir":"Articles","previous_headings":"Running parallel tasks","what":"How many cores should each process use?","title":"Parallel Tasks","text":"number cores available process can looked hipercow_parallel_get_cores. main process, number cores requested using hipercow_resources, workers created future parallel clusters, result 1, initialise separate process per core.","code":"resources <- hipercow_resources(cores = 4) id <- task_create_expr({     unlist(c(hipercow::hipercow_parallel_get_cores(),       parallel::clusterApply(         NULL,         1:4,         function(x) hipercow::hipercow_parallel_get_cores())))   },   parallel = hipercow_parallel(\"parallel\"),   resources = resources) #> ✔ Submitted task 'edc63a67e66f0ed4fb0a30995db27d12' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] 4 1 1 1 1"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"multiple-cores-per-process","dir":"Articles","previous_headings":"Running parallel tasks","what":"Multiple cores per process","title":"Parallel Tasks","text":"previous example, created cluster run 4 processes time, 4 processes single-core task. nested parallelism within 4 processes. want - nested parallelism - can use cores_per_process argument hipercow_parallel, create number processes , might number cores allocated . useful , example, requested 32 cores, wanted run 4 concurrent tasks using future_map clusterApply, 8 cores something parallel , perhaps using Stan, dust. example cluster rather smaller, create pair 2-core process using parallel. Now process knows 2 cores allocated, update function clusterApply calling, pass result hipercow_parallel_get_cores function supports parallel processing. also use x, 1 2 pair processes, cause different behaviour process.","code":"resources <- hipercow_resources(cores = 4) id <- task_create_expr({     unlist(c(hipercow::hipercow_parallel_get_cores(),       parallel::clusterApply(         NULL,         1:2,         function(x) hipercow::hipercow_parallel_get_cores())))   },   parallel = hipercow_parallel(\"parallel\", cores_per_process = 2),   resources = resources) #> ✔ Submitted task 'f560e94bb7e4759412da0a4b4f6de1fc' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] 4 2 2"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"other-ways-of-using-cores","dir":"Articles","previous_headings":"Running parallel tasks","what":"Other ways of using cores","title":"Parallel Tasks","text":"packages can use multiple cores, often number cores use can set environment variables. Hipercow automatically sets useful variables indicate many cores cluster allocated task - even don’t call hipercow_parallel. visible packages use . example, parallel package uses MC_CORES, C++ code using OpenMP look OMP_NUM_THREADS function omp_get_max_threads() called. couple examples using dust package (need provisioned run real cluster). , num_procs value dust gives us, number cores machine , may allocated job. case, two cores us use, environment variables report, dust going use. , ’ll see dust generating random numbers us different numbers threads. Note final column total_time decreases amount work threads. may want set environment variables dust packages use different number cores. example, perhaps acquired whole 32 core node memory reasons, parallel algorithms able use many cores optimally, smaller number better. (examples case). , call hipercow_parallel_set_cores number cores want, environment variables take value. better way solving problem though, specify memory requirement: (passing resources argument task creation function). See details.","code":"resources <- hipercow_resources(cores = 2) id <- task_create_expr({   res <- dust::dust_openmp_support()   c(res[[\"num_procs\"]], res[[\"OMP_NUM_THREADS\"]], res[[\"MC_CORES\"]],     dust::dust_openmp_threads()) }, resources = resources) #> ✔ Submitted task 'f544a2eda5916bf1e4a354c2bffe1598' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] 4 2 2 2 resources <- hipercow_resources(cores = 4) id <- task_create_expr({   rng <- dust::dust_rng$new(seed = 1, n_streams = 32)   bench::mark(     one = rng$random_normal(1000000, n_threads = 1),     two = rng$random_normal(1000000, n_threads = 2),     four = rng$random_normal(1000000, n_threads = 4),     check = FALSE,     time_unit = \"s\")   }, resources = resources) #> ✔ Submitted task 'b89bfff26886eaa0c7f18d265941d56b' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> # A tibble: 3 × 13 #>   expression   min median `itr/sec` mem_alloc  `gc/sec` n_itr  n_gc total_time #>   <bnch_xpr> <dbl>  <dbl>     <dbl> <bnch_byt>    <dbl> <int> <dbl>      <dbl> #> 1 <language> 1.04   1.04      0.959 256003144     0.959     1     1      1.04  #> 2 <language> 0.506  0.506     1.97  256000048     1.97      1     1      0.506 #> 3 <language> 0.352  0.356     2.81  256000048     2.81      2     2      0.712 #> # ℹ 4 more variables: result <list>, memory <list>, time <list>, gc <list> resources <- hipercow_resources(memory_per_node = \"256G\",                                 exclusive = TRUE,                                 cores = 8)"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"specifying-which-nodes-should-run-your-tasks","dir":"Articles","previous_headings":"","what":"Specifying which nodes should run your tasks","title":"Parallel Tasks","text":"’ve already set number cores task needs, one way might limit nodes capable running task. Additionally, specific memory requirements tasks, specific queue run tasks , even specific nodes run , can specified arguments hipercow_resources several different ways, outline .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"memory-requests","dir":"Articles","previous_headings":"Specifying which nodes should run your tasks","what":"Memory requests","title":"Parallel Tasks","text":"Two methods currently provided specifying memory usage. can specified integer number gigabytes, alternative strings \"64G” \"1T\" represent 64Gb, 1Tb respectively. memory_per_node specifies simply task run node least much memory. Remember node’s memory shared tasks running node, also consider specifying cores = Inf, exclusive = TRUE think ’ll need whole node’s memory . launching many tasks, know maximum memory task needs, can specify memory_per_process tell cluster . cluster avoid allocating many tasks node, combined memory needed tasks exceed node . can’t really guaranteed, unless everyone agrees set memory_per_process, help common case tasks might stacked node together.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"running-on-specific-nodes","dir":"Articles","previous_headings":"Specifying which nodes should run your tasks","what":"Running on specific nodes","title":"Parallel Tasks","text":"present, nodes new cluster similar , partitioning nodes users groups. free--, little variation specification nodes. may change time, cluster grows, user base grows. future, may nodes, queues nodes, appropriate tasks others, either specification, groups priority access nodes may purchased, example. ’ve already noted specifying cores memory requirements cause tasks run node meeting requirements. Additionally, can explicitly say tasks submitted particular queue, tasks run particular named nodes. See .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"selecting-by-queue","dir":"Articles","previous_headings":"Specifying which nodes should run your tasks > Running on specific nodes","what":"Selecting by queue","title":"Parallel Tasks","text":"present, new cluster one queue general use, called AllNodes containing, says, available compute nodes. times though, workshops example run Training queue, strict limits, ensure ’ve capacity demonstrate cluster use live setting. also may necessary future partition set nodes, either capabilities becomes significant users, research group might purchased , allow particular group protected access period. ’s see queues, choose one, using example cluster. , pass resources task_create_ functions.","code":"hipercow_cluster_info()$resources$queues #> [1] \"alltasks\" \"bigmem\"   \"fast\" resources <- hipercow_resources(queue = \"bigmem\")"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"selecting-by-node-names","dir":"Articles","previous_headings":"Specifying which nodes should run your tasks > Running on specific nodes","what":"Selecting by node names","title":"Parallel Tasks","text":"Even rarely, may particular named node want run . past, instance, specific nodes unique hardware (large RAM large disks). occasionally, may want try replicate failure rerunning task using node failure occurred. , using example cluster, can set requested_nodes argument, :- , resources gets passed one task_create_ functions.","code":"hipercow_cluster_info()$resources$nodes #> [1] \"node-1\" \"node-2\" \"gpu-3\"  \"gpu-4\" resources <- hipercow_resources(   requested_nodes = c(\"gpu-3\", \"gpu-4\"))"},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"task-time-limits-and-scheduling","dir":"Articles","previous_headings":"","what":"Task time limits and scheduling","title":"Parallel Tasks","text":"clusters years essentially run basis good , rather many limits long tasks can run , much resource can use. fairly small department, nice way work, meaning can usually get resources need, even needs quite demanding period time. Usage fluctuates depending deadlines development cycle projects. relatively rare many people projects demanding needs time, capacity cluster becomes problematic. needs coincide, resolve mainly communication, rather cluster rules. said, hipercow offers options limiting long tasks can run , specifying tasks can run cluster, also allows politely allow tasks take priority . know long tasks take, potential future priorities smaller faster tasks ahead larger slower ones.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"the-maximum-runtime","dir":"Articles","previous_headings":"Task time limits and scheduling","what":"The maximum runtime","title":"Parallel Tasks","text":"know long task take, ’d like abort takes longer, use max_runtime argument requesting resources. can specify integer number minutes, strings involving letters d, h m, days, hours minutes, \"40d” \"1h30\". might useful stochastic fitting tasks might converging, ’d like time limit tasks aborted. perhaps task ’d like run check early stages look good.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"delaying-tasks-starting","dir":"Articles","previous_headings":"Task time limits and scheduling","what":"Delaying tasks starting","title":"Parallel Tasks","text":"launch large number time consuming tasks, crucially urgent, may helpful others start running cluster outside working hours. can setting hold_until argument hipercow_resources. number formats allowed:- integer represents number minutes. Strings form \"5h\" \"1h30\" \"2d\" can delay hours, minutes days. R’s Date type can used indicate midnight given date. R’s POSIXt type date time represented. \"tonight\" makes task wait 7pm evening starting. \"midnight\" delays task tomorrow begins. \"weekend\" delays task midnight Saturday.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/parallel.html","id":"lowering-your-priority","dir":"Articles","previous_headings":"Task time limits and scheduling","what":"Lowering your priority","title":"Parallel Tasks","text":"launch large number tasks, another way polite colleagues set priority = \"low\" hipercow_resources. allows tasks lower queue normal priority overtake low priority tasks run available resources first. Effectively, means can launch large volumes tasks without annoying people, getting available resources, without holding others much also need something run. never causes running tasks get cancelled; relevant available resources node scheduler consider tasks allocate resources . Therefore, low priority works best additionally tasks don’t take long run, reasonably frequent opportunities scheduler decide .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/stan.html","id":"local-installations","dir":"Articles","previous_headings":"","what":"Local installations","title":"Using stan","text":"rstan package available CRAN historically lagged releases available directly stan developers. can install rstan CRAN cmdstanr needs installed stan repo. time writing, links official documentation: rstan cmdstanr need install suitable C++ toolchain. Please refer stan docs details , aware information found StackOverflow stan discussion forums often date. usually need moderately recent version R, .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/stan.html","id":"cmdstan-on-the-cluster","dir":"Articles","previous_headings":"","what":"CmdStan on the cluster","title":"Using stan","text":"CmdStan interface compiles stan programs standalone executables, somewhat isolates stan Rtools toolchain. newer approach using rstan. two parts ; cmdstanr R package CmdStan executables.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/stan.html","id":"installation-and-versions","dir":"Articles","previous_headings":"CmdStan on the cluster","what":"Installation and versions","title":"Using stan","text":"version package use machine important instructions (though may important depending model compiling). cluster, need install recent version cmdstanr (0.8.1 newer, released 6 June 2024), available stan repositories. pkgdepends.txt contain: (sure use https://mc-stan.org/r-packages repo, still widely noted documentation ships older versions, broken.) currently support CmdStan version 2.35.0 - like support multiple versions , internal gymnastics cmdstanr make quite hard . Please let us know need specific version different whatever installed, install update instructions can select . easy make mess cluster following instructions stan developers assume user machine, stan main piece software interested running. especially case follow instructions found StackOverflow may refer previous versions. fallout restricted working space though. Within hipercow task, please run: cmdstanr::install_cmdstan: install 1GB small files onto network shares. need specific version please let us know make one available cmdstanr::check_cmdstan_toolchain(fix = TRUE): sorts damage, including corrupting Rtools installation need install packages","code":"repo::https://stan-dev.r-universe.dev cmdstanr"},{"path":"https://mrc-ide.github.io/hipercow/articles/stan.html","id":"compiling-models","dir":"Articles","previous_headings":"CmdStan on the cluster","what":"Compiling models","title":"Using stan","text":"use cmdstandr::cmdstan_model() generate file directory .stan file. fine laptop, poor choice almost context, especially might submit one job time (, given using cluster, probably ). ’ll need pass path dir every call cmdstanr::cmdstan_model() - unfortunately ’s way automatically. rather can use Using tempdir() guarantees every process starts use different directory, won’t think much. two issues mitigated : toolchain used compile stan models differs laptop cluster (true using different operating system, minor version R, different version Rtools, different version cmdstanr) model compiled machine work cluster, perhaps difficult--diagnose errors. launch two tasks cluster, every job try compile model time, try write file. one tasks succeed, others failing due permissions issues (windows write file open). (potentially large) downside using tempdir() every time start task uses stan program compile . Even simple program quite slow (say two minutes “hello world” type problem). deciding going cause issues, think long take run code. ’s going run hour, delay may tolerable. However, program fast compiled, might become significant issue. want reuse models need way () hipercow tasks reuse compiled models (b) task tries recompile model created. might explore something like first submitting task runs (creating models-hipercow directory, stan error yet exist, won’t create ). task completes successfully submitting series tasks use model. include exact statement load model. appears mechanism either prevent compilation (can pass compile = FALSE model unusable, even compiled), test see model date. can probably get away : can use place cmdstanr::cmdstan_model, though behave expected models include files. Good luck.","code":"mod <- cmdstanr::cmdstan_model(\"model.stan\") mod <- cmdstanr::cmdstan_model(\"model.stan\", dir = tempdir()) mod <- cmdstanr::cmdstan_model(\"model.stan\", dir = \"models-hipercow\") cmdstan_model_but_dont_recompile <- function(path, dir = \".\", ...) {   path_exe <- file.path(dir, paste0(path, \".exe\"))   is_current <- file.exists(path_exe) &&     file.info(path_exe)$mtime > file.info(path)$mtime   if (!is_current) {     stop(sprintf(\"stan model '%s' at '%s' is out of date!\",                  path, dir))   }   cmdstanr::cmdstan_model(path, exe_file = NULL, compile = TRUE,                           dir = dir, ...) }"},{"path":"https://mrc-ide.github.io/hipercow/articles/stan.html","id":"a-worked-example","dir":"Articles","previous_headings":"CmdStan on the cluster","what":"A worked example","title":"Using stan","text":"example designed partly can test everything works, may ask run difficulty. Start basic hipercow Windows setup: simple stan model code.stan: little wrapper around , code.R, compiles model draws samples: need add code.R default environment: provision.txt : Install everything hipercow_provision usual Now can run stan task (need decent timeout compilation can slow): logs stan task, hopefully worked , . Note drawing samples took little time (look last bit stan output) compared total time taken task (see last line hipercow output). compilation models succeeds, remains much easier job using model amazing science.","code":"library(hipercow) hipercow_init(driver = \"dide-windows\") #> ✔ Initialised hipercow at '.' #> ✔ Configured hipercow to use 'dide-windows' data {   int<lower=0> N;   array[N] int<lower=0, upper=1> y; } parameters {   real<lower=0, upper=1> theta; } model {   theta ~ beta(1, 5); // uniform prior on interval 0,1   y ~ bernoulli(theta); } run_stan <- function() {   path <- tempfile()   dir.create(path)   mod <- cmdstanr::cmdstan_model('code.stan', dir = path)   stan_data <- list(N = 10, y = c(0, 1, 0, 0, 0, 0, 0, 0, 0, 1))   fit_mcmc <- mod$sample(     data = stan_data,     seed = 123,     chains = 2) } hipercow_environment_create(sources = \"code.R\") #> ✔ Created environment 'default' repo::https://stan-dev.r-universe.dev cmdstanr hipercow_provision() #> ℹ Looking for active tasks before installation #> ✔ No tasks running #> ✔ Selected provisioning method 'pkgdepends' #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: I:/bootstrap/4.4.0 #> Installing into library: hipercow/lib/windows/4.4.0 #> Using method pkgdepends #> Running in path: V:/cluster/hipercow-vignette/hv-20240612-15d41827525afc #> Library paths: #>   - V:/cluster/hipercow-vignette/hv-20240612-15d41827525afc/hipercow/lib/windows/4.4.0 #>   - C:/Program Files/R/R-4.4.0/library #> id: 20240612125140 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://stan-dev.r-universe.dev #> • https://cloud.r-project.org #>  #> ── refs  #> • cmdstanr #>  #> ✔ Updated metadata database: 3.15 MB in 6 files. #>  #> ℹ Updating metadata database #> ✔ Updating metadata database ... done #> + abind            1.4-5       #> + backports        1.5.0       #> + checkmate        2.3.1       #> + cli              3.6.2       #> + cmdstanr         0.8.1       #> + data.table       1.15.4      #> + distributional   0.4.0       #> + fansi            1.0.6       #> + generics         0.1.3       #> + glue             1.7.0       #> + jsonlite         1.8.8       #> + lifecycle        1.0.4       #> + magrittr         2.0.3       #> + matrixStats      1.3.0       #> + numDeriv         2016.8-1.1  #> + pillar           1.9.0       #> + pkgconfig        2.0.3       #> + posterior        1.5.0.9000  #> + processx         3.8.4       #> + ps               1.7.6       #> + R6               2.5.1       #> + rlang            1.1.4       #> + tensorA          0.36.2.1    #> + tibble           3.2.1       #> + utf8             1.2.4       #> + vctrs            0.6.5       #> + withr            3.0.0       #> ℹ No downloads are needed, 27 pkgs are cached #> ✔ Got checkmate 2.3.1 (x86_64-w64-mingw32) (746.60 kB) #> ✔ Got R6 2.5.1 (i386+x86_64-w64-mingw32) (84.99 kB) #> ✔ Got magrittr 2.0.3 (x86_64-w64-mingw32) (229.48 kB) #> ✔ Got posterior 1.5.0.9000 (i386+x86_64-w64-mingw32) (1.14 MB) #> ✔ Got distributional 0.4.0 (i386+x86_64-w64-mingw32) (432.57 kB) #> ✔ Got glue 1.7.0 (x86_64-w64-mingw32) (163.35 kB) #> ✔ Got fansi 1.0.6 (x86_64-w64-mingw32) (323.11 kB) #> ✔ Got generics 0.1.3 (i386+x86_64-w64-mingw32) (84.13 kB) #> ✔ Got pkgconfig 2.0.3 (i386+x86_64-w64-mingw32) (22.82 kB) #> ✔ Got cli 3.6.2 (x86_64-w64-mingw32) (1.36 MB) #> ✔ Got data.table 1.15.4 (x86_64-w64-mingw32) (2.42 MB) #> ✔ Got matrixStats 1.3.0 (x86_64-w64-mingw32) (551.79 kB) #> ✔ Got withr 3.0.0 (i386+x86_64-w64-mingw32) (249.66 kB) #> ✔ Got cmdstanr 0.8.1 (i386+x86_64-w64-mingw32) (1.57 MB) #> ✔ Got utf8 1.2.4 (x86_64-w64-mingw32) (150.86 kB) #> ✔ Got tibble 3.2.1 (x86_64-w64-mingw32) (695.34 kB) #> ✔ Got lifecycle 1.0.4 (i386+x86_64-w64-mingw32) (140.92 kB) #> ✔ Got processx 3.8.4 (x86_64-w64-mingw32) (688.52 kB) #> ✔ Got jsonlite 1.8.8 (x86_64-w64-mingw32) (1.11 MB) #> ✔ Got ps 1.7.6 (x86_64-w64-mingw32) (558.56 kB) #> ✔ Got pillar 1.9.0 (i386+x86_64-w64-mingw32) (663.34 kB) #> ✔ Got vctrs 0.6.5 (x86_64-w64-mingw32) (1.36 MB) #> ✔ Installed cmdstanr 0.8.1  (2.5s) #> ✔ Installed posterior 1.5.0.9000  (2.4s) #> ✔ Installed R6 2.5.1  (2.6s) #> ✔ Installed abind 1.4-5  (2.8s) #> ✔ Installed backports 1.5.0  (2.9s) #> ✔ Installed checkmate 2.3.1  (3.1s) #> ✔ Installed distributional 0.4.0  (3.1s) #> ✔ Installed fansi 1.0.6  (3.3s) #> ✔ Installed generics 0.1.3  (3.4s) #> ✔ Installed glue 1.7.0  (3.5s) #> ✔ Installed numDeriv 2016.8-1.1  (3.3s) #> ✔ Installed pkgconfig 2.0.3  (3.3s) #> ✔ Installed processx 3.8.4  (3.4s) #> ✔ Installed lifecycle 1.0.4  (4.1s) #> ✔ Installed tensorA 0.36.2.1  (3.4s) #> ✔ Installed ps 1.7.6  (3.8s) #> ✔ Installed jsonlite 1.8.8  (4.7s) #> ✔ Installed pillar 1.9.0  (4.5s) #> ✔ Installed cli 3.6.2  (5.4s) #> ✔ Installed utf8 1.2.4  (4.3s) #> ✔ Installed magrittr 2.0.3  (5.3s) #> ✔ Installed rlang 1.1.4  (4.8s) #> ✔ Installed withr 3.0.0  (4.7s) #> ✔ Installed tibble 3.2.1  (5.1s) #> ✔ Installed vctrs 0.6.5  (5.2s) #> ✔ Installed matrixStats 1.3.0  (6.4s) #> ✔ Installed data.table 1.15.4  (7.2s) #> ✔ Summary:   27 new  in 1m 48.2s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/windows/4.4.0/.conan/20240612125140' #> Done! #> ✔ Installation script finished successfully in 26.32 secs id <- task_create_expr(run_stan()) #> ✔ Submitted task '0f7dcc43b7ff14f57182bdf760add181' using 'dide-windows' task_wait(id, timeout = 600) #> [1] TRUE task_log_show(id) #>  #> ── hipercow 1.0.12 running at 'V:/cluster/hipercow-vignette/hv-20240612-15d41827 #> ℹ library paths: #> • #> V:/cluster/hipercow-vignette/hv-20240612-15d41827525afc/hipercow/lib/windows/4.4.0 #> • I:/bootstrap/4.4.0 #> • C:/Program Files/R/R-4.4.0/library #> ℹ id: 0f7dcc43b7ff14f57182bdf760add181 #> ℹ starting at: 2024-06-12 13:52:07.305275 #> ℹ Task type: expression #>   • Expression: run_stan() #>   • Locals: (none) #>   • Environment: default #>   • Environment variables: R_GC_MEM_GROW, CMDSTAN, and CMDSTANR_USE_RTOOLS #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #> In file included from stan/lib/stan_math/stan/math/rev/fun.hpp:75, #>                  from stan/lib/stan_math/stan/math/rev.hpp:12, #>                  from stan/src/stan/model/log_prob_grad.hpp:4, #>                  from src/cmdstan/command_helper.hpp:15, #>                  from src/cmdstan/command.hpp:13, #>                  from src/cmdstan/main.cpp:1: #> stan/lib/stan_math/stan/math/rev/fun/generalized_inverse.hpp: In function 'auto stan::math::generalized_inverse(const VarMat&)': #> stan/lib/stan_math/stan/math/rev/fun/generalized_inverse.hpp:67: note: '-Wmisleading-indentation' is disabled from this point onwards, since column-tracking was disabled due to the size of the code/headers #>    67 |   if (G.size() == 0) #>       |  #>  #> stan/lib/stan_math/stan/math/rev/fun/generalized_inverse.hpp:67: note: adding '-flarge-source-files' will allow for more column-tracking support, at the expense of compilation time and memory #>  #> Running MCMC with 2 sequential chains... #>  #> Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup)  #> Chain 1 Iteration:  100 / 2000 [  5%]  (Warmup)  #> Chain 1 Iteration:  200 / 2000 [ 10%]  (Warmup)  #> Chain 1 Iteration:  300 / 2000 [ 15%]  (Warmup)  #> Chain 1 Iteration:  400 / 2000 [ 20%]  (Warmup)  #> Chain 1 Iteration:  500 / 2000 [ 25%]  (Warmup)  #> Chain 1 Iteration:  600 / 2000 [ 30%]  (Warmup)  #> Chain 1 Iteration:  700 / 2000 [ 35%]  (Warmup)  #> Chain 1 Iteration:  800 / 2000 [ 40%]  (Warmup)  #> Chain 1 Iteration:  900 / 2000 [ 45%]  (Warmup)  #> Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup)  #> Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling)  #> Chain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling)  #> Chain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling)  #> Chain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling)  #> Chain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling)  #> Chain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling)  #> Chain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling)  #> Chain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling)  #> Chain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling)  #> Chain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling)  #> Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling)  #> Chain 1 finished in 0.0 seconds. #> Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup)  #> Chain 2 Iteration:  100 / 2000 [  5%]  (Warmup)  #> Chain 2 Iteration:  200 / 2000 [ 10%]  (Warmup)  #> Chain 2 Iteration:  300 / 2000 [ 15%]  (Warmup)  #> Chain 2 Iteration:  400 / 2000 [ 20%]  (Warmup)  #> Chain 2 Iteration:  500 / 2000 [ 25%]  (Warmup)  #> Chain 2 Iteration:  600 / 2000 [ 30%]  (Warmup)  #> Chain 2 Iteration:  700 / 2000 [ 35%]  (Warmup)  #> Chain 2 Iteration:  800 / 2000 [ 40%]  (Warmup)  #> Chain 2 Iteration:  900 / 2000 [ 45%]  (Warmup)  #> Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup)  #> Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling)  #> Chain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling)  #> Chain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling)  #> Chain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling)  #> Chain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling)  #> Chain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling)  #> Chain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling)  #> Chain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling)  #> Chain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling)  #> Chain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling)  #> Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling)  #> Chain 2 finished in 0.0 seconds. #>  #> Both chains finished successfully. #> Mean chain execution time: 0.0 seconds. #> Total execution time: 0.8 seconds. #>  #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✔ status: success #> ℹ finishing at: 2024-06-12 13:52:07.305275 (elapsed: 4.633 mins)"},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"my-task-failed","dir":"Articles","previous_headings":"","what":"My task failed","title":"Troubleshooting","text":"Oh !","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"caused-by-an-error-in-your-code","dir":"Articles","previous_headings":"My task failed","what":"Caused by an error in your code","title":"Troubleshooting","text":"task status failure probably indicates error code. lots reasons , first challenge working happened. task fail, task_status() report failure first place look result task . Unlike error console, error happens cluster can returned inspected: case error function mysimulation exist! ’ve forgotten tell cluster find . place worth looking task log (via task_log_show()), provides diagnostic information. often ask show us. case task log anything interesting . ’s another example, something might work perfectly well machine, fails cluster: error, bit less informative time: log gives better idea going - file c:/myfile.csv exist (found cluster; using relative paths much preferred absolute paths) real content error message present warning! can also get warnings list warnings generated execution task (even succeeds). traceback also shows happened:","code":"id <- task_create_expr(mysimulation(10)) #> ✔ Submitted task '3f3e1988520a51e194e64986318402bc' using 'example' task_status(id) #> [1] \"failure\" task_result(id) #> <simpleError in mysimulation(10): could not find function \"mysimulation\"> task_log_show(id) #>  #> ── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-33ca20eec34f'  #> ℹ library paths: #> • /home/runner/work/_temp/Library #> • /opt/R/4.5.0/lib/R/site-library #> • /opt/R/4.5.0/lib/R/library #> ℹ id: 3f3e1988520a51e194e64986318402bc #> ℹ starting at: 2025-05-13 06:45:40.676054 #> ℹ Task type: expression #> • Expression: mysimulation(10) #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✖ status: failure #> ✖ Error: could not find function \"mysimulation\" #> ℹ finishing at: 2025-05-13 06:45:40.676054 (elapsed: 0.2832 secs) id <- task_create_expr(read.csv(\"c:/myfile.csv\")) #> ✔ Submitted task 'fc41c66200777b7f6cd48db6bdcdeb5c' using 'example' task_result(id) #> <simpleError in file(file, \"rt\"): cannot open the connection> task_log_show(id) #>  #> ── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-33ca20eec34f'  #> ℹ library paths: #> • /home/runner/work/_temp/Library #> • /opt/R/4.5.0/lib/R/site-library #> • /opt/R/4.5.0/lib/R/library #> ℹ id: fc41c66200777b7f6cd48db6bdcdeb5c #> ℹ starting at: 2025-05-13 06:45:41.984056 #> ℹ Task type: expression #> • Expression: read.csv(\"c:/myfile.csv\") #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✖ status: failure #> ✖ Error: cannot open the connection #> ! 1 warning found: #> • cannot open file 'c:/myfile.csv': No such file or directory #> ℹ finishing at: 2025-05-13 06:45:41.984056 (elapsed: 0.2978 secs) task_result(id)$warnings #> [[1]] #> <simpleWarning in file(file, \"rt\"): cannot open file 'c:/myfile.csv': No such file or directory> task_result(id)$trace #>      ▆ #>   1. ├─rlang::try_fetch(...) #>   2. │ ├─base::tryCatch(...) #>   3. │ │ └─base (local) tryCatchList(expr, classes, parentenv, handlers) #>   4. │ │   └─base (local) tryCatchOne(expr, names, parentenv, handlers[[1L]]) #>   5. │ │     └─base (local) doTryCatch(return(expr), name, parentenv, handler) #>   6. │ └─base::withCallingHandlers(...) #>   7. ├─hipercow:::task_eval_expression(data, envir, verbose) #>   8. │ ├─hipercow:::eval_with_hr(...) #>   9. │ │ └─base::force(expr) #>  10. │ └─base::eval(data$expr, envir) #>  11. │   └─base::eval(data$expr, envir) #>  12. ├─utils::read.csv(\"c:/myfile.csv\") #>  13. │ └─utils::read.table(...) #>  14. │   └─base::file(file, \"rt\") #>  15. └─base::.handleSimpleError(...) #>  16.   └─rlang (local) h(simpleError(msg, call)) #>  17.     └─handlers[[2L]](cnd)"},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"caused-by-an-error-during-startup","dir":"Articles","previous_headings":"My task failed","what":"Caused by an error during startup","title":"Troubleshooting","text":"harder troubleshoot can still pull information . example real-world case illustrates one issues using shared filesystem way . Suppose code mycode.R: can create environment code use just fine: …imagine ’re editing file save file syntactically correct: either submit task, task previously submitted gets run (happen ages submit cluster busy). error happened getting code - happening source files loaded. log makes bit clearer:","code":"times2 <- function(x) {   2 * x } hipercow_environment_create(sources = \"mycode.R\") #> ✔ Created environment 'default' id <- task_create_expr(times2(10)) #> ✔ Submitted task '7e2058cd8aa747d2c595a73bd2815f4a' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] 20 times2 <- function(x) {   2 * x } newfun <- function(x) id <- task_create_expr(times2(10)) #> ✔ Submitted task '5b67476501b8655f11e87c980aa665a3' using 'example' task_wait(id) #> [1] FALSE task_status(id) #> [1] \"failure\" task_log_show(id) #>  #> ── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-33ca20eec34f'  #> ℹ library paths: #> • /home/runner/work/_temp/Library #> • /opt/R/4.5.0/lib/R/site-library #> • /opt/R/4.5.0/lib/R/library #> ℹ id: 5b67476501b8655f11e87c980aa665a3 #> ℹ starting at: 2025-05-13 06:45:44.741024 #> ℹ Task type: expression #> • Expression: times2(10) #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ℹ Loading environment 'default'... #> • packages: (none) #> • sources: mycode.R #> • globals: (none) #> ✖ status: failure #> ✖ Error: 5:0: unexpected end of input 3: } 4: newfun <- function(x)   ^ #> ℹ finishing at: 2025-05-13 06:45:44.741024 (elapsed: 0.3015 secs)"},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"my-task-got-stuck-at-submitted","dir":"Articles","previous_headings":"My task failed","what":"My task got stuck at submitted","title":"Troubleshooting","text":"(Previous users didehpc may recognise stuck PENDING). annoying one, can happen many reasons. can see via web interface Microsoft cluster tools task failed hipercow reporting pending. happens something failed script runs hipercow code runs cluster. Things triggered situation past: error Microsoft cluster tools misconfigured node (sometimes missing particular software) networking issue Gremlins Network path mapping error Running disk space submitting job doubtless others. suspect task become stuck submitted (actually running ) try one : run task_info() id fetch true id tell discrepancy checking web portal see task really listed queued. Check failed tasks see ’s look outer logs (task_log_show(id, outer = TRUE)) show scheduler’s logs task, may informative.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"my-code-works-on-my-computer-but-not-on-the-cluster","dir":"Articles","previous_headings":"My task failed","what":"My code works on my computer but not on the cluster","title":"Troubleshooting","text":"case, something different cluster sees world, computer sees . Look logs try find reason failing tasks . variables global R environment local computer, code relies upon, won’t present cluster? local R packages sources loaded haven’t told hipercow ? system variables, dependencies enable task work locally, won’t set cluster node? referring files visible local machine, cluster? referring C: instance? (Rarely:) viewing cached version network storage local computer, synced real network storage view cluster ? Check run disk-space. Q: quota normally 15Gb. running C code, check causes indeterminate failures, uninitialised variables, array --bounds errors. unpredictable errors nature, surprisingly often might get away local computer, cluster node behaves differently. running stochastic code, check really using random number seeds. expecting exactly result cluster job, check code produces answer repeat locally.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"some-of-my-tasks-work-on-the-cluster-but-others-fail","dir":"Articles","previous_headings":"My task failed","what":"Some of my tasks work on the cluster, but others fail","title":"Troubleshooting","text":"Look logs try find reason failing tasks . Try rerunning failed tasks. set passes, set fails? case, consider makes tasks different - perhaps task-specific input data parameters cause failures. find messages Error allocating vector... std::bad_alloc, try work memory usage single task. Perhaps run locally task manager (Windows), top/htop (macOS/Linux) running, watch see memory usage . task single-core, consider total memory used run 8 16 instances cluster machine. total memory exceeds available, behaviour undefined, tasks likely fail. example, note someone else’s memory-hungry combination tasks may affect small-memory task, run node. don’t enforce memory limits tasks, whole, nice convenient, carries risk can happen. Always check ’re running disk space. Q: quota normally 15Gb. Find node tasks running . consistently get errors one node, others, get touch Wes, get node failures time time, fault obvious first.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"my-code-is-slower-on-the-cluster-than-running-locally","dir":"Articles","previous_headings":"My task failed","what":"My code is slower on the cluster than running locally!","title":"Troubleshooting","text":"expected, especially single-core tasks. Cluster nodes often aiming provide larger throughput, rather better linear performance, single task may run slower cluster node computer. cluster node might able run 16 tasks , without taking longer, continue using local computer local things. still insufficient, still want compare timings way, check cluster exactly work local computer.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"i-cant-connect-to-the-cluster","dir":"Articles","previous_headings":"","what":"I can’t connect to the cluster","title":"Troubleshooting","text":"lots possible causes , ways might manifest error message, example: (add error messages catch ). time get , ’ve thrown pretty generic error reason can’t tell happened. Possible reasons might see error like : local internet connection failed ZScaler session timed needs re-authentication cluster session timed DIDE password expired can check running work many common points failure report back work. want help diagnosing sort error, expect see output command. work, still looks like connection problems, try launch simple job. work, want ask help, like see whole output command. works, actual job work, something submitting causing problem. case, asking help, need know something code, case read next section.","code":"Error in client_parse_submit(httr_text(r), 1L) :   Job submission has likely failed; could be a login error dide_check() hipercow_hello()"},{"path":"https://mrc-ide.github.io/hipercow/articles/troubleshooting.html","id":"asking-for-help","dir":"Articles","previous_headings":"","what":"Asking for help","title":"Troubleshooting","text":"need help, can ask “Cluster” teams channel. better emailing Rich Wes directly may time respond, may leave. asking help really important make easy possible us help . surprisingly hard well, ask first take look two short articles: ask good question create minimal, reproducible example Things need know: contents hipercow::hipercow_configuration() ’ve tried values errors (just occurred!) Logs offending task often, get requests help information run, packages versions installed, etc. means message sits see , ’ll ask clarification - message sits see , respond little information, may days finally discover root cause problem, point ’re quite fed . never complain provide “much” information good effort outline problem . Don’t say Hi, running cluster task, seems like failed. ’m sure worked day though! know problem ? say Since yesterday, cluster task stopped working. DIDE username alicebobson configuration : set cluster task task 43333cbd79ccbf9ede79556b592473c8 one failed error, log says sort information problem may just jump us, may able create error - either way may able work problem get back solution rather request information. tips, reasons may directed page: Please provide whole error message. provide line think interesting. can store great many lines text Teams, can always attach file need . really like see much information possible. Please provide screenshots photos text unless reason computer lost ability copy paste. Please provide much context possible working , . Please don’t assume remember anything told us previous discussion - ’ve probably forgotten context problem point ask . Please let us know got ; asked us problem solved , please let us know working, anything extra get working, anything can make documentation clearer. general, please try reduce chance response message another question us . may feel like get answer quicker don’t try investigate end, take much longer overall use everyone’s time. want help, expect slower responses lots discovery find problem , take longer find time energy start digging. information provide, likely can spot error.","code":"-- hipercow configuration ----- [etc] # include short script here if you can! # contents of task_log_show(id) here"},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Workers","text":"get started, need rrq package, already (installed automatically hipercow, can skip step want) ’ll want recent version; using version 0.7.21","code":"install.packages(   \"rrq\",   repos = c(\"https://mrc-ide.r-universe.dev\", \"https://cloud.r-project.org\")) library(hipercow) hipercow_init(driver = \"dide-windows\") #> ✔ Initialised hipercow at '.' (/home/rfitzjoh/net/home/cluster/hipercow-vignette/hv-20241128-3181c95d685377) #> ✔ Configured hipercow to use 'dide-windows'"},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"the-lightweight-queue-pattern","dir":"Articles","previous_headings":"","what":"The lightweight queue pattern","title":"Workers","text":"interaction rrq done via “controller”; object can use submit tasks query status: interface controller subject change, many ideas feel similar hipercow . controller object just handle can used functions rrq package: thing ’ll need workers. Let’s submit single worker cluster, wait become available: (experimenting , using Testing queue, used finding cluster scripts working). workers submitted task bundles can inspected using bundle name like task: worker remain running 10 minutes last piece work runs.","code":"r <- hipercow_rrq_controller() #> ✔ Created new rrq queue 'rrq:7010f758' r #> <rrq_controller: rrq:7010f758> resources <- hipercow_resources(queue = \"Testing\") info <- hipercow_rrq_workers_submit(1, resources = resources) #> ✔ Using existing rrq queue 'rrq:7010f758' #> ✔ Submitted task '8b61e994eecba7e711ea4aa9fa1dff2a' using 'dide-windows' #> ✔ Created bundle 'cluttered_wildcat' with 1 task #>  ⠙ Waiting for worker to start [2s] [K  ⠹ Waiting for worker to start [2.2s] [K  ⠸ #> Waiting for worker to start [2.4s] [K  ⠼ Waiting for worker to start [2.6s] [K  ⠴ #> Waiting for worker to start [2.8s] [K  ⠦ Waiting for worker to start [3s] [K  ⠧ #> Waiting for worker to start [3.2s] [K  ⠇ Waiting for worker to start [3.4s] [K  ⠏ #> Waiting for worker to start [3.6s] [K  ⠋ Waiting for worker to start [3.8s] [K  ⠙ #> Waiting for worker to start [4s] [K  ⠹ Waiting for worker to start [4.2s] [K  ⠸ #> Waiting for worker to start [4.4s] [K  ⠼ Waiting for worker to start [4.6s] [K  ⠴ #> Waiting for worker to start [4.8s] [K  ⠦ Waiting for worker to start [5s] [K  ⠧ #> Waiting for worker to start [5.2s] [K  ⠇ Waiting for worker to start [5.4s] [K  ⠏ #> Waiting for worker to start [5.6s] [K  ⠋ Waiting for worker to start [5.8s] [K  ⠙ #> Waiting for worker to start [6s] [K  ⠹ Waiting for worker to start [6.2s] [K  ⠸ #> Waiting for worker to start [6.4s] [K  ⠼ Waiting for worker to start [6.6s] [K  ⠴ #> Waiting for worker to start [6.8s] [K  ⠦ Waiting for worker to start [7s] [K  ⠧ #> Waiting for worker to start [7.2s] [K  ⠇ Waiting for worker to start [7.4s] [K  ⠏ #> Waiting for worker to start [7.6s] [K  ⠋ Waiting for worker to start [7.8s] [K  ⠙ #> Waiting for worker to start [8s] [K  ⠹ Waiting for worker to start [8.2s] [K  ⠸ #> Waiting for worker to start [8.4s] [K  ⠼ Waiting for worker to start [8.6s] [K  ⠴ #> Waiting for worker to start [8.8s] [K  ⠦ Waiting for worker to start [9s] [K  ⠧ #> Waiting for worker to start [9.2s] [K  ⠇ Waiting for worker to start [9.4s] [K  ⠏ #> Waiting for worker to start [9.6s] [K  ⠋ Waiting for worker to start [9.8s] [K  ⠙ #> Waiting for worker to start [10s] [K  ⠹ Waiting for worker to start [10.2s] [K  ⠸ #> Waiting for worker to start [10.4s] [K  ⠼ Waiting for worker to start [10.6s] [K  ⠴ #> Waiting for worker to start [10.8s] [K  ⠦ Waiting for worker to start [11s] [K  ⠧ #> Waiting for worker to start [11.2s] [K  ⠇ Waiting for worker to start [11.4s] [K  ⠏ #> Waiting for worker to start [11.6s] [K  ⠋ Waiting for worker to start [11.8s] [K  ⠙ #> Waiting for worker to start [12s] [K  ⠹ Waiting for worker to start [12.2s] [K  ⠸ #> Waiting for worker to start [12.4s] [K  ⠼ Waiting for worker to start [12.6s] [K  ⠴ #> Waiting for worker to start [12.8s] [K  ⠦ Waiting for worker to start [13s] [K  ⠧ #> Waiting for worker to start [13.2s] [K  ⠇ Waiting for worker to start [13.4s] [K  ⠏ #> Waiting for worker to start [13.6s] [K  ⠋ Waiting for worker to start [13.8s] [K  ⠙ #> Waiting for worker to start [14s] [K  ⠹ Waiting for worker to start [14.2s] [K  ⠸ #> Waiting for worker to start [14.4s] [K  ⠼ Waiting for worker to start [14.6s] [K  ⠴ #> Waiting for worker to start [14.8s] [K  ⠦ Waiting for worker to start [15s] [K  ⠧ #> Waiting for worker to start [15.2s] [K  ⠇ Waiting for worker to start [15.4s] [K  ⠏ #> Waiting for worker to start [15.6s] [K  ⠋ Waiting for worker to start [15.8s] [K  ⠙ #> Waiting for worker to start [16s] [K  ⠹ Waiting for worker to start [16.2s] [K  ⠸ #> Waiting for worker to start [16.4s] [K  ⠼ Waiting for worker to start [16.6s] [K  ⠴ #> Waiting for worker to start [16.8s] [K  ⠦ Waiting for worker to start [17s] [K  ⠧ #> Waiting for worker to start [17.2s] [K  ⠇ Waiting for worker to start [17.4s] [K  ⠏ #> Waiting for worker to start [17.6s] [K  ⠋ Waiting for worker to start [17.8s] [K  ⠙ #> Waiting for worker to start [18s] [K  ⠹ Waiting for worker to start [18.3s] [K  ⠸ #> Waiting for worker to start [18.5s] [K  ⠼ Waiting for worker to start [18.7s] [K  ⠴ #> Waiting for worker to start [18.9s] [K  ⠦ Waiting for worker to start [19.1s] [K  ⠧ #> Waiting for worker to start [19.3s] [K  ⠇ Waiting for worker to start [19.5s] [K  ⠏ #> Waiting for worker to start [19.7s] [K  ⠋ Waiting for worker to start [19.9s] [K  ⠙ #> Waiting for worker to start [20.1s] [K  ⠹ Waiting for worker to start [20.3s] [K  ⠸ #> Waiting for worker to start [20.5s] [K  ⠼ Waiting for worker to start [20.7s] [K  ⠴ #> Waiting for worker to start [20.9s] [K  ⠦ Waiting for worker to start [21.1s] [K  ⠧ #> Waiting for worker to start [21.3s] [K  ⠇ Waiting for worker to start [21.5s] [K  ⠏ #> Waiting for worker to start [21.7s] [K  ⠋ Waiting for worker to start [21.9s] [K  ⠙ #> Waiting for worker to start [22.1s] [K  ⠹ Waiting for worker to start [22.3s] [K  ⠸ #> Waiting for worker to start [22.5s] [K  ⠼ Waiting for worker to start [22.7s] [K  ⠴ #> Waiting for worker to start [22.9s] [K  ⠦ Waiting for worker to start [23.1s] [K  ⠧ #> Waiting for worker to start [23.3s] [K  ⠇ Waiting for worker to start [23.5s] [K  ⠏ #> Waiting for worker to start [23.7s] [K  ⠋ Waiting for worker to start [23.9s] [K  ⠙ #> Waiting for worker to start [24.1s] [K  ⠹ Waiting for worker to start [24.3s] [K  ⠸ #> Waiting for worker to start [24.5s] [K  ⠼ Waiting for worker to start [24.7s] [K  ⠴ #> Waiting for worker to start [24.9s] [K  ⠦ Waiting for worker to start [25.1s] [K  ⠧ #> Waiting for worker to start [25.3s] [K  ⠇ Waiting for worker to start [25.5s] [K  ⠏ #> Waiting for worker to start [25.7s] [K  ⠋ Waiting for worker to start [25.9s] [K  ⠙ #> Waiting for worker to start [26.1s] [K  ⠹ Waiting for worker to start [26.3s] [K  ⠸ #> Waiting for worker to start [26.5s] [K  ⠼ Waiting for worker to start [26.7s] [K  ⠴ #> Waiting for worker to start [26.9s] [K  ⠦ Waiting for worker to start [27.1s] [K  ⠧ #> Waiting for worker to start [27.3s] [K  ⠇ Waiting for worker to start [27.5s] [K  ⠏ #> Waiting for worker to start [27.7s] [K  ⠋ Waiting for worker to start [27.9s] [K  ⠙ #> Waiting for worker to start [28.1s] [K  ⠹ Waiting for worker to start [28.3s] [K  ⠸ #> Waiting for worker to start [28.5s] [K  ⠼ Waiting for worker to start [28.7s] [K  ⠴ #> Waiting for worker to start [28.9s] [K  ⠦ Waiting for worker to start [29.1s] [K  ⠧ #> Waiting for worker to start [29.3s] [K  ⠇ Waiting for worker to start [29.5s] [K  ⠏ #> Waiting for worker to start [29.7s] [K  ⠋ Waiting for worker to start [29.9s] [K  ⠙ #> Waiting for worker to start [30.1s] [K  ⠹ Waiting for worker to start [30.3s] [K  ⠸ #> Waiting for worker to start [30.5s] [K  ⠼ Waiting for worker to start [30.7s] [K  ⠴ #> Waiting for worker to start [30.9s] [K  ⠦ Waiting for worker to start [31.1s] [K  ⠧ #> Waiting for worker to start [31.3s] [K  ⠇ Waiting for worker to start [31.5s] [K   [K info #>       queue_id                 worker_id                          task_id #> 1 rrq:7010f758 rrq-7010f758-ea39208bac92 8b61e994eecba7e711ea4aa9fa1dff2a #>         bundle_name #> 1 cluttered_wildcat hipercow_bundle_status(info$bundle_name) #> [1] \"running\""},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"basic-usage","dir":"Articles","previous_headings":"The lightweight queue pattern","what":"Basic usage","title":"Workers","text":"’ll load rrq package make calls little clearer read: Submitting task works much hipercow, except rather task_create_expr use rrq_task_create_expr pass controller argument: hipercow, id hex string: ’s nothing distinguish task identifier hipercow (just use strings), careful workflows. task, interacting feel familiar can query status, wait fetch result: big difference hipercow fast process ; roundtrip task (hopefully small) fraction second:","code":"library(rrq) id <- rrq_task_create_expr(runif(10)) id #> [1] \"ee7e3e3f5a6f119da1c243ba086b52b9\" rrq_task_status(id) #> [1] \"COMPLETE\" rrq_task_wait(id) #> [1] TRUE rrq_task_result(id) #>  [1] 0.090459940 0.003429649 0.362491860 0.017130037 0.775192023 0.263664258 #>  [7] 0.627378736 0.694402343 0.057331173 0.546824257 system.time({   id <- rrq_task_create_expr(runif(10))   rrq_task_wait(id)   rrq_task_result(id) }) #>    user  system elapsed  #>   0.001   0.001   0.038"},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"scaling-up","dir":"Articles","previous_headings":"The lightweight queue pattern","what":"Scaling up","title":"Workers","text":"Let’s submit 1,000 trivial tasks, using rrq_task_create_bulk_expr, taking square root first thousand positive integers. ’s equivalent task bundle rrq; just returns vector task 1000 task identifiers. can pass vector rrq_task_wait() though, fetch results using rrq_task_results() (note pluralisation; rrq_task_results() always returns list, rrq_task_result() fetches single task result). process taken 2.12 seconds, likely much faster submitting many tasks directly.","code":"ids <- rrq_task_create_bulk_expr(sqrt(x), data.frame(x = 1:1000)) ok <- rrq_task_wait(ids) #>  ⠙ Waiting for tasks (13 waiting, 0 running, 987 finished) [2s] [K   [K result <- rrq_task_results(ids)"},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"interprocess-commuication-pattern","dir":"Articles","previous_headings":"","what":"Interprocess commuication pattern","title":"Workers","text":"can submit task cluster accesses pool workers. quite difficult demonstrate clear way, bear us. general pattern try achieve : Submit normal hipercow task cluster task distributes work set workers; might happen several times Return summary work main task practical example approach might submit hipercow task runs orderly report within run MCMC send chain different worker (may use multiple cores). gives three levels parallelism ability span past single node fairly easily. Though may need use pen paper keep track ’re . example, ’ll use “dide-windows” driver submit work series four workers running DIDE cluster. ’ll submit hipercow task runs small piece code: Hopefully fairly self-explanatory, bit pointless. Note delete rrq tasks completing , prevents rrq tasks accumulating. code needs available hipercow environment run task: nice workers ; let’s add couple : now submit task call function: , id hipercow task identifier. sends additional task queue, now five things running cluster (four workers one task). task runs, picks controller, uses distribute (trivial) calculation four workers. can see worker logs tasks split workers: example trivial, submit 10 workers using 32 core node, use single core task farm series large simulations across bank computers. create 500 single core workers (~25% cluster) smash huge number simulations minimal overhead.","code":"example <- function(n) {   ids <- rrq::rrq_task_create_bulk_call(sqrt, seq_len(n))   ok <- rrq::rrq_task_wait(ids)   stopifnot(ok)   result <- rrq::rrq_task_results(ids)   rrq::rrq_task_delete(ids)   sum(unlist(result)) } hipercow_environment_create(\"default\", sources = \"code.R\") #> ✔ Created environment 'default' info <- hipercow_rrq_workers_submit(2, resources = resources) #> ✔ Using existing rrq queue 'rrq:7010f758' #> ✔ Submitted 2 tasks using 'dide-windows' #> ✔ Created bundle 'twofaced_loon' with 2 tasks #>  ⠙ Waiting for workers (2 waiting, 0 running, 0 finished) [2s] [K  ⠹ Waiting for #> workers (2 waiting, 0 running, 0 finished) [2.2s] [K  ⠸ Waiting for workers (2 #> waiting, 0 running, 0 finished) [2.4s] [K  ⠼ Waiting for workers (2 waiting, 0 #> running, 0 finished) [2.6s] [K  ⠴ Waiting for workers (2 waiting, 0 running, 0 #> finished) [2.8s] [K  ⠦ Waiting for workers (2 waiting, 0 running, 0 finished) #> [3s] [K  ⠧ Waiting for workers (2 waiting, 0 running, 0 finished) [3.2s] [K  ⠇ #> Waiting for workers (2 waiting, 0 running, 0 finished) [3.4s] [K  ⠏ Waiting for #> workers (2 waiting, 0 running, 0 finished) [3.6s] [K  ⠋ Waiting for workers (2 #> waiting, 0 running, 0 finished) [3.8s] [K  ⠙ Waiting for workers (2 waiting, 0 #> running, 0 finished) [4s] [K  ⠹ Waiting for workers (2 waiting, 0 running, 0 #> finished) [4.2s] [K  ⠸ Waiting for workers (2 waiting, 0 running, 0 finished) #> [4.4s] [K  ⠼ Waiting for workers (2 waiting, 0 running, 0 finished) [4.6s] [K  ⠴ #> Waiting for workers (2 waiting, 0 running, 0 finished) [4.8s] [K  ⠦ Waiting for #> workers (2 waiting, 0 running, 0 finished) [5s] [K  ⠧ Waiting for workers (2 #> waiting, 0 running, 0 finished) [5.2s] [K  ⠇ Waiting for workers (2 waiting, 0 #> running, 0 finished) [5.4s] [K  ⠏ Waiting for workers (2 waiting, 0 running, 0 #> finished) [5.6s] [K  ⠋ Waiting for workers (2 waiting, 0 running, 0 finished) #> [5.8s] [K  ⠙ Waiting for workers (2 waiting, 0 running, 0 finished) [6s] [K  ⠹ #> Waiting for workers (2 waiting, 0 running, 0 finished) [6.2s] [K  ⠸ Waiting for #> workers (2 waiting, 0 running, 0 finished) [6.4s] [K  ⠼ Waiting for workers (2 #> waiting, 0 running, 0 finished) [6.6s] [K  ⠴ Waiting for workers (2 waiting, 0 #> running, 0 finished) [6.8s] [K  ⠦ Waiting for workers (2 waiting, 0 running, 0 #> finished) [7s] [K  ⠧ Waiting for workers (2 waiting, 0 running, 0 finished) #> [7.2s] [K  ⠇ Waiting for workers (2 waiting, 0 running, 0 finished) [7.4s] [K  ⠏ #> Waiting for workers (2 waiting, 0 running, 0 finished) [7.6s] [K  ⠋ Waiting for #> workers (2 waiting, 0 running, 0 finished) [7.8s] [K  ⠙ Waiting for workers (2 #> waiting, 0 running, 0 finished) [8s] [K  ⠹ Waiting for workers (2 waiting, 0 #> running, 0 finished) [8.2s] [K  ⠸ Waiting for workers (2 waiting, 0 running, 0 #> finished) [8.4s] [K  ⠼ Waiting for workers (2 waiting, 0 running, 0 finished) #> [8.6s] [K  ⠴ Waiting for workers (2 waiting, 0 running, 0 finished) [8.8s] [K  ⠦ #> Waiting for workers (2 waiting, 0 running, 0 finished) [9s] [K  ⠧ Waiting for #> workers (2 waiting, 0 running, 0 finished) [9.2s] [K  ⠇ Waiting for workers (2 #> waiting, 0 running, 0 finished) [9.4s] [K  ⠏ Waiting for workers (2 waiting, 0 #> running, 0 finished) [9.6s] [K  ⠋ Waiting for workers (2 waiting, 0 running, 0 #> finished) [9.8s] [K  ⠙ Waiting for workers (2 waiting, 0 running, 0 finished) #> [10s] [K  ⠹ Waiting for workers (2 waiting, 0 running, 0 finished) [10.2s] [K  ⠸ #> Waiting for workers (2 waiting, 0 running, 0 finished) [10.4s] [K  ⠼ Waiting for #> workers (2 waiting, 0 running, 0 finished) [10.6s] [K  ⠴ Waiting for workers (2 #> waiting, 0 running, 0 finished) [10.8s] [K  ⠦ Waiting for workers (2 waiting, 0 #> running, 0 finished) [11s] [K  ⠧ Waiting for workers (2 waiting, 0 running, 0 #> finished) [11.2s] [K  ⠇ Waiting for workers (2 waiting, 0 running, 0 finished) #> [11.4s] [K  ⠏ Waiting for workers (2 waiting, 0 running, 0 finished) [11.6s] [K  ⠋ #> Waiting for workers (2 waiting, 0 running, 0 finished) [11.8s] [K  ⠙ Waiting for #> workers (2 waiting, 0 running, 0 finished) [12s] [K  ⠹ Waiting for workers (2 #> waiting, 0 running, 0 finished) [12.2s] [K  ⠸ Waiting for workers (2 waiting, 0 #> running, 0 finished) [12.4s] [K  ⠼ Waiting for workers (2 waiting, 0 running, 0 #> finished) [12.6s] [K  ⠴ Waiting for workers (2 waiting, 0 running, 0 finished) #> [12.8s] [K  ⠦ Waiting for workers (2 waiting, 0 running, 0 finished) [13s] [K  ⠧ #> Waiting for workers (2 waiting, 0 running, 0 finished) [13.2s] [K  ⠇ Waiting for #> workers (2 waiting, 0 running, 0 finished) [13.4s] [K  ⠏ Waiting for workers (2 #> waiting, 0 running, 0 finished) [13.6s] [K  ⠋ Waiting for workers (2 waiting, 0 #> running, 0 finished) [13.8s] [K  ⠙ Waiting for workers (2 waiting, 0 running, 0 #> finished) [14s] [K  ⠹ Waiting for workers (2 waiting, 0 running, 0 finished) #> [14.2s] [K  ⠸ Waiting for workers (2 waiting, 0 running, 0 finished) [14.4s] [K  ⠼ #> Waiting for workers (2 waiting, 0 running, 0 finished) [14.6s] [K  ⠴ Waiting for #> workers (2 waiting, 0 running, 0 finished) [14.8s] [K  ⠦ Waiting for workers (2 #> waiting, 0 running, 0 finished) [15s] [K  ⠧ Waiting for workers (2 waiting, 0 #> running, 0 finished) [15.2s] [K  ⠇ Waiting for workers (2 waiting, 0 running, 0 #> finished) [15.4s] [K  ⠏ Waiting for workers (2 waiting, 0 running, 0 finished) #> [15.7s] [K  ⠋ Waiting for workers (2 waiting, 0 running, 0 finished) [15.9s] [K  ⠙ #> Waiting for workers (2 waiting, 0 running, 0 finished) [16.1s] [K  ⠹ Waiting for #> workers (2 waiting, 0 running, 0 finished) [16.3s] [K  ⠸ Waiting for workers (2 #> waiting, 0 running, 0 finished) [16.5s] [K  ⠼ Waiting for workers (2 waiting, 0 #> running, 0 finished) [16.7s] [K  ⠴ Waiting for workers (2 waiting, 0 running, 0 #> finished) [16.9s] [K  ⠦ Waiting for workers (2 waiting, 0 running, 0 finished) #> [17.1s] [K  ⠧ Waiting for workers (2 waiting, 0 running, 0 finished) [17.3s] [K  ⠇ #> Waiting for workers (2 waiting, 0 running, 0 finished) [17.5s] [K  ⠏ Waiting for #> workers (2 waiting, 0 running, 0 finished) [17.7s] [K  ⠋ Waiting for workers (2 #> waiting, 0 running, 0 finished) [17.9s] [K  ⠙ Waiting for workers (2 waiting, 0 #> running, 0 finished) [18.1s] [K  ⠹ Waiting for workers (2 waiting, 0 running, 0 #> finished) [18.3s] [K  ⠸ Waiting for workers (2 waiting, 0 running, 0 finished) #> [18.5s] [K  ⠼ Waiting for workers (2 waiting, 0 running, 0 finished) [18.7s] [K  ⠴ #> Waiting for workers (2 waiting, 0 running, 0 finished) [18.9s] [K  ⠦ Waiting for #> workers (2 waiting, 0 running, 0 finished) [19.1s] [K  ⠧ Waiting for workers (2 #> waiting, 0 running, 0 finished) [19.3s] [K  ⠇ Waiting for workers (2 waiting, 0 #> running, 0 finished) [19.5s] [K  ⠏ Waiting for workers (2 waiting, 0 running, 0 #> finished) [19.7s] [K  ⠋ Waiting for workers (2 waiting, 0 running, 0 finished) #> [19.9s] [K  ⠙ Waiting for workers (2 waiting, 0 running, 0 finished) [20.1s] [K  ⠹ #> Waiting for workers (2 waiting, 0 running, 0 finished) [20.3s] [K  ⠸ Waiting for #> workers (2 waiting, 0 running, 0 finished) [20.5s] [K  ⠼ Waiting for workers (2 #> waiting, 0 running, 0 finished) [20.7s] [K  ⠴ Waiting for workers (2 waiting, 0 #> running, 0 finished) [20.9s] [K  ⠦ Waiting for workers (2 waiting, 0 running, 0 #> finished) [21.1s] [K  ⠧ Waiting for workers (2 waiting, 0 running, 0 finished) #> [21.3s] [K  ⠇ Waiting for workers (2 waiting, 0 running, 0 finished) [21.5s] [K  ⠏ #> Waiting for workers (2 waiting, 0 running, 0 finished) [21.7s] [K  ⠋ Waiting for #> workers (2 waiting, 0 running, 0 finished) [21.9s] [K  ⠙ Waiting for workers (2 #> waiting, 0 running, 0 finished) [22.1s] [K  ⠹ Waiting for workers (2 waiting, 0 #> running, 0 finished) [22.3s] [K  ⠸ Waiting for workers (2 waiting, 0 running, 0 #> finished) [22.5s] [K  ⠼ Waiting for workers (2 waiting, 0 running, 0 finished) #> [22.7s] [K  ⠴ Waiting for workers (2 waiting, 0 running, 0 finished) [22.9s] [K  ⠦ #> Waiting for workers (2 waiting, 0 running, 0 finished) [23.1s] [K  ⠧ Waiting for #> workers (2 waiting, 0 running, 0 finished) [23.3s] [K  ⠇ Waiting for workers (2 #> waiting, 0 running, 0 finished) [23.5s] [K  ⠏ Waiting for workers (2 waiting, 0 #> running, 0 finished) [23.7s] [K  ⠋ Waiting for workers (2 waiting, 0 running, 0 #> finished) [23.9s] [K  ⠙ Waiting for workers (2 waiting, 0 running, 0 finished) #> [24.1s] [K  ⠹ Waiting for workers (2 waiting, 0 running, 0 finished) [24.3s] [K  ⠸ #> Waiting for workers (2 waiting, 0 running, 0 finished) [24.5s] [K  ⠼ Waiting for #> workers (2 waiting, 0 running, 0 finished) [24.7s] [K  ⠴ Waiting for workers (2 #> waiting, 0 running, 0 finished) [24.9s] [K  ⠦ Waiting for workers (2 waiting, 0 #> running, 0 finished) [25.1s] [K  ⠧ Waiting for workers (2 waiting, 0 running, 0 #> finished) [25.3s] [K  ⠇ Waiting for workers (2 waiting, 0 running, 0 finished) #> [25.5s] [K  ⠏ Waiting for workers (2 waiting, 0 running, 0 finished) [25.7s] [K  ⠋ #> Waiting for workers (2 waiting, 0 running, 0 finished) [25.9s] [K  ⠙ Waiting for #> workers (2 waiting, 0 running, 0 finished) [26.1s] [K  ⠹ Waiting for workers (2 #> waiting, 0 running, 0 finished) [26.3s] [K  ⠸ Waiting for workers (1 waiting, 0 #> running, 1 finished) [26.5s] [K   [K id <- task_create_expr(   example(16),   parallel = hipercow_parallel(use_rrq = TRUE),   resources = resources) #> ✔ Submitted task '71e64618d20f71852f7c0097d51799a5' using 'dide-windows' id #> [1] \"71e64618d20f71852f7c0097d51799a5\" task_wait(id) #> [1] TRUE task_result(id) #> [1] 44.4692 rrq_worker_log_tail(n = 32) #>                    worker_id child       time       command #> 1  rrq-7010f758-ea39208bac92    NA 1732816685    TASK_START #> 2  rrq-7010f758-ea39208bac92    NA 1732816685 TASK_COMPLETE #> 3  rrq-7010f758-ea39208bac92    NA 1732816685    TASK_START #> 4  rrq-7010f758-ea39208bac92    NA 1732816685 TASK_COMPLETE #> 5  rrq-7010f758-ea39208bac92    NA 1732816685    TASK_START #> 6  rrq-7010f758-ea39208bac92    NA 1732816685 TASK_COMPLETE #> 7  rrq-7010f758-ea39208bac92    NA 1732816685    TASK_START #> 8  rrq-7010f758-ea39208bac92    NA 1732816685 TASK_COMPLETE #> 9  rrq-7010f758-bd7c13c3581f    NA 1732816713         ALIVE #> 10 rrq-7010f758-bd7c13c3581f    NA 1732816713         ENVIR #> 11 rrq-7010f758-bd7c13c3581f    NA 1732816713         ENVIR #> 12 rrq-7010f758-bd7c13c3581f    NA 1732816713         QUEUE #> 13 rrq-7010f758-917984e8738f    NA 1732816713         ALIVE #> 14 rrq-7010f758-917984e8738f    NA 1732816713         ENVIR #> 15 rrq-7010f758-917984e8738f    NA 1732816713         ENVIR #> 16 rrq-7010f758-917984e8738f    NA 1732816713         QUEUE #> 17 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 18 rrq-7010f758-917984e8738f    NA 1732816744    TASK_START #> 19 rrq-7010f758-bd7c13c3581f    NA 1732816744    TASK_START #> 20 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 21 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 22 rrq-7010f758-bd7c13c3581f    NA 1732816744 TASK_COMPLETE #> 23 rrq-7010f758-917984e8738f    NA 1732816744 TASK_COMPLETE #> 24 rrq-7010f758-bd7c13c3581f    NA 1732816744    TASK_START #> 25 rrq-7010f758-917984e8738f    NA 1732816744    TASK_START #> 26 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 27 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 28 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 29 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 30 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 31 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 32 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 33 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 34 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 35 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 36 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 37 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 38 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 39 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 40 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 41 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 42 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 43 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 44 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 45 rrq-7010f758-ea39208bac92    NA 1732816744    TASK_START #> 46 rrq-7010f758-ea39208bac92    NA 1732816744 TASK_COMPLETE #> 47 rrq-7010f758-bd7c13c3581f    NA 1732816744 TASK_COMPLETE #> 48 rrq-7010f758-917984e8738f    NA 1732816744 TASK_COMPLETE #>                             message #> 1  fac7edb4aba7afb25a5f5fb89dd9953e #> 2  fac7edb4aba7afb25a5f5fb89dd9953e #> 3  1498b3eea50b6a6e6e3d77af58bd8221 #> 4  1498b3eea50b6a6e6e3d77af58bd8221 #> 5  9882b0b7f866bd795c609a0050046127 #> 6  9882b0b7f866bd795c609a0050046127 #> 7  fa7582fb84ac23c84daca75876249cf9 #> 8  fa7582fb84ac23c84daca75876249cf9 #> 9                                   #> 10                              new #> 11                           create #> 12                          default #> 13                                  #> 14                              new #> 15                           create #> 16                          default #> 17 da0da47f97109e83a1058b190c9f8332 #> 18 1492f25d1b38f004ff5fd2981afb7cb9 #> 19 70533fd8d88fa4da0381b9f11b54731a #> 20 da0da47f97109e83a1058b190c9f8332 #> 21 a24702958ddc18f1acb762f4841535e6 #> 22 70533fd8d88fa4da0381b9f11b54731a #> 23 1492f25d1b38f004ff5fd2981afb7cb9 #> 24 8b74ff24f7db85876ffa7da746711ae6 #> 25 5c366be9197c398bc25afbeef925de4c #> 26 a24702958ddc18f1acb762f4841535e6 #> 27 166b5210958ad0ca2997b4d32d5e84aa #> 28 166b5210958ad0ca2997b4d32d5e84aa #> 29 420cb53445a3e1c04dee89751836eb4d #> 30 420cb53445a3e1c04dee89751836eb4d #> 31 34e98c52297f50b9ce5f3bd88f011276 #> 32 34e98c52297f50b9ce5f3bd88f011276 #> 33 db9cb6dd182f537e1bf086854c1fd2ec #> 34 db9cb6dd182f537e1bf086854c1fd2ec #> 35 18aa71b506647566a08b83ac4c4efa06 #> 36 18aa71b506647566a08b83ac4c4efa06 #> 37 1876225bb4f5a0b9ed103f87c4589c6e #> 38 1876225bb4f5a0b9ed103f87c4589c6e #> 39 d50cdad8eec494e653f6a0c4bb5dc27c #> 40 d50cdad8eec494e653f6a0c4bb5dc27c #> 41 c42185da2edacbec230f13c912938759 #> 42 c42185da2edacbec230f13c912938759 #> 43 14f3608cc4663a84576108cf9822421f #> 44 14f3608cc4663a84576108cf9822421f #> 45 97ad2df3d8cc470a32879d7992feb617 #> 46 97ad2df3d8cc470a32879d7992feb617 #> 47 8b74ff24f7db85876ffa7da746711ae6 #> 48 5c366be9197c398bc25afbeef925de4c"},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"tricks-and-tips","dir":"Articles","previous_headings":"","what":"Tricks and tips","title":"Workers","text":"section expand document patterns useful.","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"controlling-the-worker-environment","dir":"Articles","previous_headings":"Tricks and tips","what":"Controlling the worker environment","title":"Workers","text":"workers use rrq environment exists, failing default environment. need different packages sources loaded workers normal tasks, can creating different environment can submit workers resources parallel control want (see vignettes(\"parallel\") details); pass resources parallel hipercow_rrq_workers_submit().","code":"hipercow_environment_create(\"rrq\", packages = \"cowsay\") #> ✔ Created environment 'rrq' #> ℹ Refreshing existing rrq worker environments #> ✔ Using existing rrq queue 'rrq:7010f758'"},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"stopping-redundant-workers","dir":"Articles","previous_headings":"General considerations","what":"Stopping redundant workers","title":"Workers","text":"default, workers live 10 minutes finishing last task. means time use workers can largely forget cleanup. want polite give resources early (important wanted launch new workers, using large fraction cluster), can tell stop completion last job:","code":"hipercow_rrq_stop_workers_once_idle() #> ✔ Using existing rrq queue 'rrq:7010f758' #> ✔ Sent message to 3 workers #> ℹ Workers will stop 60 seconds after their last task #> ℹ Current worker status: IDLE (3)"},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"permanence","dir":"Articles","previous_headings":"General considerations","what":"Permanence","title":"Workers","text":"treat data submitted task permanent; subject deletion point! aim pull data rrq soon can. Practically won’t delete data database least days creation, make guarantees. ’ll describe cleanup later. reserve right delete things Redis database without warning, though try polite .","code":""},{"path":"https://mrc-ide.github.io/hipercow/articles/workers.html","id":"object-storage","dir":"Articles","previous_headings":"General considerations","what":"Object storage","title":"Workers","text":"Redis memory datastore, means inputs outputs tasks stored memory head node. means need careful store part tasks. refuse save object larger 100KB serialised (approximately size file created saveRDS() without using compression). encourage make use rrq’s task deletion using rrq::rrq_task_delete() delete tasks done . can pass long vector efficiently function. need save large outputs need write file (e.g., saveRDS() rather returning function expression set target rrq task. submitting large number tasks take short deterministic time run can put lot load file server, sure using project share personal share using DIDE cluster (see vignette(\"dide-cluster\")).","code":""},{"path":"https://mrc-ide.github.io/hipercow/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rich FitzJohn. Author, maintainer. Wes Hinsley. Author. Paul Liétar. Author. Imperial College Science, Technology Medicine. Copyright holder.","code":""},{"path":"https://mrc-ide.github.io/hipercow/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"FitzJohn R, Hinsley W, Liétar P (2025). hipercow: High Performance Computing. R package version 1.1.5, https://github.com/mrc-ide/hipercow.","code":"@Manual{,   title = {hipercow: High Performance Computing},   author = {Rich FitzJohn and Wes Hinsley and Paul Liétar},   year = {2025},   note = {R package version 1.1.5},   url = {https://github.com/mrc-ide/hipercow}, }"},{"path":"https://mrc-ide.github.io/hipercow/index.html","id":"hipercow-","dir":"","previous_headings":"","what":"High Performance Computing","title":"High Performance Computing","text":"NOTICE: use people DIDE, uses cluster web portal, local cluster, local network file systems.","code":""},{"path":"https://mrc-ide.github.io/hipercow/index.html","id":"what-is-this","dir":"","previous_headings":"","what":"What is this?","title":"High Performance Computing","text":"package interfacing DIDE cluster directly R. meant make jobs running cluster appear running locally asynchronously. idea let cluster appear extension computer can get using within R project easily. package supercedes didehpc (2015-2023).","code":""},{"path":"https://mrc-ide.github.io/hipercow/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"High Performance Computing","text":"New ? main vignette contains full instructions explanations bits needed. Trying install packages cluster? Check packages vignette ways controlling . problems? Check troubleshooting guide. DIDE Cluster (wpia-hn) long-form documentation, available hipercow website Reference documentation function","code":""},{"path":"https://mrc-ide.github.io/hipercow/index.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"High Performance Computing","text":"Check issue tracker known problems, create new one Use “Cluster” channel Teams, Rich Wes keep eye ","code":""},{"path":"https://mrc-ide.github.io/hipercow/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"High Performance Computing","text":"install hipercow:","code":"install.packages(   \"hipercow\",   repos = c(\"https://mrc-ide.r-universe.dev\", \"https://cloud.r-project.org\"))"},{"path":"https://mrc-ide.github.io/hipercow/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"High Performance Computing","text":"MIT © Imperial College Science, Technology Medicine","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/DEFAULT_ENVVARS.html","id":null,"dir":"Reference","previous_headings":"","what":"The default set of environment variables used for all tasks. — DEFAULT_ENVVARS","title":"The default set of environment variables used for all tasks. — DEFAULT_ENVVARS","text":"chosen provide best general experience. default variables may overridden globally setting hipercow.default_envvars option, per-task variable basis assigning different value environment variable question.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/DEFAULT_ENVVARS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The default set of environment variables used for all tasks. — DEFAULT_ENVVARS","text":"","code":"DEFAULT_ENVVARS"},{"path":"https://mrc-ide.github.io/hipercow/reference/DEFAULT_ENVVARS.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The default set of environment variables used for all tasks. — DEFAULT_ENVVARS","text":"object class hipercow_envvars (inherits data.frame) 1 rows 3 columns.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_authenticate.html","id":null,"dir":"Reference","previous_headings":"","what":"DIDE credentials — dide_authenticate","title":"DIDE credentials — dide_authenticate","text":"Register DIDE credentials.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_authenticate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DIDE credentials — dide_authenticate","text":"","code":"dide_authenticate()"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_authenticate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DIDE credentials — dide_authenticate","text":"Nothing, function called side effect setting updating credentials within keyring.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_authenticate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"DIDE credentials — dide_authenticate","text":"order able communicate DIDE HPC system, need able communicate HPC portal (https::mrcdata.dide.ic.ac.uk/hpc), need DIDE password username. typically, always, Imperial credentials.  store information securely using keyring package, unlocking credentials prompted computer password, DIDE password use windows machine connected DIDE domain, likely differ either DIDE Imperial password outside DIDE domain, use Windows.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_authenticate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DIDE credentials — dide_authenticate","text":"","code":"if (FALSE) {  dide_authenticate() }"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check we can use the DIDE cluster — dide_check","title":"Check we can use the DIDE cluster — dide_check","text":"Perform basic checks make system configured use DIDE cluster properly.  Calling something goes wrong never bad idea.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check we can use the DIDE cluster — dide_check","text":"","code":"dide_check(path = getwd())"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check we can use the DIDE cluster — dide_check","text":"path Path check; typically working directory.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check we can use the DIDE cluster — dide_check","text":"Invisibly, logical; TRUE checks succeed FALSE otherwise.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check we can use the DIDE cluster — dide_check","text":"","code":"if (FALSE) {  dide_check() }"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_generate_keypair.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate keypair — dide_generate_keypair","title":"Generate keypair — dide_generate_keypair","text":"Generate keypair encrypting small data send DIDE cluster.  can used encrypt environment variables, possibly workflows future.  default, ever created keypair replace already exists, unless set update = TRUE may call function safely ensure keypair set .","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_generate_keypair.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate keypair — dide_generate_keypair","text":"","code":"dide_generate_keypair(update = FALSE)"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_generate_keypair.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate keypair — dide_generate_keypair","text":"update Replace existing keypair.  need use accidentally remove .hipercow/ directory network home share, want renew key.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_generate_keypair.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate keypair — dide_generate_keypair","text":"Nothing, called side effect","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_generate_keypair.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate keypair — dide_generate_keypair","text":"","code":"if (FALSE) {  # Generate a new keypair, if one does not exist dide_generate_keypair() }"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe a path mapping — dide_path","title":"Describe a path mapping — dide_path","text":"Describe path mapping use setting jobs cluster.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe a path mapping — dide_path","text":"","code":"dide_path(path_local, path_remote, drive_remote, call = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe a path mapping — dide_path","text":"path_local point drive attached locally. Windows something like \"Q:/\", Mac something like \"/Volumes/mountname\", Linux anything , depending used mounted (written /etc/fstab) path_remote network path drive.  look something like \\\\\\\\projects.dide.ic.ac.uk\\\\tmp\\\\. Unfortunately backslashes really hard get right need use twice many expect (four backslashes beginning two separator). makes feel bad know alone: https://xkcd.com/1638 – alternatively may use forward slashes place backslashes (e.g. //projects.dide.ic.ac.uk/tmp) drive_remote place mount drive cluster. probably going mount things Q: T: already use .  things like C: likely used. Perhaps guidelines somewhere? call name calling function, error reporting.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe a path mapping — dide_path","text":"","code":"if (FALSE) {  # Suppose you have mounted your malaria share at \"~/net/malaria\" # (e.g., on a Linux machine).  You can tell the cluster to mount # this as \"M:\" when running tasks by first creating a path # mapping: share <- dide_path(\"~/net/malaria\",                    \"//wpia-hn.hpc.dide.ic.ac.uk/Malaria\",                    \"M:\")  # This share object contains information about how to relate your # local and remote paths: share  # When configuring the cluster you might pass this: hipercow_configure(\"dide-windows\", shares = share) }"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_username.html","id":null,"dir":"Reference","previous_headings":"","what":"Report DIDE username — dide_username","title":"Report DIDE username — dide_username","text":"Report username used log web portal use DIDE cluster.  may may local username.  may ask run helping debug cluster failures.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_username.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Report DIDE username — dide_username","text":"","code":"dide_username()"},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_username.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Report DIDE username — dide_username","text":"username, string","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/dide_username.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Report DIDE username — dide_username","text":"","code":"if (FALSE) {  # Return your DIDE username dide_username() }"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow.html","id":null,"dir":"Reference","previous_headings":"","what":"hipercow — hipercow","title":"hipercow — hipercow","text":"hipercow","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"hipercow — hipercow","text":"","code":"hipercow()"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"hipercow — hipercow","text":"Moo","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"hipercow — hipercow","text":"","code":"hipercow() #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW #> HHHHHHHHHHIIIIIIIIIIPPPPPPPPPPEEEEEEEEEERRRRRRRRRRCCCCCCCCCCOOOOOOOOOOWWWWWWWWWW"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_cancel.html","id":null,"dir":"Reference","previous_headings":"","what":"Cancel bundle tasks — hipercow_bundle_cancel","title":"Cancel bundle tasks — hipercow_bundle_cancel","text":"Cancel tasks bundle.  wraps task_cancel ids.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_cancel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cancel bundle tasks — hipercow_bundle_cancel","text":"","code":"hipercow_bundle_cancel(bundle, follow = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_cancel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cancel bundle tasks — hipercow_bundle_cancel","text":"bundle Either hipercow_bundle object, name bundle. follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_cancel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cancel bundle tasks — hipercow_bundle_cancel","text":"logical vector length id indicating task cancelled. FALSE job already completed, running, etc.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_cancel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cancel bundle tasks — hipercow_bundle_cancel","text":"","code":"cleanup <- hipercow_example_helper(runner = FALSE) #> ℹ This example uses a special helper  bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:5)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'nonspheric_siberiantiger' with 5 tasks hipercow_bundle_cancel(bundle) #> ✔ Successfully cancelled 5 tasks #> [1] TRUE TRUE TRUE TRUE TRUE hipercow_bundle_status(bundle) #> [1] \"cancelled\" \"cancelled\" \"cancelled\" \"cancelled\" \"cancelled\"  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_create.html","id":null,"dir":"Reference","previous_headings":"","what":"Create task bundle — hipercow_bundle_create","title":"Create task bundle — hipercow_bundle_create","text":"Create bundle tasks.  simply collection tasks relate together way, provide helper functions working save writing lots loops.  bundle name, randomly generated provide one, set task ids.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_create.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create task bundle — hipercow_bundle_create","text":"","code":"hipercow_bundle_create(   ids,   name = NULL,   validate = TRUE,   overwrite = TRUE,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_create.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create task bundle — hipercow_bundle_create","text":"ids character vector task ids name string, name bundle.  given, random name generated.  Names can contain letters, numbers, underscores hyphens, contain special characters. validate Logical, indicating check task ids exist.  always check task ids plausible. overwrite Logical, indicating overwrite existing bundle name. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_create.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create task bundle — hipercow_bundle_create","text":"task bundle object","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_create.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create task bundle — hipercow_bundle_create","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # Two task that were created separately: id1 <- task_create_expr(sqrt(1)) #> ✔ Submitted task 'f71ec64803a73cfc15788b6935ad2344' using 'example' id2 <- task_create_expr(sqrt(2)) #> ✔ Submitted task '278557d89b0ae04e18754974191719f6' using 'example'  # Combine these tasks together in a bundle: bundle <- hipercow_bundle_create(c(id1, id2)) #> ✔ Created bundle 'sacred_alpineroadguidetigerbeetle' with 2 tasks  # Now we can use bundle operations: hipercow_bundle_status(bundle) #> [1] \"submitted\" \"submitted\" hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_result(bundle) #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] 1.414214 #>   cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_delete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete task bundles — hipercow_bundle_delete","title":"Delete task bundles — hipercow_bundle_delete","text":"Delete one hipercow task bundles.  Note delete underlying tasks, yet supported.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_delete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete task bundles — hipercow_bundle_delete","text":"","code":"hipercow_bundle_delete(name, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_delete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete task bundles — hipercow_bundle_delete","text":"name Character vectors names delete root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_delete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delete task bundles — hipercow_bundle_delete","text":"Nothing, called side effect","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_delete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete task bundles — hipercow_bundle_delete","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:5)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'artsycraftsy_easteuropeanshepherd' with 5 tasks hipercow_bundle_list() #>                                name                time #> 1 artsycraftsy_easteuropeanshepherd 2025-05-13 06:41:29  # Retaining the ids, delete bundle ids <- bundle$ids hipercow_bundle_delete(bundle$name) hipercow_bundle_list() #> [1] name time #> <0 rows> (or 0-length row.names)  # The tasks still exist: task_status(ids) #> [1] \"submitted\" \"submitted\" \"submitted\" \"submitted\" \"submitted\"  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_list.html","id":null,"dir":"Reference","previous_headings":"","what":"List existing bundles — hipercow_bundle_list","title":"List existing bundles — hipercow_bundle_list","text":"List existing bundles","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List existing bundles — hipercow_bundle_list","text":"","code":"hipercow_bundle_list(root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List existing bundles — hipercow_bundle_list","text":"root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List existing bundles — hipercow_bundle_list","text":"data.frame columns name time, ordered time (recent first)","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List existing bundles — hipercow_bundle_list","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # With no bundles present hipercow_bundle_list() #> [1] name time #> <0 rows> (or 0-length row.names)  # With a bundle bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:5)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'compassionless_pachyderm' with 5 tasks hipercow_bundle_list() #>                       name                time #> 1 compassionless_pachyderm 2025-05-13 06:41:30  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Load existing bundle — hipercow_bundle_load","title":"Load existing bundle — hipercow_bundle_load","text":"Load existing saved bundle name.  intended created long-running bundle since closed session.  See hipercow_bundle_list finding names bundles.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load existing bundle — hipercow_bundle_load","text":"","code":"hipercow_bundle_load(name, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load existing bundle — hipercow_bundle_load","text":"name Name bundle load root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_load.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load existing bundle — hipercow_bundle_load","text":"hipercow_bundle object","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_load.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load existing bundle — hipercow_bundle_load","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:5)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'diamond_doe' with 5 tasks name <- bundle$name  # Delete the bundle object; the bundle exists still in hipercow's store. rm(bundle)  # With the name we can load the bundle and fetch its status bundle <- hipercow_bundle_load(name) hipercow_bundle_status(bundle) #> [1] \"submitted\" \"submitted\" \"submitted\" \"submitted\" \"submitted\"  # In fact, you can use just the name if you prefer: hipercow_bundle_status(name) #> [1] \"submitted\" \"submitted\" \"submitted\" \"submitted\" \"submitted\"  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_log_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch bundle logs — hipercow_bundle_log_value","title":"Fetch bundle logs — hipercow_bundle_log_value","text":"Fetch logs tasks bundle.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_log_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch bundle logs — hipercow_bundle_log_value","text":"","code":"hipercow_bundle_log_value(bundle, outer = FALSE, follow = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_log_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch bundle logs — hipercow_bundle_log_value","text":"bundle Either hipercow_bundle object, name bundle. outer Logical, indicating request \"outer\" logs; logs underlying HPC software hands hipercow. follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_log_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch bundle logs — hipercow_bundle_log_value","text":"list element logs corresponding element bundle.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_log_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch bundle logs — hipercow_bundle_log_value","text":"","code":"cleanup <- hipercow_example_helper(with_logging = TRUE) #> ℹ This example uses a special helper bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:2)) #> ✔ Submitted 2 tasks using 'example' #> ✔ Created bundle 'indistinct_indianspinyloach' with 2 tasks hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_log_value(bundle) #> [[1]] #>  [1] \"\"                                                                                 #>  [2] \"── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-1ca7fea9138' ─\" #>  [3] \"ℹ library paths:\"                                                                 #>  [4] \"• /home/runner/work/_temp/Library\"                                                #>  [5] \"• /opt/R/4.5.0/lib/R/site-library\"                                                #>  [6] \"• /opt/R/4.5.0/lib/R/library\"                                                     #>  [7] \"ℹ id: 245c12fd08d9059beff65f3d90103203\"                                           #>  [8] \"ℹ starting at: 2025-05-13 06:41:30.923834\"                                        #>  [9] \"ℹ Task type: expression\"                                                          #> [10] \"• Expression: sqrt(x)\"                                                            #> [11] \"• Locals: x\"                                                                      #> [12] \"• Environment: default\"                                                           #> [13] \"  R_GC_MEM_GROW: 3\"                                                               #> [14] \"───────────────────────────────────────────────────────────────── task logs ↓ ──\" #> [15] \"\"                                                                                 #> [16] \"───────────────────────────────────────────────────────────────── task logs ↑ ──\" #> [17] \"✔ status: success\"                                                                #> [18] \"ℹ finishing at: 2025-05-13 06:41:30.923834 (elapsed: 0.2055 secs)\"                #>  #> [[2]] #>  [1] \"\"                                                                                 #>  [2] \"── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-1ca7fea9138' ─\" #>  [3] \"ℹ library paths:\"                                                                 #>  [4] \"• /home/runner/work/_temp/Library\"                                                #>  [5] \"• /opt/R/4.5.0/lib/R/site-library\"                                                #>  [6] \"• /opt/R/4.5.0/lib/R/library\"                                                     #>  [7] \"ℹ id: 188a8054f2ea662eeb215908d472311d\"                                           #>  [8] \"ℹ starting at: 2025-05-13 06:41:31.333209\"                                        #>  [9] \"ℹ Task type: expression\"                                                          #> [10] \"• Expression: sqrt(x)\"                                                            #> [11] \"• Locals: x\"                                                                      #> [12] \"• Environment: default\"                                                           #> [13] \"  R_GC_MEM_GROW: 3\"                                                               #> [14] \"───────────────────────────────────────────────────────────────── task logs ↓ ──\" #> [15] \"\"                                                                                 #> [16] \"───────────────────────────────────────────────────────────────── task logs ↑ ──\" #> [17] \"✔ status: success\"                                                                #> [18] \"ℹ finishing at: 2025-05-13 06:41:31.333209 (elapsed: 0.2062 secs)\"                #>   cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch bundle results — hipercow_bundle_result","title":"Fetch bundle results — hipercow_bundle_result","text":"Fetch bundle results","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch bundle results — hipercow_bundle_result","text":"","code":"hipercow_bundle_result(bundle, follow = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch bundle results — hipercow_bundle_result","text":"bundle Either hipercow_bundle object, name bundle. follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch bundle results — hipercow_bundle_result","text":"unnamed list, element result task bundle, order.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch bundle results — hipercow_bundle_result","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:5)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'ecological_snake' with 5 tasks hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_result(bundle) #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] 1.414214 #>  #> [[3]] #> [1] 1.732051 #>  #> [[4]] #> [1] 2 #>  #> [[5]] #> [1] 2.236068 #>   cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_retry.html","id":null,"dir":"Reference","previous_headings":"","what":"Retry task bundle — hipercow_bundle_retry","title":"Retry task bundle — hipercow_bundle_retry","text":"Retry tasks bundle.  slightly different semantics task_retry(), errors retry possible.  , anticipate much time interested retrying fraction bundle need wait tasks finished order retry failed tasks.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_retry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retry task bundle — hipercow_bundle_retry","text":"","code":"hipercow_bundle_retry(bundle, if_status_in = NULL, driver = NULL, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_retry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retry task bundle — hipercow_bundle_retry","text":"bundle Either hipercow_bundle object, name bundle. if_status_in Optionally, character vector task statuses retry tasks.  example, pass if_status_in = c(\"cancelled\", \"failure\") retry cancelled failed tasks.  Can terminal statuses (cancelled, failure, success). driver Name driver use submit task.  default (NULL) depends configured drivers; drivers configured submission happens (indeed possible).  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured.  pass FALSE , submission prevented even driver configured. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_retry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retry task bundle — hipercow_bundle_retry","text":"Invisibly, logical vector, indicating tasks within bundle retried. means immediately obvious can get new id back tasks, typically unimportant, bundle functions follow retries default.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_retry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retry task bundle — hipercow_bundle_retry","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper bundle <- task_create_bulk_expr(rnorm(1, x), data.frame(x = 1:5)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'frosted_dungbeetle' with 5 tasks hipercow_bundle_wait(bundle) #> [1] TRUE  retried <- hipercow_bundle_retry(bundle) #> ℹ Retrying 5 / 5 tasks #> ✔ Submitted 5 tasks using 'example' retried #> [1] TRUE TRUE TRUE TRUE TRUE hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_result(bundle, follow = FALSE) #> [[1]] #> [1] -0.61925 #>  #> [[2]] #> [1] 1.768599 #>  #> [[3]] #> [1] 4.476165 #>  #> [[4]] #> [1] 3.473956 #>  #> [[5]] #> [1] 4.737513 #>  hipercow_bundle_result(bundle, follow = TRUE) #> [[1]] #> [1] 2.379403 #>  #> [[2]] #> [1] 1.190994 #>  #> [[3]] #> [1] 2.614999 #>  #> [[4]] #> [1] 4.369971 #>  #> [[5]] #> [1] 4.049014 #>   cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_status.html","id":null,"dir":"Reference","previous_headings":"","what":"Bundle status — hipercow_bundle_status","title":"Bundle status — hipercow_bundle_status","text":"Fetch status tasks bundle.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_status.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bundle status — hipercow_bundle_status","text":"","code":"hipercow_bundle_status(bundle, reduce = FALSE, follow = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_status.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bundle status — hipercow_bundle_status","text":"bundle Either hipercow_bundle object, name bundle. reduce Reduce status across tasks bundle. means return single value \"worst\" status across bundle.  return success tasks succeeded, return failed task failed. follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_status.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bundle status — hipercow_bundle_status","text":"character vector length number tasks bundle, length 1 reduce TRUE.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_status.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bundle status — hipercow_bundle_status","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:5)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'deferential_copepod' with 5 tasks # Immediately after submission, tasks may not all be complete so # we may get a mix of statuses.  In that case the reduced status # will be \"submitted\" or \"running\", even though some tasks may be # \"success\" hipercow_bundle_status(bundle) #> [1] \"submitted\" \"submitted\" \"submitted\" \"submitted\" \"submitted\" hipercow_bundle_status(bundle, reduce = TRUE) #> [1] \"submitted\"  # After completion all tasks have status \"success\", as does the # reduction. hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_status(bundle) #> [1] \"success\" \"success\" \"success\" \"success\" \"success\" hipercow_bundle_status(bundle, reduce = TRUE) #> [1] \"success\"  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_wait.html","id":null,"dir":"Reference","previous_headings":"","what":"Wait for a bundle to complete — hipercow_bundle_wait","title":"Wait for a bundle to complete — hipercow_bundle_wait","text":"Wait tasks bundle complete.  generalisation task_wait bundle.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_wait.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wait for a bundle to complete — hipercow_bundle_wait","text":"","code":"hipercow_bundle_wait(   bundle,   timeout = NULL,   poll = 1,   fail_early = TRUE,   progress = NULL,   follow = TRUE,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_wait.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wait for a bundle to complete — hipercow_bundle_wait","text":"bundle Either hipercow_bundle object, name bundle. timeout time wait task complete. default wait forever. poll Time, seconds, used throttle calls status function. default 1 second fail_early Logical, indicating fail soon first task failed.  case, running tasks continue running, return indicate final result succeed.  fail_early = FALSE keep running tasks passed failed, even though know return FALSE; upon return hipercow_bundle_result() can called results/errors returned. progress Logical value, indicating progress spinner used. default NULL uses option hipercow.progress, unset displays progress bar interactive session. follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_wait.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wait for a bundle to complete — hipercow_bundle_wait","text":"scalar logical value; TRUE tasks complete successfully FALSE otherwise","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_bundle_wait.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wait for a bundle to complete — hipercow_bundle_wait","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:5)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'frantic_grub' with 5 tasks hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_status(bundle) #> [1] \"success\" \"success\" \"success\" \"success\" \"success\"  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_cluster_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe cluster — hipercow_cluster_info","title":"Describe cluster — hipercow_cluster_info","text":"Describe information cluster.  (naturally) dependent cluster details value reliable; see Value details.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_cluster_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe cluster — hipercow_cluster_info","text":"","code":"hipercow_cluster_info(driver = NULL, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_cluster_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe cluster — hipercow_cluster_info","text":"driver driver use, determines cluster fetch information (depending configuration).  driver configured, error thrown. root Hipercow root, usually best NULL","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_cluster_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe cluster — hipercow_cluster_info","text":"list describing cluster.  details depend driver, subject change.  expect see elements: resources: Describes computational resources cluster, used hipercow_resources_validate.  Currently simple list elements max_ram (max RAM available, GB), max_cores (max number cores can request), queues (character vector available queues), nodes (character vector available nodes), default_queue (default queue). details subject change contents always informative fairly self explanatory. redis_url: URL redis server communicate outside cluster (.e., computer), form suitable use redux::hiredis r_versions: vector R versions, numeric_vector objects","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_cluster_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe cluster — hipercow_cluster_info","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper hipercow_cluster_info() #> $resources #> $resources$name #> [1] \"example\" #>  #> $resources$node_os #> [1] \"example_os\" #>  #> $resources$max_ram #> [1] 4 #>  #> $resources$max_cores #> [1] 4 #>  #> $resources$queues #> [1] \"alltasks\" \"bigmem\"   \"fast\"     #>  #> $resources$build_queue #> [1] \"fast\" #>  #> $resources$nodes #> [1] \"node-1\" \"node-2\" \"gpu-3\"  \"gpu-4\"  #>  #> $resources$default_queue #> [1] \"alltasks\" #>  #> $resources$redis_url #> [1] \"127.0.0.1:6379\" #>  #>  #> $r_versions #> [1] ‘4.5.0’ #>  #> $redis_url #> [1] \"127.0.0.1:6379\" #>  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configuration.html","id":null,"dir":"Reference","previous_headings":"","what":"Report on hipercow configuration — hipercow_configuration","title":"Report on hipercow configuration — hipercow_configuration","text":"Report hipercow configuration.  always want post along side problems; lots useful information help us see set configured.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configuration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Report on hipercow configuration — hipercow_configuration","text":"","code":"hipercow_configuration(show = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configuration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Report on hipercow configuration — hipercow_configuration","text":"show Display configuration screen root Hipercow root, usually best NULL","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configuration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Report on hipercow configuration — hipercow_configuration","text":"list machine readable form information, invisibly.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configuration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Report on hipercow configuration — hipercow_configuration","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper hipercow_configuration() #>  #> ── hipercow root at /home/runner/work/_temp/hv-20250513-1ca7237f6bb4 ─────────── #> ✔ Working directory '.' within root #> ℹ R version 4.5.0 on Linux (runner@fv-az1112-967) #>  #> ── Packages ── #>  #> ℹ This is hipercow 1.1.5 #> ℹ Installed: conan2 (1.9.102), logwatch (0.1.1), rrq (0.7.23) #> ✖ hipercow.dide is not installed #>  #> ── Environments ── #>  #> ── default  #> • packages: (none) #> • sources: (none) #> • globals: (none) #>  #> ── empty  #> • packages: (none) #> • sources: (none) #> • globals: (none) #>  #> ── Drivers ── #>  #> ✔ 1 driver configured ('example') #>  #> ── example  #> (unconfigurable)  # If you have saved additional environments, they will be listed here: file.create(\"functions.R\") #> [1] TRUE hipercow_environment_create(   name = \"other\",   packages = \"knitr\",   sources = \"functions.R\") #> ✔ Created environment 'other' hipercow_configuration() #>  #> ── hipercow root at /home/runner/work/_temp/hv-20250513-1ca7237f6bb4 ─────────── #> ✔ Working directory '.' within root #> ℹ R version 4.5.0 on Linux (runner@fv-az1112-967) #>  #> ── Packages ── #>  #> ℹ This is hipercow 1.1.5 #> ℹ Installed: conan2 (1.9.102), logwatch (0.1.1), rrq (0.7.23) #> ✖ hipercow.dide is not installed #>  #> ── Environments ── #>  #> ── default  #> • packages: (none) #> • sources: (none) #> • globals: (none) #>  #> ── empty  #> • packages: (none) #> • sources: (none) #> • globals: (none) #>  #> ── other  #> • packages: knitr #> • sources: functions.R #> • globals: (none) #>  #> ── Drivers ── #>  #> ✔ 1 driver configured ('example') #>  #> ── example  #> (unconfigurable)  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configure.html","id":null,"dir":"Reference","previous_headings":"","what":"Configure your hipercow root — hipercow_configure","title":"Configure your hipercow root — hipercow_configure","text":"Configure hipercow root.  hipercow_configure creates configuration hipercow_configuration looks ","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Configure your hipercow root — hipercow_configure","text":"","code":"hipercow_configure(driver, ..., root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Configure your hipercow root — hipercow_configure","text":"driver hipercow driver; support two present: \"dide-windows\" \"dide-linux\". ... Arguments passed driver; see Details information supported (varies driver). root Hipercow root, usually best NULL","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configure.html","id":"dide-cluster-windows-nodes","dir":"Reference","previous_headings":"","what":"DIDE Cluster - Windows nodes","title":"Configure your hipercow root — hipercow_configure","text":"Options supported dide-windows driver: shares: Information shares (additional one mounted working directory) made available cluster job. use case need access files present shared drive access absolute path (say M:/gis/shapefiles/) tasks.  can provide share windows_path object, list objects.  typically need use option. r_version: Control R version used cluster. Typically hipercow choose version close one using submit jobs, set available cluster. can use option choose specific version (e.g., pass \"4.3.0\" select exactly version). redis_url: Control URL used connect Redis.  can use use alternative Redis host, unlikely unless suggested .  default (NULL) uses Redis server headnode. See vignette(\"details\") information options.","code":""},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_configure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Configure your hipercow root — hipercow_configure","text":"","code":"if (FALSE) { hipercow_configure(\"dide-windows\", r_version = \"4.3.0\") }"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_driver.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a driver — hipercow_driver","title":"Create a driver — hipercow_driver","text":"Create new hipercow driver; intended used packages, rarely called directly. trying run tasks cluster need call !","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_driver.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a driver — hipercow_driver","text":"","code":"hipercow_driver(   configure,   submit,   status,   info,   log,   result,   cancel,   provision_run,   provision_list,   provision_compare,   keypair,   check_hello,   cluster_info,   default_envvars = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_driver.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a driver — hipercow_driver","text":"configure Function used set core configuration driver.  function called hipercow root directory (getwd() report correct path). can take arguments, calculation must return R object can serialised.  resulting configuration passed config driver functions. submit Submit task cluster.  run task created (either automatically manually) takes arguments task id, configuration, path root. status Fetch task status. Takes vector ids returns vector length statuses. info Fetch task info single task. May take longer status expected retrieve true status scheduler. log Fetch task log. Takes single task id integer (number lines already known) returns character vector new logs.  Return NULL (zero length character vector) log available. result Fetch task result.  needed, copies result file current hipercow root.  Assume result available (.e., already checked task status terminal) cancel Cancel one tasks. Takes vector task ids, requests tasks cancelled, returning list elements cancelled: logical vector length indicating cancellation successful, time_started: time task started, NA task yet started. provision_run Provision library. Works conan, must accept args, config, path_root. args injected conan2::conan_configure. expected function trigger running conan provision library.  return value ignored, error thrown installation fails. provision_list List previous installations. Takes args non-NULL injects conan2::conan_configure (provision_run) order build hash. Runs conan2::conan_list returning value. provision_compare Test library current.  expected call conan2::conan_compare keypair Return keypair list elements pub key; public key string private key path accessible cluster runs, permissions open user submitted task. check_hello Run preflight checks launching hello world task.  Return validated resources list. cluster_info Return information particular cluster: maximum core count, maximum memory, node list queue names, used validating hipercow_resources cluster. default_envvars Driver-specific default environment variables.  Drivers can use add environment variables higher precedence hipercow defaults, lower precedence hipercow.default_envvars option envvars argument task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_environment.html","id":null,"dir":"Reference","previous_headings":"","what":"Manage environments — hipercow_environment_create","title":"Manage environments — hipercow_environment_create","text":"Create, update, list, view delete environments.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_environment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manage environments — hipercow_environment_create","text":"","code":"hipercow_environment_create(   name = \"default\",   packages = NULL,   sources = NULL,   globals = NULL,   overwrite = TRUE,   check = TRUE,   root = NULL )  hipercow_environment_list(root = NULL)  hipercow_environment_delete(name = \"default\", root = NULL)  hipercow_environment_show(name = \"default\", root = NULL)  hipercow_environment_exists(name = \"default\", root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_environment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manage environments — hipercow_environment_create","text":"name Name environment. name default special; environment used default (hence name!).  Environment names can contain letters, numbers, hyphens underscores. packages Packages attached starting task. loaded library(), order provided, sources sourced.  need attach package script reason, just call library within one source files. sources Files source starting task. sourced global (execution) environment task. paths must relative hipercow root, working directory.  Files sourced order. globals Names global objects can assume exist within environment.  might include function definitions large data objects.  special value TRUE triggers automatic detection objects within environment (takes seconds requires environment constructable local machine , currently enabled default). overwrite environment creation, replace environment name. check Logical, indicating check source files issues.  Pass FALSE need bypass checks beware consequences may await . root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_environment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manage environments — hipercow_environment_create","text":"Nothing, called side effects.","code":""},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_environment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manage environments — hipercow_environment_create","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # Suppose you have a file with some functions you want to use in # your task: writeLines(\"simulation <- function(n) cumsum(rnorm(n))\", \"myfuns.R\")  # Update the default environment to include these functions (or in # this example, just this one function) hipercow_environment_create(sources = \"myfuns.R\") #> ✔ Created environment 'default'  # You can now use this function in your tasks: id <- task_create_expr(simulation(5)) #> ✔ Submitted task 'a9797d2f6641b842170c5504c980d621' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] -0.007539692 -0.721048921  0.354777357  0.754454429 -0.240203353  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_envvars.html","id":null,"dir":"Reference","previous_headings":"","what":"Environment variables — hipercow_envvars","title":"Environment variables — hipercow_envvars","text":"Create environment variables use hipercow task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_envvars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Environment variables — hipercow_envvars","text":"","code":"hipercow_envvars(..., secret = FALSE)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_envvars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Environment variables — hipercow_envvars","text":"... <dynamic-dots> Named environment variable.  unnamed, assumed refer environment variable exists.  Use NA value unset environment variable. secret environment variables secret?  encrypt saving decrypt use.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_envvars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Environment variables — hipercow_envvars","text":"list class hipercow_envvars modified.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_envvars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Environment variables — hipercow_envvars","text":"","code":"# Declare environment variables as key-value pairs: hipercow_envvars(\"MY_ENVVAR1\" = \"value1\", \"MY_ENVVAR2\" = \"value2\") #>         name  value secret #> 1 MY_ENVVAR1 value1  FALSE #> 2 MY_ENVVAR2 value2  FALSE  # If an environment variable already exists in your environment # and you want to duplicate this into a task, you can use this # shorthand: Sys.setenv(HIPERCOW_EXAMPLE_ENVVAR = \"moo\") # suppose this exists already hipercow_envvars(\"HIPERCOW_EXAMPLE_ENVVAR\") #>                      name value secret #> 1 HIPERCOW_EXAMPLE_ENVVAR   moo  FALSE hipercow_envvars(\"HIPERCOW_EXAMPLE_ENVVAR\", ANOTHER_ENVVAR = \"value\") #>                      name value secret #> 1 HIPERCOW_EXAMPLE_ENVVAR   moo  FALSE #> 2          ANOTHER_ENVVAR value  FALSE  # Secret envvars are still printed (at the moment at least) but # once passed into a task they will be encrypted at rest. hipercow_envvars(\"MY_SECRET\" = \"password\", secret = TRUE) #>        name    value secret #> 1 MY_SECRET password   TRUE  # Secret and public environment variables should be created # separately and concatenated together: env_public <- hipercow_envvars(\"HIPERCOW_EXAMPLE_ENVVAR\") env_secret <- hipercow_envvars(\"MY_PASSWORD\" = \"secret\", secret = TRUE) c(env_public, env_secret) #>                      name  value secret #> 1 HIPERCOW_EXAMPLE_ENVVAR    moo  FALSE #> 2             MY_PASSWORD secret   TRUE  # Cleanup Sys.unsetenv(\"HIPERCOW_EXAMPLE_ENVVAR\")"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_example_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"Example helper — hipercow_example_helper","title":"Example helper — hipercow_example_helper","text":"helper used running examples docs.  function change working directory new temporary hipercow root, start worker process quietly run tasks.  intended people use outside running examples!","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_example_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example helper — hipercow_example_helper","text":"","code":"hipercow_example_helper(   runner = TRUE,   with_logging = FALSE,   new_directory = TRUE,   initialise = TRUE )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_example_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Example helper — hipercow_example_helper","text":"runner Start runner?  TRUE (default) start background process callr::r_bg pick tasks queue run . with_logging Run task logging; quite bit slower, enables examples use task_log_show etc. effect runner TRUE. new_directory Create new empty (temporary) directory?  FALSE just use current directory.  used vignettes directory set already. initialise Initialise? FALSE initialisation done.  intended examples use hipercow_init() later.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_example_helper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Example helper — hipercow_example_helper","text":"function can called (arguments) return original working directory clean files created example.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_hello.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello world — hipercow_hello","title":"Hello world — hipercow_hello","text":"Hello world hipercow. function sends tiny test task whole system confirm everything configured correctly.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_hello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello world — hipercow_hello","text":"","code":"hipercow_hello(progress = NULL, timeout = NULL, driver = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_hello.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hello world — hipercow_hello","text":"progress Logical value, indicating progress spinner used. default NULL uses option hipercow.progress, unset displays progress bar interactive session. timeout time wait task complete. default wait forever. driver driver use send test task.  can omitted exactly one driver, error given one driver, configured drivers.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_hello.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hello world — hipercow_hello","text":"string \"Moo\", direct cluster.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_hello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello world — hipercow_hello","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper hipercow_hello() #> ✔ Submitted task 'c2218eb1ccca5e6de85fd4872a41960f' using 'example' #> ✔ Successfully ran test task 'c2218eb1ccca5e6de85fd4872a41960f'  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_init.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a hipercow root — hipercow_init","title":"Create a hipercow root — hipercow_init","text":"Create hipercow root.  marks directory task information saved, along local copy R packages (\"library\" cluster).  Immediately running first time, probably want run hipercow_configure() order control set projects network paths R version.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_init.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a hipercow root — hipercow_init","text":"","code":"hipercow_init(root = \".\", driver = NULL, ...)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_init.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a hipercow root — hipercow_init","text":"root path root, defaulting current directory. driver Optionally, name driver configure ... Arguments passed hipercow_configure driver non-NULL.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_init.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a hipercow root — hipercow_init","text":"Invisibly, root object","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_init.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a hipercow root — hipercow_init","text":"","code":"# Create an empty root path <- withr::local_tempfile() hipercow_init(path) #> ✔ Initialised hipercow at '/tmp/RtmpAyb54J/file1ca73e31a26b' #> ℹ Next, call 'hipercow_configure()'"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify parallel use of cores — hipercow_parallel","title":"Specify parallel use of cores — hipercow_parallel","text":"Set parallel options.  requested one core using hipercow_resources, hipercow can start local cluster node running , using either future parallel package.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify parallel use of cores — hipercow_parallel","text":"","code":"hipercow_parallel(   method = NULL,   cores_per_process = 1L,   environment = NULL,   use_rrq = FALSE )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify parallel use of cores — hipercow_parallel","text":"method parallel method hipercow prepare. Three options available: future package, parallel package, NULL, default, nothing. See details examples. cores_per_process number cores allocated process launching local cluster using one parallel methods. default, 1. See details. environment name environment load parallel workers.  default use environment submit task (defaults default), means worker gets environment main process.  often want, can mean load much worker incur speed memory cost.  case may want create new environment (hipercow_environment_create) contains fewer packages sources fewer functions specify . want suppress loading packages workers can use empty environment, always exists. use_rrq Logical, indicating intend use rrq-based workers tasks, case set default controller.  Enabling requires configured rrq controller via hipercow_rrq_controller() submitting task (check submission) submitted workers via hipercow_rrq_workers_submit() (check want running time task starts, may want launch later depending workflow.  document vignete(\"rrq\").","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify parallel use of cores — hipercow_parallel","text":"list containing parallel configuration.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify parallel use of cores — hipercow_parallel","text":", hipercow automatically setup work supported methods, initialise local cluster processes can used future_map clusterApply, depending method. default, hipercow initialises cluster number processes number cores requested using hipercow_resources. process use single core. can also call hipercow_parallel cores_per_process, make hipercow launch many processes can process number cores request, total cores requested hipercow_resources. example, request 32 cores hipercow_resources, call hipercow_parallel cores_per_process = 4, hipercow create local cluster 8 processes, reporting 4 cores process calls hipercow_parallel_get_cores. cores_per_process = 5, hipercow create 6 local processes, reporting 5 cores, two cores effectively unallocated. brief examples; see vignette(\"parallel\") details. example, looking process id (show different processes launched), asking process many cores using. using future package:   furrr must provisioned using hipercow_provision. equivalent example parallel:","code":"resources <- hipercow_resources(cores = 4) id <- task_create_expr(   furrr::future_map(1:4,     ~c(Sys.getpid(), hipercow_parallel_get_cores()),   parallel = hipercow_parallel(\"future\"),   resources = resources) resources <- hipercow_resources(cores = 4) id <- task_create_expr(   parallel::clusterApply(NULL, 1:4, function(x)     c(Sys.getpid(), hipercow_parallel_get_cores()),   parallel = hipercow_parallel(\"parallel\"),   resources = resources)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_get_cores.html","id":null,"dir":"Reference","previous_headings":"","what":"Get number of cores — hipercow_parallel_get_cores","title":"Get number of cores — hipercow_parallel_get_cores","text":"Lookup number cores allocated task","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_get_cores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get number of cores — hipercow_parallel_get_cores","text":"","code":"hipercow_parallel_get_cores()"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_get_cores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get number of cores — hipercow_parallel_get_cores","text":"number cores cluster allocated task. less equal number cores cluster node running task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_load_environment.html","id":null,"dir":"Reference","previous_headings":"","what":"Load an environment in a parallel context — hipercow_parallel_load_environment","title":"Load an environment in a parallel context — hipercow_parallel_load_environment","text":"Load environment parallel worker.  helper function designed use parallel backends, exported mostly makes easier us work .  Users never need call function directly.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_load_environment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load an environment in a parallel context — hipercow_parallel_load_environment","text":"","code":"hipercow_parallel_load_environment(name, envir = .GlobalEnv)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_load_environment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load an environment in a parallel context — hipercow_parallel_load_environment","text":"envir name environment","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_load_environment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load an environment in a parallel context — hipercow_parallel_load_environment","text":"Nothing, called side effects ","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_set_cores.html","id":null,"dir":"Reference","previous_headings":"","what":"Set various environment variables that report the number of cores available for execution. — hipercow_parallel_set_cores","title":"Set various environment variables that report the number of cores available for execution. — hipercow_parallel_set_cores","text":"Sets environment variables MC_CORES, OMP_NUM_THREADS, OMP_THREAD_LIMIT, R_DATATABLE_NUM_THREADS HIPERCOW_CORES given number cores. used help various thread-capable packages use correct number cores. can also call know specifically many cores want available code looks environment variables.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_set_cores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set various environment variables that report the number of cores available for execution. — hipercow_parallel_set_cores","text":"","code":"hipercow_parallel_set_cores(cores, envir = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_parallel_set_cores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set various environment variables that report the number of cores available for execution. — hipercow_parallel_set_cores","text":"cores Number cores used. envir Environment variables set limit lifetime. need setting general, see withr::local_envvar example use.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":null,"dir":"Reference","previous_headings":"","what":"Provision cluster library — hipercow_provision","title":"Provision cluster library — hipercow_provision","text":"Provision library.  runs small task cluster set packages.  changed R version need rerun .  See vignette(\"packages\") much process.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provision cluster library — hipercow_provision","text":"","code":"hipercow_provision(   method = NULL,   ...,   driver = NULL,   environment = \"default\",   check_running_tasks = TRUE,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provision cluster library — hipercow_provision","text":"method provisioning method use, defaulting NULL, indicates try detect best provisioning mechanism ; typically work well unless manually adding packages library (see Details). given, must one auto, pkgdepends, script renv; described Details vignette(\"packages\"). ... Arguments passed conan. See Details. driver name driver use, can leave blank one configured (typical). environment name environment provision (see hipercow_environment_create details). check_running_tasks Logical, indicating check tasks running starting installation. Generally, installing packages tasks running harmful may get unexpected results, task may start package inconsistent state, windows may get corrupted library package upgraded loaded.  can disable check passing FALSE.  drivers respond argument, windows driver . root hipercow root","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Provision cluster library — hipercow_provision","text":"Nothing","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Provision cluster library — hipercow_provision","text":"hope time need pass options ..., time hipercow right thing. Please let us know case routinely add arguments .","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"manually-adding-packages-to-an-installation","dir":"Reference","previous_headings":"","what":"Manually adding packages to an installation","title":"Provision cluster library — hipercow_provision","text":"One case expect pass options hipercow_provision manually adding packages existing library.  usage typically look like:   pkg1 pkg2 names packages pkgdepends references (e.g., username/repo GitHub package; see vignette(\"packages\") details).","code":"hipercow_provision(\"pkgdepends\", refs = c(\"pkg1\", \"pkg2\"))"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"supported-methods-and-options","dir":"Reference","previous_headings":"","what":"Supported methods and options","title":"Provision cluster library — hipercow_provision","text":"four possible methods: pkgdepends, auto, script renv. canonical source documentation approaches conan2::conan_configure.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"pkgdepends","dir":"Reference","previous_headings":"","what":"pkgdepends","title":"Provision cluster library — hipercow_provision","text":"simplest method understand, probably similar approach didehpc.  method installs packages list pkgdepends.txt hipercow root, via vector provided package references. Uses pkgdepends actual dependency resolution installation. Supported options (passed via ...) refs: character vector package references override pkgdepends.txt policy: policy argument pkgdepends::new_pkg_installation_proposal (accepts lazy upgrade)","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"auto","dir":"Reference","previous_headings":"","what":"auto","title":"Provision cluster library — hipercow_provision","text":"Uses pkgdepends internally tries everything automatically based declared environments (see hipercow_environment_create vignette(\"hipercow\")) installation information recorded locally installed versions required packages. experimental love know works . options supported, idea automatic :)","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"script","dir":"Reference","previous_headings":"","what":"script","title":"Provision cluster library — hipercow_provision","text":"Runs script (default provision.R) cluster install things however want.  flexible mostly.  intended use case option pkgdepends fails resolve dependencies properly need install things manually.  remotes package pre-installed use within script. script run special build queue, run even cluster busy.  However, restricted ways, allowing maximum 30 minutes disallowing parallel running. Supports one option: script: path script run, defaulting provision.R","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"renv","dir":"Reference","previous_headings":"","what":"renv","title":"Provision cluster library — hipercow_provision","text":"Uses renv recreate renv environment.  must using renv locally work, present renv project root must hipercow root. options currently supported, may pass renv options future; need flexibility please let us know.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Provision cluster library — hipercow_provision","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper writeLines(c(\"knitr\", \"data.table\"), \"pkgdepends.txt\") hipercow_provision() #> ✔ Selected provisioning method 'pkgdepends' #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/runner/work/_temp/Library #> Installing into library: hipercow/lib #> Using method pkgdepends #> Running in path: /home/runner/work/_temp/hv-20250513-1ca7b002f88 #> Library paths: #>   - /home/runner/work/_temp/hv-20250513-1ca7b002f88/hipercow/lib #>   - /opt/R/4.5.0/lib/R/site-library #>   - /opt/R/4.5.0/lib/R/library #> id: 20250513064144 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • knitr #> • data.table #>  #> ✔ Updated metadata database: 4.66 MB in 9 files. #>  #> ℹ Updating metadata database #> ✔ Updating metadata database ... done #>  #> ! Failed to update system requirement mappings, will use cached mappings. #> + data.table   1.17.2 [bld][cmp][dl] #> + evaluate     1.0.3  [bld][dl] #> + highr        0.11   [bld][dl] #> + knitr        1.50   [bld][dl] #> + xfun         0.52   [bld][cmp][dl] #> + yaml         2.3.10 [bld][cmp][dl] #> ℹ Getting 6 pkgs with unknown sizes #> ✔ Got evaluate 1.0.3 (source) (37.75 kB) #> ✔ Got highr 0.11 (source) (13.85 kB) #> ✔ Got yaml 2.3.10 (source) (94.56 kB) #> ✔ Got xfun 0.52 (source) (177.58 kB) #> ✔ Got knitr 1.50 (source) (534.26 kB) #> ✔ Got data.table 1.17.2 (source) (5.84 MB) #> ℹ Building evaluate 1.0.3 #> ℹ Building xfun 0.52 #> ℹ Building yaml 2.3.10 #> ℹ Building data.table 1.17.2 #> ✔ Built evaluate 1.0.3 (1.9s) #> ✔ Installed evaluate 1.0.3  (35ms) #> ✔ Built xfun 0.52 (5s) #> ✔ Installed xfun 0.52  (24ms) #> ℹ Building highr 0.11 #> ✔ Built highr 0.11 (1.4s) #> ✔ Installed highr 0.11  (1s) #> ✔ Built yaml 2.3.10 (7.5s) #> ✔ Installed yaml 2.3.10  (1s) #> ℹ Building knitr 1.50 #> ✔ Built knitr 1.50 (4.9s) #> ✔ Installed knitr 1.50  (1s) #> ✔ Built data.table 1.17.2 (22.2s) #> ✔ Installed data.table 1.17.2  (1.1s) #> ✔ Summary:   6 new  in 47.2s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250513064144' #> Done! hipercow_provision_list() #> ℹ 1 conan installation recorded #> • 1: 20250513064144 (moments ago) [0]  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare installations — hipercow_provision_compare","title":"Compare installations — hipercow_provision_compare","text":"Compare installations performed libraries conan.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare installations — hipercow_provision_compare","text":"","code":"hipercow_provision_compare(curr = 0, prev = -1, driver = NULL, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare installations — hipercow_provision_compare","text":"curr previous installation compare . Can name (see hipercow_provision_list get names), negative number -n indicates \"n installations ago\" positive number n indicates \"nth installation\". default value 0 corresponds current installation. prev previous installation compare . Can name (see hipercow_provision_list get names), negative number -n indicates \"n installations ago\" positive number n indicates \"nth installation\". default -1 indicates previous installation. Must refer installation curr. Use NULL -Inf want compare empty installation. driver name driver use, can leave blank one configured (typical). root hipercow root","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare installations — hipercow_provision_compare","text":"object class conan_compare, can printed nicely.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare installations — hipercow_provision_compare","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper hipercow_provision(\"pkgdepends\", refs = \"knitr\") #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/runner/work/_temp/Library #> Installing into library: hipercow/lib #> Using method pkgdepends #> Running in path: /home/runner/work/_temp/hv-20250513-1ca768add473 #> Library paths: #>   - /home/runner/work/_temp/hv-20250513-1ca768add473/hipercow/lib #>   - /opt/R/4.5.0/lib/R/site-library #>   - /opt/R/4.5.0/lib/R/library #> id: 20250513064218 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • knitr #>  #> ✔ Updated metadata database: 4.66 MB in 9 files. #>  #> ℹ Updating metadata database #> ✔ Updating metadata database ... done #>  #> + evaluate   1.0.3  [bld][dl] #> + highr      0.11   [bld][dl] #> + knitr      1.50   [bld][dl] #> + xfun       0.52   [bld][cmp][dl] #> + yaml       2.3.10 [bld][cmp][dl] #> ℹ Getting 5 pkgs with unknown sizes #> ✔ Got highr 0.11 (source) (13.85 kB) #> ✔ Got evaluate 1.0.3 (source) (37.75 kB) #> ✔ Got yaml 2.3.10 (source) (94.56 kB) #> ✔ Got xfun 0.52 (source) (177.58 kB) #> ✔ Got knitr 1.50 (source) (534.26 kB) #> ℹ Building evaluate 1.0.3 #> ℹ Building xfun 0.52 #> ℹ Building yaml 2.3.10 #> ✔ Built evaluate 1.0.3 (1.7s) #> ✔ Installed evaluate 1.0.3  (29ms) #> ✔ Built xfun 0.52 (4s) #> ✔ Installed xfun 0.52  (1s) #> ℹ Building highr 0.11 #> ✔ Built yaml 2.3.10 (5.2s) #> ✔ Installed yaml 2.3.10  (1s) #> ✔ Built highr 0.11 (1.3s) #> ✔ Installed highr 0.11  (1s) #> ℹ Building knitr 1.50 #> ✔ Built knitr 1.50 (4.6s) #> ✔ Installed knitr 1.50  (1s) #> ✔ Summary:   5 new  in 20.9s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250513064218' #> Done! hipercow_provision(\"pkgdepends\", refs = \"data.table\") #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/runner/work/_temp/Library #> Installing into library: hipercow/lib #> Using method pkgdepends #> Running in path: /home/runner/work/_temp/hv-20250513-1ca768add473 #> Library paths: #>   - /home/runner/work/_temp/hv-20250513-1ca768add473/hipercow/lib #>   - /opt/R/4.5.0/lib/R/site-library #>   - /opt/R/4.5.0/lib/R/library #> id: 20250513064239 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • data.table #> ℹ Loading metadata database #> ✔ Loading metadata database ... done #>  #> + data.table   1.17.2 [bld][cmp] #> ℹ No downloads are needed, 1 pkg is cached #> ✔ Got data.table 1.17.2 (source) (5.84 MB) #> ℹ Building data.table 1.17.2 #> ✔ Built data.table 1.17.2 (19.7s) #> ✔ Installed data.table 1.17.2  (65ms) #> ✔ Summary:   1 new  in 19.8s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250513064239' #> Done! hipercow_provision_compare() #> ── Comparing conan installations ─────────────────────────────────────────────── #> • 20250513064218 1st; previous installation (less than a minute ago) #> • 20250513064239 2nd; current installation (moments ago) #>  #> ── 5 unchanged packages ── #>  #> ℹ To show unchanged packages, print with 'show_unchanged = TRUE' #>  #> ── 1 added package ── #>  #> • data.table (1.17.2) CRAN  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_list.html","id":null,"dir":"Reference","previous_headings":"","what":"List installations — hipercow_provision_list","title":"List installations — hipercow_provision_list","text":"List previous successful installations hipercow root.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List installations — hipercow_provision_list","text":"","code":"hipercow_provision_list(driver = NULL, root = NULL)  hipercow_provision_check(   method = NULL,   ...,   driver = NULL,   environment = \"default\",   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List installations — hipercow_provision_list","text":"driver name driver use, can leave blank one configured (typical). root hipercow root method provisioning method use, defaulting NULL, indicates try detect best provisioning mechanism ; typically work well unless manually adding packages library (see Details). given, must one auto, pkgdepends, script renv; described Details vignette(\"packages\"). ... Arguments passed conan. See Details. environment name environment provision (see hipercow_environment_create details).","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List installations — hipercow_provision_list","text":"data.frame columns: name: name installation. might useful conan_compare time: time installation started hash: installation hash method: method used installation args: arguments installation (list column) current: using hipercow_provision_check, installation match arguments provided? object also class conan_list prints nicely, can drop .data.frame.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_provision_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List installations — hipercow_provision_list","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper writeLines(\"data.table\", \"pkgdepends.txt\")  # Before any installation has happened: hipercow_provision_list() #> ! No conan installations recorded hipercow_provision_check() #> ✔ Selected provisioning method 'pkgdepends' #> ! No conan installations recorded  # After installation: hipercow_provision() #> ✔ Selected provisioning method 'pkgdepends' #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/runner/work/_temp/Library #> Installing into library: hipercow/lib #> Using method pkgdepends #> Running in path: /home/runner/work/_temp/hv-20250513-1ca719f6462d #> Library paths: #>   - /home/runner/work/_temp/hv-20250513-1ca719f6462d/hipercow/lib #>   - /opt/R/4.5.0/lib/R/site-library #>   - /opt/R/4.5.0/lib/R/library #> id: 20250513064304 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • data.table #>  #> ✔ Updated metadata database: 4.66 MB in 9 files. #>  #> ℹ Updating metadata database #> ✔ Updating metadata database ... done #>  #> ! Failed to update system requirement mappings, will use cached mappings. #> + data.table   1.17.2 [bld][cmp][dl] #> ℹ Getting 1 pkg with unknown size #> ✔ Got data.table 1.17.2 (source) (5.84 MB) #> ℹ Building data.table 1.17.2 #> ✔ Built data.table 1.17.2 (19.5s) #> ✔ Installed data.table 1.17.2  (64ms) #> ✔ Summary:   1 new  in 19.5s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250513064304' #> Done! hipercow_provision_list() #> ℹ 1 conan installation recorded #> • 1: 20250513064304 (moments ago) [0] hipercow_provision_check() #> ✔ Selected provisioning method 'pkgdepends' #> ℹ 1 conan installation recorded #> • 1: 20250513064304 (moments ago) [0] (*) #> ℹ The entry marked with '*' matches the provided installation hash  # After a different installation: hipercow_provision(\"pkgdepends\", refs = \"knitr\") #> /`-'\\  _______  ___  ___ ____ #> \\,T./ / __/ _ \\/ _ \\/ _ `/ _ \\ #>   |   \\__/\\___/_//_/\\_,_/_//_/ #>   |   ---- THE  LIBRARIAN ---- #>  #> Bootstrapping from: /home/runner/work/_temp/Library #> Installing into library: hipercow/lib #> Using method pkgdepends #> Running in path: /home/runner/work/_temp/hv-20250513-1ca719f6462d #> Library paths: #>   - /home/runner/work/_temp/hv-20250513-1ca719f6462d/hipercow/lib #>   - /opt/R/4.5.0/lib/R/site-library #>   - /opt/R/4.5.0/lib/R/library #> id: 20250513064332 #> Logs from pkgdepends follow: #>  #> ------------------------------------------------------------------------------- #>  #>  #> ── repos  #> • https://cloud.r-project.org #>  #> ── refs  #> • knitr #> ℹ Loading metadata database #> ✔ Loading metadata database ... done #>  #> + evaluate   1.0.3  [bld] #> + highr      0.11   [bld] #> + knitr      1.50   [bld] #> + xfun       0.52   [bld][cmp] #> + yaml       2.3.10 [bld][cmp] #> ℹ No downloads are needed, 5 pkgs are cached #> ✔ Got highr 0.11 (source) (13.85 kB) #> ✔ Got evaluate 1.0.3 (source) (37.75 kB) #> ✔ Got yaml 2.3.10 (source) (94.56 kB) #> ✔ Got xfun 0.52 (source) (177.58 kB) #> ✔ Got knitr 1.50 (source) (534.26 kB) #> ℹ Building evaluate 1.0.3 #> ℹ Building xfun 0.52 #> ℹ Building yaml 2.3.10 #> ✔ Built evaluate 1.0.3 (1.7s) #> ✔ Installed evaluate 1.0.3  (70ms) #> ✔ Built xfun 0.52 (4s) #> ✔ Installed xfun 0.52  (1s) #> ℹ Building highr 0.11 #> ✔ Built yaml 2.3.10 (5.4s) #> ✔ Installed yaml 2.3.10  (1s) #> ✔ Built highr 0.11 (1.4s) #> ✔ Installed highr 0.11  (1s) #> ℹ Building knitr 1.50 #> ✔ Built knitr 1.50 (4.4s) #> ✔ Installed knitr 1.50  (38ms) #> ✔ Summary:   5 new  in 20.1s #>  #> ------------------------------------------------------------------------------- #> Writing library description to 'hipercow/lib/.conan/20250513064332' #> Done! hipercow_provision_list() #> ℹ 2 conan installations recorded #> • 1: 20250513064304 (less than a minute ago) [-1] #> • 2: 20250513064332 (moments ago) [0] hipercow_provision_check() #> ✔ Selected provisioning method 'pkgdepends' #> ℹ 2 conan installations recorded #> • 1: 20250513064304 (less than a minute ago) [-1] (*) #> • 2: 20250513064332 (moments ago) [0] #> ℹ The entry marked with '*' matches the provided installation hash  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_purge.html","id":null,"dir":"Reference","previous_headings":"","what":"Purge tasks — hipercow_purge","title":"Purge tasks — hipercow_purge","text":"Purge (delete) hipercow tasks.  destructive operation undone can unintended consequences! However, running short space want just delete everything start (general recommendation), function provides mechanism cleaning tasks longer need.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_purge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Purge tasks — hipercow_purge","text":"","code":"hipercow_purge(   task_ids = NULL,   finished_before = NULL,   in_bundle = NULL,   with_status = NULL,   dry_run = FALSE,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_purge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Purge tasks — hipercow_purge","text":"task_ids character vector task identifiers.  Typically provide provide filters. finished_before date, time, difftime object representing time time ago task finished (, job might finished reason; successfully unsuccessfully unless also provide with_status argument).  Everything prior deleted. in_bundle character vector bundle names. Wild cards supported using shell (glob) syntax, rather regular expression syntax.  use data_* match bundles start data_ (see utils::glob2rx details).  error bundles matched, error individual pattern match. with_status character vector statuses match.  purge tasks match statuses.  Valid statuses use created, success, failure cancelled (note select tasks status submitted running; use task_cancel first). dry_run TRUE, report done, changes made. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_purge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Purge tasks — hipercow_purge","text":"character vector deleted identifiers, invisibly.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_purge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Purge tasks — hipercow_purge","text":"arguments describe filters tasks.  delete intersection filters (union), must provide least one filter.  delete tasks created week ago write:   restrict tasks also failed write","code":"hipercow_purge(created_before = as.difftime(1, units = \"weeks\")) hipercow_purge(created_before = \"1 week\", with_status = \"failed\")"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_purge.html","id":"consequences-of-deletion","dir":"Reference","previous_headings":"","what":"Consequences of deletion","title":"Purge tasks — hipercow_purge","text":"non-exhaustive list: delete task part task_retry chain, tasks (upstream downstream chain) deleted support task dependencies (mrc-4797), deleting tasks mark -yet-run dependent task impossible, perhaps delete , prevent deleting task; decided yet may bundle references task delete, case bundle behave expected.  result delete bundles reference deleted task Deleted bundles deleted tasks hold identifiers deletion behave expected, tasks reported missing.  Restarting session probably safest thing purging. prevent race conditions, purging tasks time also retrying tasks purge, create tasks might want allow, tasks fail peculiar ways.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_purge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Purge tasks — hipercow_purge","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # Here are some tasks that have finished running: bundle <- task_create_bulk_expr(sqrt(x), data.frame(x = 1:5),                                 bundle_name = \"mybundle\") #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'mybundle' with 5 tasks hipercow_bundle_wait(bundle) #> [1] TRUE  # Purge all tasks contained in any bundle starting with \"my\": hipercow_purge(in_bundle = \"my*\") #> ℹ Purging 5 tasks #> ℹ Deleting 1 task bundle  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources.html","id":null,"dir":"Reference","previous_headings":"","what":"Hipercow Resources — hipercow_resources","title":"Hipercow Resources — hipercow_resources","text":"Specify resources task requires run.  creates validated list resources can passed resources argument task_create_expr task creation functions.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hipercow Resources — hipercow_resources","text":"","code":"hipercow_resources(   cores = 1L,   exclusive = FALSE,   max_runtime = NULL,   hold_until = NULL,   memory_per_node = NULL,   memory_per_process = NULL,   requested_nodes = NULL,   priority = NULL,   queue = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hipercow Resources — hipercow_resources","text":"cores number cores task requires. 1 default. Setting Inf request single node, however many cores node . exclusive Set TRUE ensure tasks concurrently run node runs task. done implicitly cores Inf. might useful single core task uses large amount memory, multiple tasks reason co-exist node. max_runtime Set specify time limit running job. Acceptable formats either integer number minutes, strings specifying combination hours (h), days (d) minutes (m). Example valid values: 60, \"1h30m\", \"5h\", \"40d\". hold_until Specify task wait queue certain time, certain period. former, can POSIXt (.e., date time future), Date (midnight day future), special strings \"tonight\" (7pm), \"midnight\", \"weekend\" (midnight Saturday morning). delay period, can specify integer number minutes, strings specifying combination hours (h), days (d) minutes (m). Example valid values: 60, \"1h30m\", \"5h\", \"3d\". memory_per_node Specify task can run node least specified memory. integer assumed gigabytes, string gigabytes terabytes written \"64G\" \"1T\" example. memory_per_process can provide estimate much RAM task requires, cluster can ensure total memory required running multiple tasks node exceed much memory node . Specify integer number gigabytes, characters \"10G\" requested_nodes touch us DIDE , need run task selection named compute nodes, specify vector strings node names. priority tasks launching low priority, can allow queuing tasks jump , setting priority low; otherwise, default normal. acceptable values. queue Specify particular queue submit tasks . development decide time queues best need DIDE's common workflows. See Details information, queues available cluster.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hipercow Resources — hipercow_resources","text":"function succeeds, returns hipercow_resources list parameters syntactically valid, although yet validated particular driver see resources can satisfied. function fails, return information arguments validated. modify return value.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources.html","id":"windows-cluster-wpia-hn-","dir":"Reference","previous_headings":"","what":"Windows cluster (wpia-hn)","title":"Hipercow Resources — hipercow_resources","text":"Cores present must 1 32 Memory per node (per task) can 512Gb . available queues AllNodes Testing - latter maximum runtime 30 minutes; jobs aborted exceed . node names wpia-001 wpia-089, excluding 41, 42, 49 50.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources.html","id":"linux-cluster-hermod-","dir":"Reference","previous_headings":"","what":"Linux cluster (hermod)","title":"Hipercow Resources — hipercow_resources","text":"Coming Soon.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hipercow Resources — hipercow_resources","text":"","code":"# The default set of resources hipercow_resources() #>  #> ── hipercow resource control (hipercow_resources) ────────────────────────────── #> • cores: 1 #> • exclusive: FALSE #> Unset: 'max_runtime', 'hold_until', 'memory_per_node', 'memory_per_process', #> 'requested_nodes', 'priority', and 'queue'  # A more complex case: hipercow_resources(   cores = 32,   exclusive = TRUE,   priority = \"low\") #>  #> ── hipercow resource control (hipercow_resources) ────────────────────────────── #> • cores: 32 #> • exclusive: TRUE #> • priority: low #> Unset: 'max_runtime', 'hold_until', 'memory_per_node', 'memory_per_process', #> 'requested_nodes', and 'queue'  # (remember that in order to change resources you would pass the # return value here into the \"resources\" argument of # task_create_expr() or similar)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources_validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate a hipercow_resources list for a driver. — hipercow_resources_validate","title":"Validate a hipercow_resources list for a driver. — hipercow_resources_validate","text":"Query driver find information cluster, validate hipercow_resources list driver see resources requested satisfied.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources_validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate a hipercow_resources list for a driver. — hipercow_resources_validate","text":"","code":"hipercow_resources_validate(resources, driver = NULL, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources_validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate a hipercow_resources list for a driver. — hipercow_resources_validate","text":"resources hipercow_resources list returned hipercow_resources, NULL driver name driver use, can leave blank one configured (typical). root hipercow root","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources_validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate a hipercow_resources list for a driver. — hipercow_resources_validate","text":"TRUE resources compatible driver.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_resources_validate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate a hipercow_resources list for a driver. — hipercow_resources_validate","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper hipercow_resources_validate(hipercow_resources(cores = 1)) #>  #> ── hipercow resource control (hipercow_resources) ────────────────────────────── #> • cores: 1 #> • exclusive: FALSE #> • queue: alltasks #> Unset: 'max_runtime', 'hold_until', 'memory_per_node', 'memory_per_process', #> 'requested_nodes', and 'priority'  # This example does not allow more than one core tryCatch(   hipercow_resources_validate(hipercow_resources(cores = 32)),   error = identity) #> <error/rlang_error> #> Error in `validate_cluster_cores()`: #> ! 32 is too many cores for this cluster. #> ℹ The largest node has 4 cores. #> --- #> Backtrace: #>      ▆ #>   1. └─pkgdown::build_site_github_pages(new_process = FALSE, install = FALSE) #>   2.   └─pkgdown::build_site(...) #>   3.     └─pkgdown:::build_site_local(...) #>   4.       └─pkgdown::build_reference(...) #>   5.         ├─pkgdown:::unwrap_purrr_error(...) #>   6.         │ └─base::withCallingHandlers(...) #>   7.         └─purrr::map(...) #>   8.           └─purrr:::map_(\"list\", .x, .f, ..., .progress = .progress) #>   9.             ├─purrr:::with_indexed_errors(...) #>  10.             │ └─base::withCallingHandlers(...) #>  11.             ├─purrr:::call_with_cleanup(...) #>  12.             └─pkgdown (local) .f(.x[[i]], ...) #>  13.               ├─base::withCallingHandlers(...) #>  14.               └─pkgdown:::data_reference_topic(...) #>  15.                 └─pkgdown:::run_examples(...) #>  16.                   └─pkgdown:::highlight_examples(code, topic, env = env) #>  17.                     └─downlit::evaluate_and_highlight(...) #>  18.                       └─evaluate::evaluate(code, child_env(env), new_device = TRUE, output_handler = output_handler) #>  19.                         ├─base::withRestarts(...) #>  20.                         │ └─base (local) withRestartList(expr, restarts) #>  21.                         │   ├─base (local) withOneRestart(withRestartList(expr, restarts[-nr]), restarts[[nr]]) #>  22.                         │   │ └─base (local) doWithOneRestart(return(expr), restart) #>  23.                         │   └─base (local) withRestartList(expr, restarts[-nr]) #>  24.                         │     └─base (local) withOneRestart(expr, restarts[[1L]]) #>  25.                         │       └─base (local) doWithOneRestart(return(expr), restart) #>  26.                         ├─evaluate:::with_handlers(...) #>  27.                         │ ├─base::eval(call) #>  28.                         │ │ └─base::eval(call) #>  29.                         │ └─base::withCallingHandlers(...) #>  30.                         ├─base::withVisible(eval(expr, envir)) #>  31.                         └─base::eval(expr, envir) #>  32.                           └─base::eval(expr, envir) #>  33.                             ├─base::tryCatch(...) #>  34.                             │ └─base (local) tryCatchList(expr, classes, parentenv, handlers) #>  35.                             │   └─base (local) tryCatchOne(expr, names, parentenv, handlers[[1L]]) #>  36.                             │     └─base (local) doTryCatch(return(expr), name, parentenv, handler) #>  37.                             └─hipercow::hipercow_resources_validate(hipercow_resources(cores = 32)) #>  38.                               └─hipercow:::resources_validate(resources, driver, root) #>  39.                                 └─hipercow:::validate_cluster_cores(resources$cores, cluster_resources$max_cores)  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_controller.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an rrq controller — hipercow_rrq_controller","title":"Create an rrq controller — hipercow_rrq_controller","text":"Create rrq controller queue, set default controller.  Use interact workers created hipercow_rrq_workers_submit().  Proper docs forthcoming, interfaces subject change.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_controller.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an rrq controller — hipercow_rrq_controller","text":"","code":"hipercow_rrq_controller(   ...,   set_as_default = TRUE,   driver = NULL,   queue_id = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_controller.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an rrq controller — hipercow_rrq_controller","text":"... Additional arguments passed rrq::rrq_controller(); currently follow timeout_task_wait. set_as_default Set rrq controller default; usually want. driver Name driver use.  default (NULL) depends configured drivers; drivers configured error lack information required proceed.  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured. queue_id rrq queue id use. parameter used internally hipercow. ever need pass value . root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_controller.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an rrq controller — hipercow_rrq_controller","text":"rrq::rrq_controller object.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_stop_workers_once_idle.html","id":null,"dir":"Reference","previous_headings":"","what":"Tell workers to exit once complete — hipercow_rrq_stop_workers_once_idle","title":"Tell workers to exit once complete — hipercow_rrq_stop_workers_once_idle","text":"Tell workers exit work complete","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_stop_workers_once_idle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tell workers to exit once complete — hipercow_rrq_stop_workers_once_idle","text":"","code":"hipercow_rrq_stop_workers_once_idle(root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_stop_workers_once_idle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tell workers to exit once complete — hipercow_rrq_stop_workers_once_idle","text":"root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_stop_workers_once_idle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tell workers to exit once complete — hipercow_rrq_stop_workers_once_idle","text":"Nothing, called side effects ","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_workers_submit.html","id":null,"dir":"Reference","previous_headings":"","what":"Submit rrq workers — hipercow_rrq_workers_submit","title":"Submit rrq workers — hipercow_rrq_workers_submit","text":"Submit workers cluster, use conjunction hipercow_rrq_controller.  worker may sit single core whole node depending set resources.  use rrq environment exists (hipercow_environment_create) otherwise use default environment.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_workers_submit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Submit rrq workers — hipercow_rrq_workers_submit","text":"","code":"hipercow_rrq_workers_submit(   n,   driver = NULL,   resources = NULL,   envvars = NULL,   parallel = NULL,   timeout = NULL,   progress = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_workers_submit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Submit rrq workers — hipercow_rrq_workers_submit","text":"n number workers submit. required argument. driver Name driver use.  default (NULL) depends configured drivers; drivers configured error lack information required proceed.  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured. resources list generated hipercow_resources giving cluster resource requirements run task. envvars Environment variables generated hipercow_envvars, might use control task. parallel Parallel configuration generated hipercow_parallel, defines method, , used initialise worker parallel execution (means think parallelism three levels least, diagram may help ). timeout Time wait workers appear. progress display progress bar? root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_rrq_workers_submit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Submit rrq workers — hipercow_rrq_workers_submit","text":"data.frame information launch, columns: queue_id: rrq queue id (workers) worker_id: rrq worker identifier task_id: hipercow task identifier bundle_name: hipercow bundle name (workers)","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_unconfigure.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove a driver from a hipercow configuration — hipercow_unconfigure","title":"Remove a driver from a hipercow configuration — hipercow_unconfigure","text":"Remove driver configured hipercow_configure.  affect tasks already submitted driver, prevent future tasks submitted .","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_unconfigure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove a driver from a hipercow configuration — hipercow_unconfigure","text":"","code":"hipercow_unconfigure(driver, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_unconfigure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove a driver from a hipercow configuration — hipercow_unconfigure","text":"driver name driver remove root Hipercow root, usually best NULL","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/hipercow_unconfigure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove a driver from a hipercow configuration — hipercow_unconfigure","text":"Nothing, called side effects .","code":""},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/reference/task_cancel.html","id":null,"dir":"Reference","previous_headings":"","what":"Cancel tasks — task_cancel","title":"Cancel tasks — task_cancel","text":"Cancel one tasks","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_cancel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cancel tasks — task_cancel","text":"","code":"task_cancel(id, follow = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_cancel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cancel tasks — task_cancel","text":"id task id task ids cancel follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_cancel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cancel tasks — task_cancel","text":"logical vector length id indicating task cancelled. FALSE task already completed, running, etc.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_cancel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cancel tasks — task_cancel","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  ids <- c(task_create_expr(Sys.sleep(2)), task_create_expr(runif(1))) #> ✔ Submitted task '2b4fe8df61f65961546d71a81e05c851' using 'example' #> ✔ Submitted task '58feac70de052659135b5601b0a4cee4' using 'example'  # The first task may or not be cancelled (depends on if it was # started already) but the second one will almost certainly be # cancelled: task_cancel(ids) #> ✔ Successfully cancelled 2 tasks #> [1] TRUE TRUE  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Create bulk tasks from a call — task_create_bulk_call","title":"Create bulk tasks from a call — task_create_bulk_call","text":"Create bulk set tasks based applying function vector data.frame.  bulk equivalent task_create_call, way task_create_bulk_expr bulk version task_create_expr.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_call.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create bulk tasks from a call — task_create_bulk_call","text":"","code":"task_create_bulk_call(   fn,   data,   args = NULL,   environment = \"default\",   bundle_name = NULL,   driver = NULL,   resources = NULL,   envvars = NULL,   parallel = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create bulk tasks from a call — task_create_bulk_call","text":"fn function call data data apply function .  can vector list, case act like lapply apply fn element turn.  Alternatively, can data.frame, case row taken set arguments fn.  Note data data.frame arguments fn named. args Additional arguments fn, shared across calls. must named.  using data.frame data, probably better adding additional columns vary across rows, end result . environment Name hipercow environment evaluate task within. bundle_name Name pass hipercow_bundle_create making bundle. NULL use random name.  always overwrite, bundle_name already refers bundle replaced. driver Name driver use submit task.  default (NULL) depends configured drivers; drivers configured submission happens (indeed possible).  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured.  pass FALSE , submission prevented even driver configured. resources list generated hipercow_resources giving cluster resource requirements run task. envvars Environment variables generated hipercow_envvars, might use control task. combined default environment variables (see vignettes(\"details\"), can overridden option hipercow.default_envvars), driver-specific environment variables (see vignette(\"windows\")).  Variables provided highest precedence.  can unset environment variable setting NA. parallel Parallel configuration generated hipercow_parallel, defines method, , used initialise task parallel execution. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_call.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create bulk tasks from a call — task_create_bulk_call","text":"hipercow_bundle object, groups together tasks, can use set grouped functions get status (hipercow_bundle_status), results (hipercow_bundle_result) etc.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_call.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create bulk tasks from a call — task_create_bulk_call","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # The simplest way to use this function is like lapply: x <- runif(5) bundle <- task_create_bulk_call(sqrt, x) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'raging_llama' with 5 tasks hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_result(bundle) # lapply(x, sqrt) #> [[1]] #> [1] 0.692116 #>  #> [[2]] #> [1] 0.6573973 #>  #> [[3]] #> [1] 0.8404962 #>  #> [[4]] #> [1] 0.973949 #>  #> [[5]] #> [1] 0.4246631 #>   # You can pass additional arguments in via 'args': x <- runif(5) bundle <- task_create_bulk_call(log, x, list(base = 3)) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'intercorporate_oriole' with 5 tasks hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_result(bundle) # lapply(x, log, base = 3) #> [[1]] #> [1] -0.238289 #>  #> [[2]] #> [1] -0.008493522 #>  #> [[3]] #> [1] -0.02723649 #>  #> [[4]] #> [1] -0.8589984 #>  #> [[5]] #> [1] -0.7044822 #>   # Passing in a data.frame acts like Map (though with all arguments named) x <- data.frame(a = runif(5), b = rpois(5, 10)) bundle <- task_create_bulk_call(function(a, b) sum(rnorm(b)) / a, x) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'unangry_krill' with 5 tasks hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_result(bundle) # Map(f, x$a, x$b) #> [[1]] #> [1] 4.927103 #>  #> [[2]] #> [1] -4.398486 #>  #> [[3]] #> [1] -0.2330529 #>  #> [[4]] #> [1] -0.9244314 #>  #> [[5]] #> [1] 1.596739 #>   cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_expr.html","id":null,"dir":"Reference","previous_headings":"","what":"Create bulk tasks from an expression — task_create_bulk_expr","title":"Create bulk tasks from an expression — task_create_bulk_expr","text":"Create bulk set tasks. Variables data take precedence variables environment expr created. \"pronoun\" support yet (see rlang docs).  Use !! pull variable environment need , careful inject something really large (e.g., vector really) end revolting expression poor backtraces.  likely change semantics later, careful.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_expr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create bulk tasks from an expression — task_create_bulk_expr","text":"","code":"task_create_bulk_expr(   expr,   data,   environment = \"default\",   bundle_name = NULL,   driver = NULL,   resources = NULL,   envvars = NULL,   parallel = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_expr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create bulk tasks from an expression — task_create_bulk_expr","text":"expr expression, task_create_expr data Data wish inject row-wise expression environment Name hipercow environment evaluate task within. bundle_name Name pass hipercow_bundle_create making bundle. NULL use random name.  always overwrite, bundle_name already refers bundle replaced. driver Name driver use submit task.  default (NULL) depends configured drivers; drivers configured submission happens (indeed possible).  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured.  pass FALSE , submission prevented even driver configured. resources list generated hipercow_resources giving cluster resource requirements run task. envvars Environment variables generated hipercow_envvars, might use control task. combined default environment variables (see vignettes(\"details\"), can overridden option hipercow.default_envvars), driver-specific environment variables (see vignette(\"windows\")).  Variables provided highest precedence.  can unset environment variable setting NA. parallel Parallel configuration generated hipercow_parallel, defines method, , used initialise task parallel execution. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_expr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create bulk tasks from an expression — task_create_bulk_expr","text":"hipercow_bundle object, groups together tasks, can use set grouped functions get status (hipercow_bundle_status), results (hipercow_bundle_result) etc.","code":""},{"path":[]},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_bulk_expr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create bulk tasks from an expression — task_create_bulk_expr","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # Suppose we have a data.frame: d <- data.frame(a = 1:5, b = runif(5))  # We can create a \"bundle\" by applying an expression involving \"a\" # and \"b\": bundle <- task_create_bulk_expr(sqrt(a * b), d) #> ✔ Submitted 5 tasks using 'example' #> ✔ Created bundle 'creviced_cormorant' with 5 tasks  # Once you have your bundle, interact with it using the bundle # analogues of the usual task functions: hipercow_bundle_wait(bundle) #> [1] TRUE hipercow_bundle_result(bundle) #> [[1]] #> [1] 0.1416517 #>  #> [[2]] #> [1] 0.8682983 #>  #> [[3]] #> [1] 1.296047 #>  #> [[4]] #> [1] 1.851576 #>  #> [[5]] #> [1] 1.387101 #>   cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Create task from call — task_create_call","title":"Create task from call — task_create_call","text":"Create task based function call.  fairly similar callr::r, forms basis lapply()-like task submission.  Sending call may slightly different semantics expect send closure (function binds data), may change behaviour find happy set compromises.  See Details .  expression task_create_call(f, list(, b, c)) similar task_create_expr(f(, b, c)), use whichever prefer.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_call.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create task from call — task_create_call","text":"","code":"task_create_call(   fn,   args,   environment = \"default\",   driver = NULL,   resources = NULL,   envvars = NULL,   parallel = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create task from call — task_create_call","text":"fn function call. args list arguments pass function environment Name hipercow environment evaluate task within. driver Name driver use submit task.  default (NULL) depends configured drivers; drivers configured submission happens (indeed possible).  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured.  pass FALSE , submission prevented even driver configured. resources list generated hipercow_resources giving cluster resource requirements run task. envvars Environment variables generated hipercow_envvars, might use control task. combined default environment variables (see vignettes(\"details\"), can overridden option hipercow.default_envvars), driver-specific environment variables (see vignette(\"windows\")).  Variables provided highest precedence.  can unset environment variable setting NA. parallel Parallel configuration generated hipercow_parallel, defines method, , used initialise task parallel execution. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_call.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create task from call — task_create_call","text":"task id, string hex characters. Use interact task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_call.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create task from call — task_create_call","text":"Things pretty unambiguous pass function package, especially refer package namespace (e.g. pkg::fn). pass name without namespace package loaded library() locally loaded library within hipercow environment, may right thing may see task fail, find different function name.  may change semantics future version attach package immediately running task. pass anonymous function (e.g., function(x) x + 1) may may right thing respect environment capture.  never capture global environment function closure tries bind symbol global environment work.  Like callr::r, anonymous functions easiest think fully self contained (.e., inputs functions come args). bound local environment, may slightly better, semantics undefined subject change. R fancy things function calls try replicate.  particular may noticed works:   can end situation locally :   R looks symbol call skips non-function objects.  reconstruct environment chains exactly way locally possible.","code":"c <- \"x\" c(c, c) # a vector of two \"x\"'s f <- function(x) x + 1 local({   f <- 1   f(f) # 2 })"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_call.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create task from call — task_create_call","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # Similar to the example in task_create_call id <- task_create_call(stats::runif, list(5)) #> ✔ Submitted task '0a8b121f077bd0d28298eae0429c1038' using 'example' task_info(id) #>  #> ── task 0a8b121f077bd0d28298eae0429c1038 (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: call #>   • Call: stats::runif #>   • Args: 5 #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:43:57.381169 (moments ago) #> ! Not started yet (waiting for 66ms) #> ! Not finished yet (waiting to start) task_wait(id) #> [1] TRUE task_result(id) #> [1] 0.21784860 0.46579865 0.39692911 0.04411139 0.17253155  # Unlike task_create_explicit, variables are automatically included: id <- task_create_call(function(x, y) x + y, list(2, 5)) #> ✔ Submitted task 'c26372bbcbd7ac4010bd89120162bbbe' using 'example' task_info(id) #>  #> ── task c26372bbcbd7ac4010bd89120162bbbe (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: call #>   • Call: (anonymous) #>   • Args: 2, 5 #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:43:58.462183 (moments ago) #> ℹ Started at 2025-05-13 06:43:58.669851 (moments ago; waited 208ms) #> ! Not finished yet (waiting to start) task_wait(id) #> [1] TRUE task_result(id) #> [1] 7  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_explicit.html","id":null,"dir":"Reference","previous_headings":"","what":"Create explicit task — task_create_explicit","title":"Create explicit task — task_create_explicit","text":"Create explicit task. Explicit tasks simplest sort task hipercow nothing magic. accept R expression (quote friends) possibly set variables export global environment.  can run cluster loading variables running expression.  expression depends packages attached pass vector package names .  function may disappear, used us think package, designed really used.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_explicit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create explicit task — task_create_explicit","text":"","code":"task_create_explicit(   expr,   export = NULL,   envir = parent.frame(),   environment = \"default\",   driver = NULL,   resources = NULL,   envvars = NULL,   parallel = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_explicit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create explicit task — task_create_explicit","text":"expr Unevaluated expression object, e.g., quote export Optional character vector names objects export evaluating environment envir Local R environment find variables export. default parent frame, often right thing.  Another sensible choice .GlobalEnv use global environment. environment Name hipercow environment evaluate task within. driver Name driver use submit task.  default (NULL) depends configured drivers; drivers configured submission happens (indeed possible).  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured.  pass FALSE , submission prevented even driver configured. resources list generated hipercow_resources giving cluster resource requirements run task. envvars Environment variables generated hipercow_envvars, might use control task. combined default environment variables (see vignettes(\"details\"), can overridden option hipercow.default_envvars), driver-specific environment variables (see vignette(\"windows\")).  Variables provided highest precedence.  can unset environment variable setting NA. parallel Parallel configuration generated hipercow_parallel, defines method, , used initialise task parallel execution. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_explicit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create explicit task — task_create_explicit","text":"task id, string hex characters. Use interact task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_explicit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create explicit task — task_create_explicit","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # About the most simple task that can be created: id <- task_create_explicit(quote(sqrt(2))) #> ✔ Submitted task '824bc322842ffb9880df12c3b3fdced7' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] 1.414214  # Variables are not automatically included with the expression: a <- 5 id <- task_create_explicit(quote(sqrt(a))) #> ✔ Submitted task 'cabc0298a8fcc689e81f013641a9e632' using 'example' task_info(id) #>  #> ── task cabc0298a8fcc689e81f013641a9e632 (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: explicit #>   • Expression: sqrt(a) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:01.485149 (moments ago) #> ! Not started yet (waiting for 48ms) #> ! Not finished yet (waiting to start) task_wait(id) #> [1] FALSE task_result(id) #> <simpleError in eval(data$expr, envir): object 'a' not found>  # Include variables by passing them via 'export': id <- task_create_explicit(quote(sqrt(a)), export = \"a\") #> ✔ Submitted task '6f1e0cbcfc0e46f72cf43410a141537f' using 'example' task_info(id) #>  #> ── task 6f1e0cbcfc0e46f72cf43410a141537f (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: explicit #>   • Expression: sqrt(a) #>   • Locals: a #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:02.545186 (moments ago) #> ! Not started yet (waiting for 48ms) #> ! Not finished yet (waiting to start) task_wait(id) #> [1] TRUE task_result(id) #> [1] 2.236068  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_expr.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a task based on an expression — task_create_expr","title":"Create a task based on an expression — task_create_expr","text":"Create task based expression. similar task_create_explicit except magic, closer interface expect people use.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_expr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a task based on an expression — task_create_expr","text":"","code":"task_create_expr(   expr,   environment = \"default\",   driver = NULL,   resources = NULL,   envvars = NULL,   parallel = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_expr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a task based on an expression — task_create_expr","text":"expr expression, need quoting. See Details. environment Name hipercow environment evaluate task within. driver Name driver use submit task.  default (NULL) depends configured drivers; drivers configured submission happens (indeed possible).  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured.  pass FALSE , submission prevented even driver configured. resources list generated hipercow_resources giving cluster resource requirements run task. envvars Environment variables generated hipercow_envvars, might use control task. combined default environment variables (see vignettes(\"details\"), can overridden option hipercow.default_envvars), driver-specific environment variables (see vignette(\"windows\")).  Variables provided highest precedence.  can unset environment variable setting NA. parallel Parallel configuration generated hipercow_parallel, defines method, , used initialise task parallel execution. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_expr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a task based on an expression — task_create_expr","text":"task id, string hex characters. Use interact task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_expr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a task based on an expression — task_create_expr","text":"expression passed expr typically function call (e.g., f(x)).  analyse expression find variables reference (case f(x) x) combine function name run cluster.  x found calling environment error; behaviour subject change let us know thoughts. Alternatively may provide multiline statement using {} surround multiple lines, :   case, apply simple heuristic work x locally assigned saved expression. reference values require lot memory, hipercow error refuse save task.  prevent accidentally including values make available environment, prevent making hipercow directory excessively large.  Docs controlling process still written.","code":"task_create_expr({   x <- runif(1)   f(x) }, ...)"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_expr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a task based on an expression — task_create_expr","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # Similar to task_create_explicit, but we don't include the 'quote' id <- task_create_expr(runif(5)) #> ✔ Submitted task 'f5aa836b88310523d9feee8dc4e549c5' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] 0.2189351 0.5941505 0.8568886 0.5524367 0.2488799  # Unlike task_create_explicit, variables are automatically included: n <- 3 id <- task_create_expr(runif(n)) #> ✔ Submitted task '664209eecc6bdcc3b12d46a6f87bf088' using 'example' task_info(id) #>  #> ── task 664209eecc6bdcc3b12d46a6f87bf088 (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: runif(n) #>   • Locals: n #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:04.853214 (moments ago) #> ! Not started yet (waiting for 47ms) #> ! Not finished yet (waiting to start) task_wait(id) #> [1] TRUE task_result(id) #> [1] 0.7130433 0.8108209 0.3924359  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_script.html","id":null,"dir":"Reference","previous_headings":"","what":"Create script task — task_create_script","title":"Create script task — task_create_script","text":"Create task script.  arrange run file script via hipercow.  script must exist within hipercow root, may change directory script executes (otherwise evaluate current directory relative hipercow root, usual).","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_script.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create script task — task_create_script","text":"","code":"task_create_script(   script,   chdir = FALSE,   echo = TRUE,   environment = \"default\",   driver = NULL,   resources = NULL,   envvars = NULL,   parallel = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_script.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create script task — task_create_script","text":"script Path script chdir Logical, indicating change working directory directory containing script executing (similar chdir argument source). echo Passed source control printing evaluating.  Generally want leave TRUE environment Name hipercow environment evaluate task within. driver Name driver use submit task.  default (NULL) depends configured drivers; drivers configured submission happens (indeed possible).  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured.  pass FALSE , submission prevented even driver configured. resources list generated hipercow_resources giving cluster resource requirements run task. envvars Environment variables generated hipercow_envvars, might use control task. combined default environment variables (see vignettes(\"details\"), can overridden option hipercow.default_envvars), driver-specific environment variables (see vignette(\"windows\")).  Variables provided highest precedence.  can unset environment variable setting NA. parallel Parallel configuration generated hipercow_parallel, defines method, , used initialise task parallel execution. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_script.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create script task — task_create_script","text":"task id, string hex characters. Use interact task.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_create_script.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create script task — task_create_script","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # Create a small script; this would usually be several lines of # course.  The script will need to do something as a side effect # to be worth calling, so here we write a file. writeLines(\"saveRDS(mtcars, 'data.rds')\", \"script.R\")  # Now create a task from this script id <- task_create_script(\"script.R\") #> ✔ Submitted task 'a703a84a3f471642da6a93b84e7bde0e' using 'example' task_info(id) #>  #> ── task a703a84a3f471642da6a93b84e7bde0e (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: script #>   • Script: script.R #>   • Options: chdir = FALSE, echo = TRUE #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:06.366735 (moments ago) #> ! Not started yet (waiting for 65ms) #> ! Not finished yet (waiting to start) task_wait(id) #> [1] TRUE task_result(id) #> NULL dir() #> [1] \"data.rds\" \"hipercow\" \"script.R\"  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a task — task_eval","title":"Run a task — task_eval","text":"Run task created task_create_* function, e.g., task_create_explicit(), task_create_expr(). Generally users run function directly.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a task — task_eval","text":"","code":"task_eval(id, envir = .GlobalEnv, verbose = FALSE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a task — task_eval","text":"id task identifier envir environment evaluate expression. non-testing purposes, generally ignore , global environment likely expected environment. verbose Logical, indicating print information . root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a task — task_eval","text":"Logical indicating success (TRUE) failure (FALSE)","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a task — task_eval","text":"","code":"cleanup <- hipercow_example_helper(runner = FALSE) #> ℹ This example uses a special helper id <- task_create_expr(runif(1), driver = FALSE) # Status is only 'created', not 'submitted', as we did not submit # task.  This task can never run. task_status(id) #> [1] \"created\"  # Explicitly evaluate the task: task_eval(id, verbose = TRUE) #>  #> ── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-1ca75f229d69'  #> ℹ library paths: #>   • /home/runner/work/_temp/Library #>   • /opt/R/4.5.0/lib/R/site-library #>   • /opt/R/4.5.0/lib/R/library #> ℹ id: aa7edee7f77783fd70c3f49fed086e9e #> ℹ starting at: 2025-05-13 06:44:07.659537 #> ℹ Task type: expression #>   • Expression: runif(1) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✔ status: success #> ℹ finishing at: 2025-05-13 06:44:07.659537 (elapsed: 0.07309 secs) task_result(id) #> [1] 0.2613714  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch task information — task_info","title":"Fetch task information — task_info","text":"Fetch information task.  much detailed information task_status.  task running also fetch true status via driver, can slower.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch task information — task_info","text":"","code":"task_info(id, follow = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch task information — task_info","text":"id single task id fetch information follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch task information — task_info","text":"object class hipercow_task_info, print nicely.  just list elements: id: task identifier status: retrieved status driver: driver used run task (NA) data: task data (depends type task) times: vector times retry_chain: retry chain (NULL) can see access elements easily running unclass() result task_info().","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch task information — task_info","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper id <- task_create_expr(runif(1)) #> ✔ Submitted task '50164918b276ec3d929ce2f3f94a1a9f' using 'example' task_wait(id) #> [1] TRUE  # Task information at completion includes times: task_info(id) #>  #> ── task 50164918b276ec3d929ce2f3f94a1a9f (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: runif(1) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:07.920567 (moments ago) #> ℹ Started at 2025-05-13 06:44:08.098458 (moments ago; waited 178ms) #> ℹ Finished at 2025-05-13 06:44:08.18571 (moments ago; ran for 88ms)  # If you need to work with these times, use the \"times\" element: task_info(id)$times #>                   created                   started                  finished  #> \"2025-05-13 06:44:07 UTC\" \"2025-05-13 06:44:08 UTC\" \"2025-05-13 06:44:08 UTC\"   # If a task is retried, this information appears as a retry chain: id2 <- task_retry(id) #> ✔ Submitted task 'c72cb44006cae8ad4b3da379fa42a368' using 'example' task_info(id2, follow = FALSE) #>  #> ── task c72cb44006cae8ad4b3da379fa42a368 (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: runif(1) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:07.920567 (moments ago) #> ! Not started yet (waiting for 1.1s) #> ! Not finished yet (waiting to start) #> ℹ Last of a chain of a task retried 1 time task_info(id2) #>  #> ── task c72cb44006cae8ad4b3da379fa42a368 (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: runif(1) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:07.920567 (moments ago) #> ! Not started yet (waiting for 1.2s) #> ! Not finished yet (waiting to start) #> ℹ Last of a chain of a task retried 1 time  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_list.html","id":null,"dir":"Reference","previous_headings":"","what":"List tasks — task_list","title":"List tasks — task_list","text":"List hipercow tasks.  rarely want , can useful situations.  get requests function periodically, !  , better, functions may available (see Details).  Please aware function can quite slow, overuse scripts (please , example, call repeatedly loop - talk us tempted ).","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List tasks — task_list","text":"","code":"task_list(   task_ids = NULL,   finished_before = NULL,   in_bundle = NULL,   with_status = NULL,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List tasks — task_list","text":"task_ids character vector task identifiers.  Typically provide provide filters. finished_before date, time, difftime object representing time time ago task finished (, job might finished reason; successfully unsuccessfully unless also provide with_status argument). in_bundle character vector bundle names. Wild cards supported using shell (glob) syntax, rather regular expression syntax.  use data_* match bundles start data_ (see utils::glob2rx details).  error bundles matched, error individual pattern match. with_status character vector statuses match.  purge tasks match statuses.  Valid statuses use created, submitted, running, success, failureandcancelled`. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List tasks — task_list","text":"character vector.  may want pull vector ids bundle (e.g., hipercow_bundle_create).  order arbitrary reflect anything tasks.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List tasks — task_list","text":"Sometimes, better functions available : want list tasks order delete , might prefer hipercow_purge() want list tasks bundle, use hipercow_bundle_list() find bundle hipercow_bundle_load() load (use bundle functions) listed tasks task_list()","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Get task log — task_log_show","title":"Get task log — task_log_show","text":"Get task log, task produced one.  Tasks run dide-windows driver generally produce log.  log might quite long, might want print screen entirety (task_log_show), return character vector (task_log_value).","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get task log — task_log_show","text":"","code":"task_log_show(id, outer = FALSE, follow = TRUE, root = NULL)  task_log_value(id, outer = FALSE, follow = TRUE, root = NULL)  task_log_watch(   id,   poll = 1,   skip = 0,   timeout = NULL,   progress = NULL,   follow = TRUE,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get task log — task_log_show","text":"id task identifier outer Logical, indicating request \"outer\" logs; logs underlying HPC software hands hipercow. follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree. poll Time, seconds, used throttle calls status function. default 1 second skip Optional integer indicating handle log content exists point start watching. default (0) shows log contents.  positive integer skips many lines, negative integer shows many lines (-5 shows first five lines log).  can pass Inf discard previous logs, stream new ones. timeout time wait task complete. default wait forever. progress Logical value, indicating progress spinner used. default NULL uses option hipercow.progress, unset displays progress bar interactive session.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get task log — task_log_show","text":"Depending function: task_log_show returns log value contents invisibly, primarily displays log contents console side effect task_log_value returns character log contents task_log_watch returns status converted logical (task_wait)","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get task log — task_log_show","text":"function task_log_watch similar semantics task_wait error timeout, always displays log.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get task log — task_log_show","text":"","code":"cleanup <- hipercow_example_helper(with_logging = TRUE) #> ℹ This example uses a special helper  # Tasks that don't produce any output (print, cat, warning, etc) # will only contain logging information from hipercow itself id <- task_create_expr(runif(1)) #> ✔ Submitted task 'd50d4d047858612eeb7007b47662a7df' using 'example' task_wait(id) #> [1] TRUE task_log_show(id) #>  #> ── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-1ca71d901758'  #> ℹ library paths: #> • /home/runner/work/_temp/Library #> • /opt/R/4.5.0/lib/R/site-library #> • /opt/R/4.5.0/lib/R/library #> ℹ id: d50d4d047858612eeb7007b47662a7df #> ℹ starting at: 2025-05-13 06:44:09.839026 #> ℹ Task type: expression #> • Expression: runif(1) #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✔ status: success #> ℹ finishing at: 2025-05-13 06:44:09.839026 (elapsed: 0.2064 secs)  # If your task creates output then it will appear within the # horizontal rules: id <- task_create_explicit(quote({   message(\"Starting analysis\")   x <- mean(runif(100))   message(\"all done!\")   x })) #> ✔ Submitted task '0d95317625ef9cecd58f2cccab739227' using 'example' task_wait(id) #> [1] TRUE task_log_show(id) #>  #> ── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-1ca71d901758'  #> ℹ library paths: #> • /home/runner/work/_temp/Library #> • /opt/R/4.5.0/lib/R/site-library #> • /opt/R/4.5.0/lib/R/library #> ℹ id: 0d95317625ef9cecd58f2cccab739227 #> ℹ starting at: 2025-05-13 06:44:10.651894 #> ℹ Task type: explicit #> • Expression: { [...] #> • Locals: (none) #> • Environment: default #>   R_GC_MEM_GROW: 3 #> ───────────────────────────────────────────────────────────────── task logs ↓ ── #> Starting analysis #> all done! #>  #> ───────────────────────────────────────────────────────────────── task logs ↑ ── #> ✔ status: success #> ℹ finishing at: 2025-05-13 06:44:10.651894 (elapsed: 0.2146 secs)  # Use \"task_log_value\" to get the log value as a character vector task_log_value(id) #>  [1] \"\"                                                                                 #>  [2] \"── hipercow 1.1.5 running at '/home/runner/work/_temp/hv-20250513-1ca71d901758' \" #>  [3] \"ℹ library paths:\"                                                                 #>  [4] \"• /home/runner/work/_temp/Library\"                                                #>  [5] \"• /opt/R/4.5.0/lib/R/site-library\"                                                #>  [6] \"• /opt/R/4.5.0/lib/R/library\"                                                     #>  [7] \"ℹ id: 0d95317625ef9cecd58f2cccab739227\"                                           #>  [8] \"ℹ starting at: 2025-05-13 06:44:10.651894\"                                        #>  [9] \"ℹ Task type: explicit\"                                                            #> [10] \"• Expression: { [...]\"                                                            #> [11] \"• Locals: (none)\"                                                                 #> [12] \"• Environment: default\"                                                           #> [13] \"  R_GC_MEM_GROW: 3\"                                                               #> [14] \"───────────────────────────────────────────────────────────────── task logs ↓ ──\" #> [15] \"Starting analysis\"                                                                #> [16] \"all done!\"                                                                        #> [17] \"\"                                                                                 #> [18] \"───────────────────────────────────────────────────────────────── task logs ↑ ──\" #> [19] \"✔ status: success\"                                                                #> [20] \"ℹ finishing at: 2025-05-13 06:44:10.651894 (elapsed: 0.2146 secs)\"                 # Depending on the driver you are using, there may be useful # information in the \"outer\" log; the logs produced by the # submission system before hipercow takes over: task_log_show(id, outer = TRUE) #> Running task 0d95317625ef9cecd58f2cccab739227 #> Finished task 0d95317625ef9cecd58f2cccab739227  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Get task result — task_result","title":"Get task result — task_result","text":"Get task result. might error task failed.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get task result — task_result","text":"","code":"task_result(id, follow = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get task result — task_result","text":"id task identifier follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get task result — task_result","text":"value queued expression","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get task result — task_result","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # Typical usage id <- task_create_expr(runif(1)) #> ✔ Submitted task '6c93dc17f87fd0852ef93585f66874f0' using 'example' task_wait(id) #> [1] TRUE task_result(id) #> [1] 0.1038355  # Tasks that error return error values as results id <- task_create_expr(readRDS(\"nosuchfile.rds\")) #> ✔ Submitted task 'f1ea3a3fd8c909f1856b61169ece93db' using 'example' task_wait(id) #> [1] FALSE task_result(id) #> <simpleError in gzfile(file, \"rb\"): cannot open the connection>  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_retry.html","id":null,"dir":"Reference","previous_headings":"","what":"Retry a task — task_retry","title":"Retry a task — task_retry","text":"Retry one tasks.  creates new task copies work old one.  time transparent.  document \"advanced\" vignette written.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_retry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retry a task — task_retry","text":"","code":"task_retry(id, driver = NULL, resources = NULL, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_retry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retry a task — task_retry","text":"id identifier identifiers tasks retry. driver Name driver use submit task.  default (NULL) depends configured drivers; drivers configured submission happens (indeed possible).  exactly one driver configured submit task .  one driver configured, error, though future versions may fall back default driver one configured.  pass FALSE , submission prevented even driver configured. resources list generated hipercow_resources giving cluster resource requirements run task. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_retry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retry a task — task_retry","text":"New identifiers retried tasks","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_retry.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retry a task — task_retry","text":"ends little complicated ideal order keep things relatively fast, keeping usual guarantees race conditions etc.  Basically; retrying way task can move terminal state still modify existing task.  Instead, keep separate register whether task retried .  time retry write register.  query status etc task can add follow argument control whether check register.  assume never call parallel; retries may lost.  can run task_retry(NULL) refresh cached copy retry map need .","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_retry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retry a task — task_retry","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  # For demonstration, we just generate random numbers as then it's # more obvious that things have been rerun: id1 <- task_create_expr(runif(1)) #> ✔ Submitted task '431a79d7a2c70de29b3d473fcb7c8b96' using 'example' task_wait(id1) #> [1] TRUE task_result(id1) #> [1] 0.1360819  # Now retry the task and get the retried result: id2 <- task_retry(id1) #> ✔ Submitted task '472cab7bb76f0fcb0145a9cfb98d1f72' using 'example' task_wait(id2) #> [1] TRUE task_result(id2) #> [1] 0.1597178  # After a retry, both the original and derived tasks know about # each other: task_info(id1) #>  #> ── task 431a79d7a2c70de29b3d473fcb7c8b96 (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: runif(1) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:13.962411 (moments ago) #> ℹ Started at 2025-05-13 06:44:14.140933 (moments ago; waited 179ms) #> ℹ Finished at 2025-05-13 06:44:14.228799 (moments ago; ran for 88ms) #> ℹ 1st of a chain of a task retried 1 time, most recently '472cab7bb76f0fcb0145a9cfb98d1f72' task_info(id2) #>  #> ── task 472cab7bb76f0fcb0145a9cfb98d1f72 (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: runif(1) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:13.962411 (moments ago) #> ℹ Started at 2025-05-13 06:44:15.033324 (moments ago; waited 1.1s) #> ℹ Finished at 2025-05-13 06:44:15.034317 (moments ago; ran for 1ms) #> ℹ Last of a chain of a task retried 1 time  # By default every task will \"follow\" and access the most recent # task in the chain: task_result(id1) == task_result(id2) #> [1] TRUE  # You can prevent this by passing follow = FALSE to get the value # of this particular attempt: task_result(id1, follow = FALSE) #> [1] 0.1360819  # Tasks can be retried as many times as needed, creating a # chain. It does not matter which task you retry as we always # follow all the way to the end of the chain before retrying: id3 <- task_retry(id1) #> ✔ Submitted task 'eecdfdac91b6ec5c2e6f18a623cff4d3' using 'example' task_info(id1, follow = FALSE) #>  #> ── task 431a79d7a2c70de29b3d473fcb7c8b96 (submitted) ─────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: runif(1) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:13.962411 (moments ago) #> ℹ Started at 2025-05-13 06:44:14.225814 (moments ago; waited 264ms) #> ! Not finished yet (waiting to start) #> ℹ 1st of a chain of a task retried 2 times, most recently 'eecdfdac91b6ec5c2e6f18a623cff4d3' task_info(id3) #>  #> ── task eecdfdac91b6ec5c2e6f18a623cff4d3 (success) ───────────────────────────── #> ℹ Submitted with 'example' #> ℹ Task type: expression #>   • Expression: runif(1) #>   • Locals: (none) #>   • Environment: default #>     R_GC_MEM_GROW: 3 #> ℹ Created at 2025-05-13 06:44:13.962411 (moments ago) #> ℹ Started at 2025-05-13 06:44:16.139443 (moments ago; waited 2.2s) #> ℹ Finished at 2025-05-13 06:44:16.140352 (moments ago; ran for 1ms) #> ℹ Last of a chain of a task retried 2 times  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_status.html","id":null,"dir":"Reference","previous_headings":"","what":"Get task status — task_status","title":"Get task status — task_status","text":"Get status task. See Details lifecycle.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_status.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get task status — task_status","text":"","code":"task_status(id, follow = TRUE, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_status.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get task status — task_status","text":"id task identifier follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_status.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get task status — task_status","text":"string task status. Tasks exist status NA.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_status.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get task status — task_status","text":"task passes lifecycle: created submitted running success, failure, cancelled occur increasing order result function furthest list. Later, introduce types cope tasks blocked dependencies (become impossible due failed dependencies).","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_status.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get task status — task_status","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  ids <- c(task_create_expr(runif(1)), task_create_expr(runif(1))) #> ✔ Submitted task 'ab8c02899aca6a91b743608291c2be49' using 'example' #> ✔ Submitted task '554438d6936f0e2985d5fbf8ea22479e' using 'example' # Depending on how fast these tasks get picked up they will be one # of 'submitted', 'running' or 'success': task_status(ids) #> [1] \"submitted\" \"submitted\"  # Wait until both tasks are complete task_wait(ids[[1]]) #> [1] TRUE task_wait(ids[[2]]) #> [1] TRUE # And both are success now task_status(ids) #> [1] \"success\" \"success\"  cleanup() #> ℹ Cleaning up example"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_submit.html","id":null,"dir":"Reference","previous_headings":"","what":"Submit a task — task_submit","title":"Submit a task — task_submit","text":"Submit task queue.  lower-level function often need call.  Typically task submitted automatically driver creation (e.g., task_create_expr()), unless specified driver = FALSE yet configured driver.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_submit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Submit a task — task_submit","text":"","code":"task_submit(id, ..., resources = NULL, driver = NULL, root = NULL)"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_submit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Submit a task — task_submit","text":"id vector task ids ... Disallowed additional arguments, use. resources list generated hipercow_resources giving cluster resource requirements run task. driver name driver use, can leave blank one configured (typical). root hipercow root","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_wait.html","id":null,"dir":"Reference","previous_headings":"","what":"Wait for a task to complete — task_wait","title":"Wait for a task to complete — task_wait","text":"Wait single task complete (start).  function similar task_log_watch, except errors task complete (can used easily ensure task completed) return logs.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_wait.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wait for a task to complete — task_wait","text":"","code":"task_wait(   id,   for_start = FALSE,   timeout = NULL,   poll = 1,   progress = NULL,   follow = TRUE,   root = NULL )"},{"path":"https://mrc-ide.github.io/hipercow/reference/task_wait.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wait for a task to complete — task_wait","text":"id task identifier for_start Logical value, indicating want wait task start rather complete. block task moves away submitted, return takes status running terminal status (success, failure, cancelled). Note guarantee task still running time task_wait exits, task may finished ! timeout time wait task complete. default wait forever. poll Time, seconds, used throttle calls status function. default 1 second progress Logical value, indicating progress spinner used. default NULL uses option hipercow.progress, unset displays progress bar interactive session. follow Logical, indicating follow retried tasks. root hipercow root, path . NULL search directory tree.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_wait.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wait for a task to complete — task_wait","text":"Logical value, TRUE task completed successfully, FALSE otherwise.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_wait.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wait for a task to complete — task_wait","text":"progress spinners come cli package respond cli's options. particular cli.progress_clear cli.progress_show_after.","code":""},{"path":"https://mrc-ide.github.io/hipercow/reference/task_wait.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wait for a task to complete — task_wait","text":"","code":"cleanup <- hipercow_example_helper() #> ℹ This example uses a special helper  id <- task_create_expr(sqrt(2)) #> ✔ Submitted task '4459a1aa13297b33be4d5e39e3ccbfbb' using 'example' task_wait(id) #> [1] TRUE  cleanup() #> ℹ Cleaning up example"}]
