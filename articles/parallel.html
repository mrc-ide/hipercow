<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-GB">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Parallel Tasks • hipercow</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Parallel Tasks">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">hipercow</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.5</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/hipercow.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>General</h6></li>
    <li><a class="dropdown-item" href="../articles/packages.html">Packages and provisioning</a></li>
    <li><a class="dropdown-item" href="../articles/parallel.html">Parallel Tasks</a></li>
    <li><a class="dropdown-item" href="../articles/troubleshooting.html">Troubleshooting</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Details</h6></li>
    <li><a class="dropdown-item" href="../articles/details.html">Details</a></li>
    <li><a class="dropdown-item" href="../articles/environments.html">Environments</a></li>
    <li><a class="dropdown-item" href="../articles/stan.html">Using stan</a></li>
    <li><a class="dropdown-item" href="../articles/INLA.html">Using INLA on Windows</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Clusters</h6></li>
    <li><a class="dropdown-item" href="../articles/dide-cluster.html">The DIDE Cluster</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Advanced topics</h6></li>
    <li><a class="dropdown-item" href="../articles/workers.html">Workers</a></li>
    <li><a class="dropdown-item" href="../articles/administration.html">Administration</a></li>
    <li><a class="dropdown-item" href="../articles/migration.html">Migration from didehpc</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mrc-ide/hipercow/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Parallel Tasks</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mrc-ide/hipercow/blob/main/vignettes/parallel.Rmd" class="external-link"><code>vignettes/parallel.Rmd</code></a></small>
      <div class="d-none name"><code>parallel.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="task-level-parallelism">Task-level parallelism<a class="anchor" aria-label="anchor" href="#task-level-parallelism"></a>
</h2>
<p>Never underestimate the performance gain you might get by simple
running many tasks at the same time. If your code is written in a way
that makes it easy to run many instances of it, with different
parameters for example, then consider using
<code><a href="../reference/task_create_bulk_expr.html">task_create_bulk_expr()</a></code> to simply run those tasks, without
making any coding changes.</p>
<p>If however, you want to use multiple cores at the same time within a
task, or if your task has special requirements regarding the compute
nodes it can run on, then read this vignette.</p>
<p>As we go, we’ll be using an example cluster; the results that you’ll
get back from a real cluster will differ, but the principles should be
the same.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/hipercow_init.html">hipercow_init</a></span><span class="op">(</span><span class="st">"."</span>, driver <span class="op">=</span> <span class="st">"example"</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Initialised hipercow at '.' (/home/runner/work/_temp/hv-20250513-317295408e7)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Configured hipercow to use 'example'</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="what-resources-does-the-cluster-have">What resources does the cluster have?<a class="anchor" aria-label="anchor" href="#what-resources-does-the-cluster-have"></a>
</h2>
<p>At present, we have one Windows-based cluster, but in the future we
plan for others. Our aim is that use of
<code><a href="../reference/hipercow_resources.html">hipercow_resources()</a></code> and <code><a href="../reference/hipercow_parallel.html">hipercow_parallel()</a></code>
will be the same across the clusters we will support - yet the clusters
are likely to have different resources and queues.</p>
<p>To look up information about the cluster you are currently configured
to use, call <code><a href="../reference/hipercow_cluster_info.html">hipercow_cluster_info()</a></code> - a real example of
this is in <code>vignette("windows")</code>.</p>
<p>For the purposes of this vignette, we will be using a virtual cluster
called <code>example</code> that has a single 4-core node, and can run
the simple examples below.</p>
<p>To create a task that uses more than one core, we need to request the
resources using <code><a href="../reference/hipercow_resources.html">hipercow_resources()</a></code>, and then specify how
we want the cores to be used, using
<code><a href="../reference/hipercow_parallel.html">hipercow_parallel()</a></code>.</p>
</div>
<div class="section level2">
<h2 id="specifying-multi-core-resources">Specifying multi-core resources<a class="anchor" aria-label="anchor" href="#specifying-multi-core-resources"></a>
</h2>
<p>The <code>cores</code> and <code>exclusive</code> arguments to
<code><a href="../reference/hipercow_resources.html">hipercow_resources()</a></code> are the important ones here.</p>
<ul>
<li><p>If <code>cores</code> is an integer, then as soon as a node has
sufficient cores free, your task will launch on that node. Task
submission will fail if no node has that many cores. This is the most
common way people increase the resources allocated to their tasks in
practice.</p></li>
<li><p>If <code>cores</code> is <code>Inf</code>, then your task will
run on the first node that becomes completely free; this node could have
any number of cores. At present our nodes all have the same number of
cores. When that changes, then this will be useful for throughput if you
have a bulk number of tasks that benefit from parallel execution, and
you don’t particularly mind whether some run on 20-core machines, and
others on 32-core machines.</p></li>
<li><p>Setting <code>exclusive</code> to <code>TRUE</code>, is similar
to setting <code>cores</code> as <code>Inf</code>, in that your task
will get a whole node to itself; the difference is that the number of
cores reported to <code>hipercow</code> will be the number of cores you
request, which may be less than the number of cores the node has. This
is useful if your task cannot co-exist on the same node with another of
your tasks, or perhaps anyone else’s tasks; for example, a single-core
node that uses all the memory a node has, or a task that does some
network API access that would fail if multiple requests came from the
same IP address.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="running-parallel-tasks">Running parallel tasks<a class="anchor" aria-label="anchor" href="#running-parallel-tasks"></a>
</h2>
<p>Requesting a number of cores through <code>hipercow_resoures</code>
will cause a number of environment variables to be set when the task
starts running. These are <code>MC_CORES</code>,
<code>OMP_NUM_THREADS</code>, <code>OMP_THREAD_LIMIT</code> and
<code>R_DATATABLE_NUM_THREADS</code>, along with
<code>HIPERCOW_CORES</code> which we use internally, and their value is
the number of cores you requested.</p>
<p>Some packages (such as <a href="https://mrc-ide.github.io/dust/" class="external-link"><code>dust</code></a> or <a href="https://mc-stan.org/" class="external-link">Stan</a>) can use these environment
variables and run in parallel without you having to do anything further.
There are also ways you can explicitly say how many threads you would
like to use - see below.</p>
<p>However, if you’re not using any packages that look up these
environment variables, then requesting the resources with
<code><a href="../reference/hipercow_resources.html">hipercow_resources()</a></code> alone will not change the behaviour or
performance of your code; it will only affect the resources the cluster
reserves and allocates to your task, as it decides what tasks to run on
which nodes.</p>
<p>Hipercow provides more ways of making use of the cores we reserved.
The <code><a href="../reference/hipercow_parallel.html">hipercow_parallel()</a></code> function at present supports two
methods for running different code on the different cores you have
reserved. One is the <code>parallel</code> package, and the other is the
<code>future</code> package. In each case, <code>hipercow</code> handles
the setup of the parallel cluster for us, as we’ll describe next.</p>
<div class="section level3">
<h3 id="using-the-parallel-package">Using the Parallel package<a class="anchor" aria-label="anchor" href="#using-the-parallel-package"></a>
</h3>
<p>In this example, we reserve two cores on the cluster, and then call
<code>hipercow_parallel("parallel")</code> which sets up a team of
workers (two in this case), each of which use one of the allocated
cores.</p>
<p>The <code>parallel</code> package is built into R and provides a
simple, if somewhat eccentric, approach to multi-process parallelism.
There is an introductory vignette in
<code><a href="https://cran.rstudio.com/web/packages/parallel/vignettes/parallel.pdf" class="external-link">vignette("parallel", package = "parallel")</a></code>. The general
strategy when using <code>parallel</code> is to write code that you
could run with <code><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply()</a></code>, then use
<code><a href="https://rdrr.io/r/parallel/clusterApply.html" class="external-link">parallel::clusterApply()</a></code> to run it in parallel instead,
with no other changes needed.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">id</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/task_create_expr.html">task_create_expr</a></span><span class="op">(</span></span>
<span>  <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/clusterApply.html" class="external-link">clusterApply</a></span><span class="op">(</span><span class="cn">NULL</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  parallel <span class="op">=</span> <span class="fu"><a href="../reference/hipercow_parallel.html">hipercow_parallel</a></span><span class="op">(</span><span class="st">"parallel"</span><span class="op">)</span>,</span>
<span>  resources <span class="op">=</span> <span class="va">resources</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Submitted task '74a7acec5b15960454ce6189544de365' using 'example'</span></span>
<span><span class="fu"><a href="../reference/task_wait.html">task_wait</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="../reference/task_info.html">task_info</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">task 74a7acec5b15960454ce6189544de365 (success)</span> <span style="color: #00BBBB;">─────────────────────────────</span></span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Submitted with 'example'</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Task type: expression</span></span>
<span><span class="co">#&gt; • Expression: parallel::clusterApply(NULL, 1:2, function(x) Sys.sleep(5))</span></span>
<span><span class="co">#&gt; • Locals: (none)</span></span>
<span><span class="co">#&gt; • Environment: default</span></span>
<span><span class="co">#&gt;   R_GC_MEM_GROW: 3</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Created at 2025-05-13 06:45:08.562571 (moments ago)</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Started at 2025-05-13 06:45:08.8118 (moments ago; waited 250ms)</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Finished at 2025-05-13 06:45:14.392728 (moments ago; ran for 5.6s)</span></span></code></pre></div>
<p>By specifying the <code>parallel</code> argument here,
<code>hipercow</code> will start up a “cluster” within your job for you,
so that the <code><a href="https://rdrr.io/r/parallel/clusterApply.html" class="external-link">parallel::clusterApply</a></code> command runs across two
processes.</p>
</div>
<div class="section level3">
<h3 id="using-the-future-package">Using the <code>future</code> package<a class="anchor" aria-label="anchor" href="#using-the-future-package"></a>
</h3>
<p>The <a href="https://future.futureverse.org/" class="external-link"><code>future</code></a>
package, is similar in use to <code>parallel</code>, and some prefer the
way of using it such as with the <a href="https://furrr.futureverse.org/" class="external-link"><code>furrr</code></a> package, as
it offers very high-level interfaces that match closely those in the <a href="https://purrr.tidyverse.org/" class="external-link"><code>purrr</code></a> package.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">id</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/task_create_expr.html">task_create_expr</a></span><span class="op">(</span></span>
<span>  <span class="fu">furrr</span><span class="fu">::</span><span class="fu"><a href="https://furrr.futureverse.org/reference/future_map.html" class="external-link">future_map</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  parallel <span class="op">=</span> <span class="fu"><a href="../reference/hipercow_parallel.html">hipercow_parallel</a></span><span class="op">(</span><span class="st">"future"</span><span class="op">)</span>,</span>
<span>  resources <span class="op">=</span> <span class="va">resources</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Submitted task 'f59df07a80af6af2fbd154573f7b8ec4' using 'example'</span></span>
<span><span class="fu"><a href="../reference/task_wait.html">task_wait</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="../reference/task_info.html">task_info</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">task f59df07a80af6af2fbd154573f7b8ec4 (success)</span> <span style="color: #00BBBB;">─────────────────────────────</span></span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Submitted with 'example'</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Task type: expression</span></span>
<span><span class="co">#&gt; • Expression: furrr::future_map(1:2, ~ Sys.sleep(5))</span></span>
<span><span class="co">#&gt; • Locals: (none)</span></span>
<span><span class="co">#&gt; • Environment: default</span></span>
<span><span class="co">#&gt;   R_GC_MEM_GROW: 3</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Created at 2025-05-13 06:45:14.75306 (moments ago)</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Started at 2025-05-13 06:45:15.042385 (moments ago; waited 290ms)</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Finished at 2025-05-13 06:45:21.276278 (moments ago; ran for 6.2s)</span></span></code></pre></div>
<p>In our testing though, <code>furrr</code> has much higher overheads
than than <code>parallel</code>. In the test above, <code>future</code>
usually takes close to 8 seconds, whereas <code>parallel</code> above
takes just over 5. So perhaps test your code at an early stage to see
whether the difference matters to you, compared to which package you
prefer writing code with. We expect this overhead will reduce in impact
as the amount of work you do in each parallel task increases (if the
overhead is 3s but your parallelised task takes 10 minutes, this
overhead is negligible, especially if you find it easier to use).</p>
<p>In this example, we would also need the <code>furrr</code> package to
be provisioned using <code><a href="../reference/hipercow_provision.html">hipercow_provision()</a></code>.</p>
</div>
<div class="section level3">
<h3 id="specifying-more-work-than-there-are-cores">Specifying more work than there are cores<a class="anchor" aria-label="anchor" href="#specifying-more-work-than-there-are-cores"></a>
</h3>
<p>With the <code>future_map</code> and <code>clusterApply</code>
examples above, we provided a vector of work to do - in this case simply
<code>1:2</code>. In these examples, this exactly matches the number of
cores we requested using <code>hipercow_resources</code>. The amount of
work could be larger, for example <code>1:4</code>, but in both methods,
only 2 processes will be run concurrently, because this is what we
requested, and is how <code>hipercow_parallel</code> initialised the
cluster. The extra processes have to queue until an allocated core is
free. For <a href="example:-" class="uri">example:-</a></p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">id</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/task_create_expr.html">task_create_expr</a></span><span class="op">(</span></span>
<span>  <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/clusterApply.html" class="external-link">clusterApply</a></span><span class="op">(</span><span class="cn">NULL</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html" class="external-link">Sys.sleep</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  parallel <span class="op">=</span> <span class="fu"><a href="../reference/hipercow_parallel.html">hipercow_parallel</a></span><span class="op">(</span><span class="st">"parallel"</span><span class="op">)</span>,</span>
<span>  resources <span class="op">=</span> <span class="va">resources</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Submitted task 'b7552c46e271e088931d9cb5127229fd' using 'example'</span></span>
<span><span class="fu"><a href="../reference/task_wait.html">task_wait</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="../reference/task_info.html">task_info</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">──</span> <span style="font-weight: bold;">task b7552c46e271e088931d9cb5127229fd (success)</span> <span style="color: #00BBBB;">─────────────────────────────</span></span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Submitted with 'example'</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Task type: expression</span></span>
<span><span class="co">#&gt; • Expression: parallel::clusterApply(NULL, 1:3, function(x) Sys.sleep(2))</span></span>
<span><span class="co">#&gt; • Locals: (none)</span></span>
<span><span class="co">#&gt; • Environment: default</span></span>
<span><span class="co">#&gt;   R_GC_MEM_GROW: 3</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Created at 2025-05-13 06:45:21.904811 (moments ago)</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Started at 2025-05-13 06:45:22.126021 (moments ago; waited 222ms)</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Finished at 2025-05-13 06:45:26.700665 (moments ago; ran for 4.6s)</span></span></code></pre></div>
<p>Here we reserve 2 cores, and then map 3 processes onto the cluster,
each of which will take 2 seconds. It takes more than 4 seconds in all,
because we can’t run the 3 processes at the same time; one of them has
to wait for a free core.</p>
</div>
<div class="section level3">
<h3 id="how-many-cores-should-each-process-use">How many cores should each process use?<a class="anchor" aria-label="anchor" href="#how-many-cores-should-each-process-use"></a>
</h3>
<p>The number of cores available to a process can be looked up with
<code>hipercow_parallel_get_cores</code>. For the main process, this
will be the same as the number of cores requested using
<code>hipercow_resources</code>, but for the workers created by the
<code>future</code> or <code>parallel</code> clusters, the result will
be 1, as we initialise a separate process per core.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">id</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/task_create_expr.html">task_create_expr</a></span><span class="op">(</span><span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/unlist.html" class="external-link">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu">hipercow</span><span class="fu">::</span><span class="fu"><a href="../reference/hipercow_parallel_get_cores.html">hipercow_parallel_get_cores</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>      <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/clusterApply.html" class="external-link">clusterApply</a></span><span class="op">(</span></span>
<span>        <span class="cn">NULL</span>,</span>
<span>        <span class="fl">1</span><span class="op">:</span><span class="fl">4</span>,</span>
<span>        <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">hipercow</span><span class="fu">::</span><span class="fu"><a href="../reference/hipercow_parallel_get_cores.html">hipercow_parallel_get_cores</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  parallel <span class="op">=</span> <span class="fu"><a href="../reference/hipercow_parallel.html">hipercow_parallel</a></span><span class="op">(</span><span class="st">"parallel"</span><span class="op">)</span>,</span>
<span>  resources <span class="op">=</span> <span class="va">resources</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Submitted task 'edc63a67e66f0ed4fb0a30995db27d12' using 'example'</span></span>
<span><span class="fu"><a href="../reference/task_wait.html">task_wait</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="../reference/task_result.html">task_result</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 4 1 1 1 1</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="multiple-cores-per-process">Multiple cores per process<a class="anchor" aria-label="anchor" href="#multiple-cores-per-process"></a>
</h3>
<p>In the previous example, we created a cluster that could run 4
processes at the same time, but each of those 4 processes was a
single-core task. We could not do any nested parallelism within those 4
processes. If we want to do that - to have nested parallelism - we can
use the <code>cores_per_process</code> argument to
<code>hipercow_parallel</code>, and create a number of processes as
before, but each of which might have a number of cores allocated to
it.</p>
<p>This would be useful if, for example, we requested 32 cores, and we
wanted to run 4 concurrent tasks using <code>future_map</code> or
<code>clusterApply</code>, each of which would have 8 cores to do
something parallel with, perhaps using <code>Stan</code>, or
<code>dust</code>. Our example cluster is rather smaller, but here we
create a pair of 2-core process using <code>parallel</code>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">id</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/task_create_expr.html">task_create_expr</a></span><span class="op">(</span><span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/unlist.html" class="external-link">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu">hipercow</span><span class="fu">::</span><span class="fu"><a href="../reference/hipercow_parallel_get_cores.html">hipercow_parallel_get_cores</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>      <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/clusterApply.html" class="external-link">clusterApply</a></span><span class="op">(</span></span>
<span>        <span class="cn">NULL</span>,</span>
<span>        <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,</span>
<span>        <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">hipercow</span><span class="fu">::</span><span class="fu"><a href="../reference/hipercow_parallel_get_cores.html">hipercow_parallel_get_cores</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  parallel <span class="op">=</span> <span class="fu"><a href="../reference/hipercow_parallel.html">hipercow_parallel</a></span><span class="op">(</span><span class="st">"parallel"</span>, cores_per_process <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>  resources <span class="op">=</span> <span class="va">resources</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Submitted task 'f560e94bb7e4759412da0a4b4f6de1fc' using 'example'</span></span>
<span><span class="fu"><a href="../reference/task_wait.html">task_wait</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="../reference/task_result.html">task_result</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 4 2 2</span></span></code></pre></div>
<p>Now each process knows it has 2 cores allocated, so we could update
the function <code>clusterApply</code> is calling, to pass the result of
<code>hipercow_parallel_get_cores</code> into some other function that
supports parallel processing. We could also use <code>x</code>, which
here will be <code>1</code> or <code>2</code> on the pair of processes,
to cause different behaviour on each process.</p>
</div>
<div class="section level3">
<h3 id="other-ways-of-using-cores">Other ways of using cores<a class="anchor" aria-label="anchor" href="#other-ways-of-using-cores"></a>
</h3>
<p>There are other packages that can use multiple cores, and often the
number of cores they use can be set with environment variables. Hipercow
automatically sets some useful variables to indicate how many cores the
cluster has allocated to your task - even if you don’t call
<code>hipercow_parallel</code>.</p>
<p>These will be visible to all packages that use them. For example, the
<code>parallel</code> package uses <code>MC_CORES</code>, C++ code using
OpenMP will look up <code>OMP_NUM_THREADS</code> when the function
<code>omp_get_max_threads()</code> is called. Here are a couple of
examples using the <code>dust</code> package (which again would need to
be provisioned if you run this on a real cluster).</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">id</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/task_create_expr.html">task_create_expr</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">dust</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/dust/man/dust_openmp_support.html" class="external-link">dust_openmp_support</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">res</span><span class="op">[[</span><span class="st">"num_procs"</span><span class="op">]</span><span class="op">]</span>, <span class="va">res</span><span class="op">[[</span><span class="st">"OMP_NUM_THREADS"</span><span class="op">]</span><span class="op">]</span>, <span class="va">res</span><span class="op">[[</span><span class="st">"MC_CORES"</span><span class="op">]</span><span class="op">]</span>,</span>
<span>    <span class="fu">dust</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/dust/man/dust_openmp_threads.html" class="external-link">dust_openmp_threads</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span>,</span>
<span>resources <span class="op">=</span> <span class="va">resources</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Submitted task 'f544a2eda5916bf1e4a354c2bffe1598' using 'example'</span></span>
<span><span class="fu"><a href="../reference/task_wait.html">task_wait</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="../reference/task_result.html">task_result</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 4 2 2 2</span></span></code></pre></div>
<p>Here, the <code>num_procs</code> value dust gives us, is the number
of cores the machine has, not all of which may have been allocated to
our job. In this case, only two cores are for us to use, which is what
the other environment variables report, and what <code>dust</code> is
going to use. Below, we’ll see dust generating random numbers for us
with different numbers of threads. Note the final column
<code>total_time</code> decreases as we do the same amount of work with
more threads.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">id</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/task_create_expr.html">task_create_expr</a></span><span class="op">(</span><span class="op">{</span></span>
<span>  <span class="va">rng</span> <span class="op">&lt;-</span> <span class="fu">dust</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/dust/man/dust_rng.html" class="external-link">dust_rng</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>seed <span class="op">=</span> <span class="fl">1</span>, n_streams <span class="op">=</span> <span class="fl">32</span><span class="op">)</span></span>
<span>  <span class="fu">bench</span><span class="fu">::</span><span class="fu"><a href="https://bench.r-lib.org/reference/mark.html" class="external-link">mark</a></span><span class="op">(</span></span>
<span>    one <span class="op">=</span> <span class="va">rng</span><span class="op">$</span><span class="fu">random_normal</span><span class="op">(</span><span class="fl">1000000</span>, n_threads <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>    two <span class="op">=</span> <span class="va">rng</span><span class="op">$</span><span class="fu">random_normal</span><span class="op">(</span><span class="fl">1000000</span>, n_threads <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>    four <span class="op">=</span> <span class="va">rng</span><span class="op">$</span><span class="fu">random_normal</span><span class="op">(</span><span class="fl">1000000</span>, n_threads <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>    check <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>    time_unit <span class="op">=</span> <span class="st">"s"</span><span class="op">)</span></span>
<span>  <span class="op">}</span>, resources <span class="op">=</span> <span class="va">resources</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #00BB00;">✔</span> Submitted task 'b89bfff26886eaa0c7f18d265941d56b' using 'example'</span></span>
<span><span class="fu"><a href="../reference/task_wait.html">task_wait</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu"><a href="../reference/task_result.html">task_result</a></span><span class="op">(</span><span class="va">id</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 3 × 13</span></span></span>
<span><span class="co">#&gt;   expression   min median `itr/sec` mem_alloc  `gc/sec` n_itr  n_gc total_time</span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;bnch_xpr&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;bnch_byt&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span> <span style="color: #949494;">&lt;language&gt;</span> 1.04   1.04      0.959 256003144     0.959     1     1      1.04 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span> <span style="color: #949494;">&lt;language&gt;</span> 0.506  0.506     1.97  256000048     1.97      1     1      0.506</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">3</span> <span style="color: #949494;">&lt;language&gt;</span> 0.352  0.356     2.81  256000048     2.81      2     2      0.712</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># ℹ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;</span></span></span></code></pre></div>
<p>You may want to set the environment variables so that dust and other
packages use a different number of cores. For example, perhaps you have
acquired a whole 32 core node because of memory reasons, but your
parallel algorithms are not able to use that many cores optimally, and a
smaller number is better. (There are examples where this is the case).
Here, you could call <code>hipercow_parallel_set_cores</code> with the
number of cores you want, and all the environment variables will take
that value.</p>
<p>A better way of solving that problem though, is to specify a memory
requirement:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>memory_per_node <span class="op">=</span> <span class="st">"256G"</span>,</span>
<span>                                exclusive <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                                cores <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<p>(and passing this in as the <code>resources</code> argument to a task
creation function). See below for more details.</p>
</div>
</div>
<div class="section level2">
<h2 id="specifying-which-nodes-should-run-your-tasks">Specifying which nodes should run your tasks<a class="anchor" aria-label="anchor" href="#specifying-which-nodes-should-run-your-tasks"></a>
</h2>
<p>We’ve already set the number of cores your task needs, so that is one
way that might limit the nodes capable of running your task.
Additionally, if you have specific memory requirements for your tasks, a
specific queue to run your tasks on, or even specific nodes they should
be run on, these can be specified with the arguments to
<code>hipercow_resources</code> in several different ways, which we
outline below.</p>
<div class="section level3">
<h3 id="memory-requests">Memory requests<a class="anchor" aria-label="anchor" href="#memory-requests"></a>
</h3>
<p>Two methods are currently provided for specifying memory usage. These
can be specified as an integer number of gigabytes, or alternative as
strings such as <code>"64G</code>” or <code>"1T"</code> to represent
64Gb, or 1Tb respectively.</p>
<ul>
<li><p>The <code>memory_per_node</code> specifies very simply that your
task should only be run on a node that has at least that much memory.
Remember that the node’s memory will be shared between all the tasks
running on that node, so you could also consider specifying
<code>cores = Inf</code>, or <code>exclusive = TRUE</code> if you think
you’ll need the whole node’s memory to yourself.</p></li>
<li><p>If you are launching many tasks, and know the maximum memory your
task needs, then you can specify <code>memory_per_process</code> to tell
the cluster about that. The cluster will then avoid allocating too many
of your tasks to the same node, if the combined memory needed by those
tasks will exceed what the node has. This can’t really be guaranteed,
unless everyone agrees to set <code>memory_per_process</code>, but it
should help in the common case where your own tasks might be stacked up
on a node together.</p></li>
</ul>
</div>
<div class="section level3">
<h3 id="running-on-specific-nodes">Running on specific nodes<a class="anchor" aria-label="anchor" href="#running-on-specific-nodes"></a>
</h3>
<p>At present, the nodes on the new cluster are all very similar to each
other, and there is no partitioning of nodes between users or groups. It
is a free-for-all, with little variation in specification for the nodes.
This may change over time, as the cluster grows, and as the user base
grows.</p>
<p>In the future, there may be some nodes, or queues of nodes, that are
more appropriate for your tasks than others, either because of their
specification, or because of some groups having priority access to nodes
they may have purchased, for example.</p>
<p>We’ve already noted that specifying cores or memory requirements will
cause your tasks to run on a node meeting those requirements.
Additionally, we can explicitly say that tasks should be submitted to a
particular <em>queue</em>, or that tasks should be run only on
particular <em>named nodes</em>. See below.</p>
<div class="section level4">
<h4 id="selecting-by-queue">Selecting by queue<a class="anchor" aria-label="anchor" href="#selecting-by-queue"></a>
</h4>
<p>At present, the new cluster only has one queue for general use,
called <code>AllNodes</code> containing, as it says, all the available
compute nodes. At other times though, during workshops for example we
have run a <code>Training</code> queue, with strict limits, to ensure
we’ve had capacity to demonstrate cluster use in a live setting.</p>
<p>It also may be necessary in the future to partition the set of nodes,
either by their capabilities if that becomes significant to some users,
or by which research group might have purchased them, or to allow a
particular group more protected access for a period.</p>
<p>Here’s how to see the queues, and choose one, using the
<code>example</code> cluster.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/hipercow_cluster_info.html">hipercow_cluster_info</a></span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">resources</span><span class="op">$</span><span class="va">queues</span></span>
<span><span class="co">#&gt; [1] "alltasks" "bigmem"   "fast"</span></span>
<span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span>queue <span class="op">=</span> <span class="st">"bigmem"</span><span class="op">)</span></span></code></pre></div>
<p>then as before, we pass <code>resources</code> to any of the
<code>task_create_</code> functions.</p>
</div>
<div class="section level4">
<h4 id="selecting-by-node-names">Selecting by node names<a class="anchor" aria-label="anchor" href="#selecting-by-node-names"></a>
</h4>
<p>Even more rarely, you may have a particular named node you want to
run on. In the past, for instance, we have had specific nodes with
unique hardware (such as very large RAM or large disks). Or
occasionally, we may want to try and replicate a failure by rerunning a
task using the same node on which the failure occurred.</p>
<p>Again, using the <code>example</code> cluster, we can set the
<code>requested_nodes</code> argument, :-</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/hipercow_cluster_info.html">hipercow_cluster_info</a></span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">resources</span><span class="op">$</span><span class="va">nodes</span></span>
<span><span class="co">#&gt; [1] "node-1" "node-2" "gpu-3"  "gpu-4"</span></span>
<span><span class="va">resources</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hipercow_resources.html">hipercow_resources</a></span><span class="op">(</span></span>
<span>  requested_nodes <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gpu-3"</span>, <span class="st">"gpu-4"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>and again, <code>resources</code> gets passed to one of the
<code>task_create_</code> functions.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="task-time-limits-and-scheduling">Task time limits and scheduling<a class="anchor" aria-label="anchor" href="#task-time-limits-and-scheduling"></a>
</h2>
<p>Our clusters over the years have essentially be run on the basis of
good will, rather than having too many limits over how long tasks can
run for, or how much resource they can use. For our fairly small
department, this is a nice way to work, meaning you can usually get the
resources you need, even if your needs are quite demanding for a period
of time. Usage fluctuates depending on deadlines and the development
cycle of projects. It is relatively rare that many people or projects
have demanding needs at the same time, such that capacity of the cluster
becomes problematic. But if needs do coincide, we resolve them mainly by
communication, rather than cluster rules.</p>
<p>That said, <code>hipercow</code> offers a few options for limiting
how long your tasks can run for, specifying when your tasks can run on
the cluster, and also allows you to politely allow other tasks to take
priority over yours. If we know how long tasks will take, then we have
the potential in the future to priorities smaller faster tasks ahead of
larger slower ones.</p>
<div class="section level3">
<h3 id="the-maximum-runtime">The maximum runtime<a class="anchor" aria-label="anchor" href="#the-maximum-runtime"></a>
</h3>
<p>If you know how long your task should take, and you’d like to abort
if it takes longer, then use the <code>max_runtime</code> argument when
requesting your resources. You can specify an integer number of minutes,
or strings involving the letters <code>d</code>, <code>h</code> and
<code>m</code>, for days, hours and minutes, such as <code>"40d</code>”
or <code>"1h30"</code>.</p>
<p>This might be useful if you have stochastic fitting tasks that might
not be converging, and you’d like a time limit after which the tasks are
aborted. Or perhaps you have a task that you’d only like to run for a
while to check that the early stages look good.</p>
</div>
<div class="section level3">
<h3 id="delaying-tasks-starting">Delaying tasks starting<a class="anchor" aria-label="anchor" href="#delaying-tasks-starting"></a>
</h3>
<p>If you are about to launch a large number of very time consuming
tasks, that are not crucially urgent, it may be helpful to others if
they could start running on the cluster outside of working hours. You
can do this by setting the <code>hold_until</code> argument for
<code>hipercow_resources</code>. A number of formats are allowed:-</p>
<ul>
<li>An integer represents a number of minutes.</li>
<li>Strings in the form <code>"5h"</code> or <code>"1h30"</code> or
<code>"2d"</code> can delay for hours, minutes or days.</li>
<li>R’s <code>Date</code> type can be used to indicate midnight on the
given date.</li>
<li>R’s <code>POSIXt</code> type a date and time to be represented.</li>
<li>
<code>"tonight"</code> makes a task wait until after 7pm this
evening before starting.</li>
<li>
<code>"midnight"</code> delays a task until tomorrow begins.</li>
<li>
<code>"weekend"</code> delays a task until midnight on
Saturday.</li>
</ul>
</div>
<div class="section level3">
<h3 id="lowering-your-priority">Lowering your priority<a class="anchor" aria-label="anchor" href="#lowering-your-priority"></a>
</h3>
<p>If you are about to launch a large number of tasks, another way of
being polite to your colleagues is to set <code>priority = "low"</code>
in <code>hipercow_resources</code>. This allows tasks lower down the
queue with <code>normal</code> priority to overtake your
<code>low</code> priority tasks and run on available resources first.
Effectively, it means you can launch large volumes of tasks without
annoying people, getting all the available resources, but without
holding others up very much if they also need something to run.</p>
<p>This never causes your running tasks to get cancelled; it is only
relevant when there are available resources on a node for the scheduler
to consider which tasks to allocate those resources too. Therefore, low
priority works best if additionally your tasks don’t take too long to
run, so there are reasonably frequent opportunities for the scheduler to
decide what to do.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Rich FitzJohn, Wes Hinsley, Paul Liétar.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer>
</div>





  </body>
</html>
