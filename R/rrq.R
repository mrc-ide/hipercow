##' Create an rrq controller for your queue, and set it as the default
##' controller.  Use this to interact with workers created with
##' [hipercow_rrq_workers_submit()].  Proper docs forthcoming, all
##' interfaces are subject to some change.
##'
##' @title Create an rrq controller
##'
##' @param ... Additional arguments passed through to
##'   [rrq::rrq_controller()]; currently this is `follow` and
##'   `timeout_task_wait`.
##'
##' @param driver Name of the driver to use.  The default (`NULL`)
##'   depends on your configured drivers; if you have no drivers
##'   configured we will error as we lack information required to
##'   proceed.  If you have exactly one driver configured we'll submit
##'   your task with it.  If you have more than one driver configured,
##'   then we will error, though in future versions we may fall back
##'   on a default driver if you have one configured.
##'
##' @param set_as_default Set the rrq controller to be the default;
##'   this is usually what you want.
##'
##' @param queue_id The rrq queue id to use. This parameter is used internally
##'   by hipercow. You shouldn't ever need to pass a value for this.
##'
##' @inheritParams task_create_expr
##'
##' @return An [rrq::rrq_controller] object.
##'
##' @export
hipercow_rrq_controller <- function(..., set_as_default = TRUE, driver = NULL,
                                    queue_id = NULL, root = NULL) {
  call <- rlang::current_env()
  check_package_version("rrq", "0.7.20", call = call)

  root <- hipercow_root(root)

  offload_path <- hipercow_rrq_offload_path(root)
  offload_threshold_size <- getOption("hipercow.rrq_offload_threshold_size",
                                      100000) # 100k

  if (is.null(queue_id)) {
    driver <- hipercow_driver_select(driver, TRUE, root, call)
    r <- rrq_prepare(driver, root,
                     offload_path = offload_path,
                     offload_threshold_size = offload_threshold_size,
                     ...,
                     call = call)
  } else {
    # TODO: this uses an offload_threshold_size that was re-evaluated locally
    # from the options, when we would maybe want to either inherit it from the
    # caller or read it out of the rrq worker config.
    #
    # Alternatively, we could use the controller that is already created by the
    # worker code and not re-create one ourselves.
    cli::cli_alert_success("Connecting to rrq queue '{queue_id}' from task")
    r <- rrq::rrq_controller(queue_id, con = redux::hiredis(),
                             offload_path = offload_path,
                             offload_threshold_size = offload_threshold_size,
                             ...)
  }
  if (set_as_default) {
    rrq::rrq_default_controller_set(r)
  }
  r
}


##' Submit workers to the cluster, use this in conjunction with
##' [hipercow_rrq_controller].  A worker may sit on a single core or a
##' whole node depending on how you set up `resources`.  We use the
##' `rrq` environment if it exists ([hipercow_environment_create])
##' otherwise we'll use the `default` environment.
##'
##' @title Submit rrq workers
##'
##' @param n The number of workers to submit. This is the only
##'   required argument.
##'
##' @inheritParams hipercow_rrq_controller
##'
##' @param resources A list generated by [hipercow_resources] giving
##'   the cluster resource requirements to run your task.
##'
##' @param envvars Environment variables as generated by
##'   [hipercow_envvars], which you might use to control your task.
##'
##' @param parallel Parallel configuration as generated by
##'   [hipercow_parallel], which defines which method, if any, will be
##'   used to initialise your worker for parallel execution (which
##'   means you have to think about parallelism at three levels at
##'   least, a diagram may help here).
##'
##' @param timeout Time to wait for workers to appear.
##'
##' @param progress Should we display a progress bar?
##'
##' @inheritParams task_eval
##'
##' @return A data.frame with information about the launch, with columns:
##'
##' * `queue_id`: the rrq queue id (same for all workers)
##' * `worker_id`: the rrq worker identifier
##' * `task_id`: the hipercow task identifier
##' * `bundle_name`: the hipercow bundle name (same for all workers)
##'
##' @export
hipercow_rrq_workers_submit <- function(n,
                                        driver = NULL, resources = NULL,
                                        envvars = NULL, parallel = NULL,
                                        timeout = NULL, progress = NULL,
                                        root = NULL) {
  root <- hipercow_root(root)
  call <- rlang::current_env()
  assert_scalar_integer(n, call = call)

  driver <- hipercow_driver_select(driver, TRUE, root, call)
  r <- hipercow_rrq_controller(driver = driver, root = root,
                               set_as_default = FALSE)

  progress <- show_progress(progress, call)
  timeout <- timeout_value(timeout, call)

  path <- relative_workdir(root$path$root)
  if (path != ".") {
    cli::cli_abort(
      c("Can't submit workers from below hipercow root",
        i = paste("Your path relative to the hipercow root is '{path}' but",
                  "for now we need to start all workers from the root,",
                  "otherwise it creates issues for saving data."),
        i = paste("We plan on relaxing this soon; please let us know",
                  "that you have seen this message")))
  }

  queue_id <- r$queue_id
  worker_ids <- sprintf("rrq-%s-%s",
                        sub("^rrq:", "", queue_id),
                        ids::random_id(n, bytes = 6))
  args <- data.frame(queue_id = queue_id, worker_id = worker_ids)
  ## The messages here are mostly quite confusing, we might want to
  ## suppress them, I think.
  grp <- task_create_bulk_call(hipercow_rrq_worker,
                               args,
                               environment = "empty",
                               envvars = envvars,
                               parallel = parallel,
                               resources = resources,
                               driver = driver,
                               root = root)

  is_dead <- rrq_worker_is_dead(grp)
  fetch_logs <- rrq_worker_fetch_logs(grp, worker_ids)

  rrq::rrq_worker_wait(worker_ids, timeout = timeout, progress = progress,
                       controller = r,
                       is_dead = is_dead, fetch_logs = fetch_logs)
  args$task_id <- grp$ids
  args$bundle_name <- grp$name
  args
}


##' Tell workers to exit once work is complete
##'
##' @title Tell workers to exit once complete
##'
##' @inheritParams hipercow_rrq_controller
##'
##' @return Nothing, called for side effects only
##' @export
hipercow_rrq_stop_workers_once_idle <- function(root = NULL) {
  r <- hipercow_rrq_controller(root = root)
  worker_ids <- rrq::rrq_worker_list(controller = r)
  n <- length(worker_ids)
  if (n == 0) {
    cli::cli_alert_warning("No workers to send messages to")
  } else {
    rrq::rrq_message_send("TIMEOUT_SET", 0, worker_ids, controller = r)
    cfg <- rrq::rrq_worker_config_read("hipercow", controller = r)
    cli::cli_alert_success("Sent message to {n} worker{?s}")
    cli::cli_alert_info(
      "Workers will stop {cfg$poll_queue} second{?s} after their last task")
    status <- table(rrq::rrq_worker_status(worker_ids, controller = r))
    status_str <- paste(
      sprintf("%s (%d)", names(status), status), collapse = ", ")
    cli::cli_alert_info(
      "Current worker status: {status_str}")
  }
}


rrq_prepare <- function(driver, root, offload_threshold_size,
                        ..., call = NULL) {
  ensure_package("rrq", "0.7.23")
  ensure_package("redux")
  driver <- hipercow_driver_select(driver, TRUE, root, call)
  info <- cluster_info(driver, root)
  if (is.null(info$redis_url)) {
    cli::cli_abort("No redis support for '{driver}'")
  }
  con <- redux::hiredis(url = info$redis_url)
  path_queue_id <- file.path(root$path$rrq, driver)
  if (file.exists(path_queue_id)) {
    queue_id <- readLines(path_queue_id)
    cli::cli_alert_success("Using existing rrq queue '{queue_id}'")
    return(rrq::rrq_controller(queue_id, con, ...))
  }

  queue_id <- paste0("rrq:", ids::random_id(bytes = 4))

  ## TODO: Some hard coding here that needs a bit of work, though
  ## practically these can all be worked around after initialisation
  ## easily enough.
  timeout_idle <- 300 # 5 minutes
  heartbeat_period <- 60 # one minute

  r <- rrq::rrq_controller(queue_id, con,
                           offload_threshold_size = offload_threshold_size,
                           ...)

  cfg <- rrq::rrq_worker_config(timeout_idle = timeout_idle,
                                heartbeat_period = heartbeat_period,
                                offload_threshold_size = offload_threshold_size,
                                verbose = FALSE)
  rrq::rrq_worker_config_save("hipercow", cfg, controller = r)
  rrq::rrq_worker_envir_set(hipercow_rrq_envir, notify = FALSE, controller = r)

  fs::dir_create(dirname(path_queue_id))
  cli::cli_alert_success("Created new rrq queue '{queue_id}'")
  writeLines(queue_id, path_queue_id)
  r
}


hipercow_rrq_worker <- function(queue_id, worker_id) {
  ## nocov start
  root <- hipercow_root()
  offload_path <- hipercow_rrq_offload_path(root)
  w <- rrq::rrq_worker$new(queue_id,
                           name_config = "hipercow",
                           worker_id = worker_id,
                           offload_path = offload_path)
  w$loop()
  ## nocov end
}


## TODO: we need a way of easily flagging that the environment should
## be reloaded, especially in cases where 'rrq' was created as an
## environment after 'default'; for later though.
hipercow_rrq_envir <- function(e) {
  root <- hipercow_root()
  name <- if (hipercow_environment_exists("rrq")) "rrq" else "default"
  environment_apply(name, e, root)
}

hipercow_rrq_offload_path <- function(root) {
  offload_path <- file.path(root$path$rrq, "offload")
}


is_rrq_enabled <- function(root, call = parent.frame()) {
  driver <- hipercow_driver_select(name = NULL, required = FALSE,
                                   root = root, call = call)
  if (!is.null(driver)) {
    path_queue_id <- file.path(root$path$rrq, driver)
    file.exists(path_queue_id)
  }
}


rrq_worker_is_dead <- function(group) {
  function() {
    hipercow_bundle_status(group) %in% c("failure", "cancelled")
  }
}


rrq_worker_fetch_logs <- function(group, worker_ids) {
  function(worker_id) {
    i <- match(worker_id, worker_ids)
    if (!is.na(i)) {
      task_log_value(group$ids[[i]])
    }
  }
}
